---
title: "Take-home_Ex01"
author: "NeoYX"
date: '7 May 2023'
#date-modified: "`r Sys.Date()`"
editor: visual
execute: 
  freeze: auto
  warning: false
  #echo: false
  #message: false
  html:
    code-fold: True
    code-overflow: scroll
    code-summary: "Show the code"
    code-line-numbers: true
---

# 1. Task and Dataset

This exerises aims to reveal the demographic and financial characteristics of the city of Engagement, using appropriate **static and interactive statistical graphics** methods. It also requires a user-friendly and interactive solution that helps city managers and planners to explore the complex data in an engaging way and reveal hidden patterns.

The dataset consists of a sample survey of 1000 representative residents that collects data related to their household demographic and spending patterns, among other things. There are primarily two datasets used in this exercise

-   'FinancialJournal.csv": Contains 1513635 number of daily transaction records (different categories of income and expenses) over a period of twelve months from March 2022 to February 2023.

<!-- -->

-   'Particpants.csv" : Contains demographics information like household size, age, education level, interest groups, joviality index and whether each household has kids.

In this exercise, each dataset will be cleansed separately and then joined by 'participantID' as primary key to form the final dataset used for further analysis.

# 

# 2. Data Preparation

## 2.1 Install and load the required libraries

The code chunk below uses `pacman::p_load()` to check if packages are installed. If they are, they will be launched into R. The packages installed are

-   `plotly`: Used for creating interactive web-based graphs.

-   `knitr`: Used for dynamic report generation

-   `patchwork`: Used to combine plots

-   `tidyverse`: A collection of core packages designed for data science, used extensively for data preparation and wrangling.

-   `ggthemes`: Provide additional themes for `ggplot2`

-   `ggstatsplot`: Used for creating graphics with details from statistical tests.

-   `ggdist`: Used for visualising distribution and uncertainty

-   

-   

```{r}
pacman::p_load(plotly, knitr, patchwork, tidyverse, ggthemes, ggstatsplot, ggdist, png, gifski, nortest)
```

## 2.2 Import the dataset

The datasets are imported using `tidyverse`'s `readr::read_csv()` function.

'FinancialJournal.csv" is stored as `finance` variable.

```{r}
finance <- read_csv('data/FinancialJournal.csv')
```

```{r}
#| echo: false
head(finance)
```

Check for empty values in the `finance` table using the `is.na()` function.

```{r}
any(is.na(finance))
```

'Particpants.csv" is stored as `ptcp` variable.

```{r}
ptcp <- read_csv('data/Participants.csv')
```

```{r}
#| echo: false
head(ptcp)
```

Checking for empty values in `ptcp` table using the `is.na()`\` function.

```{r}
any(is.na(ptcp))
```

## 2.3 Data Issues and wrangling

I will discuss the issues in the datasets and proposed cleaning methods.

`finance` dataset:

-   **participantId** should be converted from `<dbl>` format to `<chr>` format. It should be a categorical and not numerical data type.

-   **timestamp** should be converted from `<dttm>` format to `<date>` format as I will not be analysing time in this exercise.

-   Negative values of **amount** that belong to the expenses categories should be converted to positive values. The amount will also be rounded to two decimal places.

```{r}

# Convert participantId to character
finance <- finance %>% mutate(participantId = as.character(participantId))

# Extract month and year from timestamp
finance <- finance %>% 
  mutate(month_year = format(timestamp, "%m-%Y"))

# Transform negative amounts to positive and round to 2 decimal places
finance <- finance %>% 
  mutate(amount = abs(amount),
         amount = round(amount, 2))

```

In the code chunk above:

EDIT BELOW

In this code snippet, we first load the **`dplyr`** package. Then, we use the **`mutate()`** function to convert the **`participantId`** column to character using the **`as.character()`** function. Next, we create a new column **`month_year`** by extracting the year and month from the **`timestamp`** column using the **`format()`** function with the **`%Y-%m`** format specifier. Finally, we use **`mutate()`** again to transform all negative values of the **`amount`** column to positive using the **`abs()`** function and round the **`amount`** column to 2 decimal places using the **`round()`** function.

A check for duplicates using the `duplicated()` function reveals that there are 1,113 records of duplicates. The

```{r}
# Show duplicate rows
duplicated_rows <- finance[duplicated(finance),]
glimpse(duplicated_rows)
```

EDIT BELOW

In this code snippet, we first use the **`duplicated()`** function to identify the duplicate rows in the **`finance`** data frame.
This function returns a logical vector indicating whether each row is a duplicate of a previous row in the data frame. We can then use this logical vector to subset the data frame and show the duplicate rows.
Next, we store them in a new data frame called **`duplicated_rows`**. We then print **`duplicated_rows`** to show the duplicate rows.

```{r}
# Remove duplicate rows
finance <- unique(finance)
```

Next, we remove the duplicate rows from the original **`finance`** data frame using the **`unique()`** function. This function returns a data frame with only the unique rows in the original data frame. We save the result back to the **`finance`** data frame to update it with the unique rows.

Do a final check if there are still duplicated rows using `any()` function.

```{r}
any(duplicated(finance))
```

`ptcp` dataset;

-   **participantId** should be converted from `<dbl>` format to `<chr>` format.
