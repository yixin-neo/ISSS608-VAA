---
title: "Take-home_Ex02"
author: "NeoYX"
date: '15 May 2023'
date-modified: "`r Sys.Date()`"
editor: visual
execute: 
  freeze: auto
  warning: false
  echo: true
  message: true
format:
  html:
    code-fold: true
    code-overflow: scroll
    code-summary: "Show the code"
    code-line-numbers: true
---

::: callout-note
**Edge data** should be organised as such: (can use dplyr methods)

First column: Source id (FK to Node second column) - compulsory

Second column: Target id (FK to Node second column) - compulsory

**Node data**

First column: ID (contains all the distinct values of source and target in Edge data) - compulsory

-   Nodes present in edge data must exists in ID of node data, must not have missing in node ID.

Second column: Label (only need if Id are all integers)
:::

::: callout-warning
Try not to use R built-in NA/NULL function. Manually type "unknown' / 'missing' as a value instead.
:::

# Vast Challenge 2023 Mini Challenge 2 (Subtask: 1)

In this challenge, my group and I seek to use visual analytics to identify temporal patterns for individual entities and between entities using the knowledge graph the FishEye Organisation has provided us with. We will also be categorising the type of business relationship patterns found.

# 1 About the dataset

## 1.1 Data dictionary

**Node Attributes:**

-   id \-- Name of the company that originated (or received) the shipment

-   shpcountry \-- Country the company most often associated with when shipping

-   rcvcountry \-- Country the company most often associated with when receiving

-   dataset \-- Always 'MC2'

**Edge Attributes:**

-   arrivaldate \-- Date the shipment arrived at port in YYYY-MM-DD format.

-   hscode \-- Harmonized System code for the shipment. Can be joined with the hscodes table to get additional details.

-   valueofgoods_omu \-- Customs-declared value of the total shipment, in Oceanus

-   Monetary Units (OMU)

-   volumeteu \-- The volume of the shipment in 'Twenty-foot equivalent units', roughly how many 20-foot standard containers would be required. (Actual number of containers may have been different as there are 20ft and 40ft standard containers and tankers that do not use containers)

-   weightkg \-- The weight of the shipment in kilograms (if known)

-   dataset \-- Always 'MC2'

-   type \-- Always 'shipment' for MC2

-   generated_by \-- Name of the program that generated the edge. (Only found on 'bundle' records.)

## 1.2 Importing the datasets

Import libraries

The new libraries used today are :

-   `jsonlite` to import json file

```{r}
pacman::p_load(jsonlite, igraph, tidygraph, ggraph,
               visNetwork, lubridate, clock,
               tidyverse, graphlayouts,knitr,plotly, 
               ggHoriPlot, ggthemes,hrbrthemes,treemap,patchwork, ggiraph,
               ggstatsplot)
```

```{r}
MC2 <- jsonlite::fromJSON("C:/yixin-neo/ISSS608-VAA/Project/data/mc2_challenge_graph.json")
```

```{r}
#| eval: false
#| echo: false
carp <- jsonlite::fromJSON("C:/yixin-neo/ISSS608-VAA/Project/data/bundles/carp.json")
```

Pull out the nodes and edge data and save them as tibble data frames.

```{r}
MC2_nodes <- as_tibble(MC2$nodes) %>% 
  select(id,shpcountry,rcvcountry)
```

```{r}
#| echo: false
glimpse(MC2_nodes)
```

Rearranging the columns in edge file as we require `source` and `target` columns to be the first two columns.

```{r}
MC2_edges <- as_tibble(MC2$links) %>% 
  select(source,target,arrivaldate,hscode,valueofgoods_omu,volumeteu,weightkg,valueofgoodsusd)  
# can exclude dataste column as they all contain the same values.
```

```{r}
#| echo: false
glimpse(MC2_edges)
```

# 2 Data cleaning

## 2.1 Lets check for duplicates

For MC2_nodes dataframe:

There are no duplicated nodes, which is great.

```{r}
#| eval: false
# check for any duplicates
any(duplicated(MC2_nodes))
```

For MC2_edges dataframe:

There are about 155291 records (2% out of total records) that are duplicated.

```{r}
#duplicated only
# print(any(duplicated(MC2_edges)))
MC2_edges_dup <- MC2_edges[duplicated(MC2_edges), ]
print(nrow(MC2_edges_dup))
```

We will drop the duplicates.

```{r}
# Drop duplicate rows from the dataframe
MC2_edges_no_dup <- MC2_edges[!duplicated(MC2_edges), ]
```

## 2.2 Check for null values

Check whether each column in MC2_nodes and MC2_edges contains null and prints the percentage of null for each column.

**For MC2_nodes dataframe:**

There are no null values in the id column of Nodes file, which is great.

```{r}
# Check for null values in each column
null_counts_nodes <- sapply(MC2_nodes, function(x) sum(is.null(x) | is.na(x)))

# Calculate the percentage of null values for each column
null_percentages_nodes <- null_counts_nodes / nrow(MC2_nodes) * 100

# Display the results
#print(null_percentages)

knitr::kable(null_percentages_nodes, "simple", col.names = c("Null Percentage"))
```

**For MC2_edges dataframe:**

As there are a lot zeros inside MC2_edges\$volumteu col, we will consider 0 as equivalent to null values.

We can see that the columns `valueofgoods_omu` and `volumeteu` are mainly null. `valueofgoodusd` column contains more than 50% null values. There are 4 records of `source` with 0 as value, but 0 is their unique identifier so we do not consider 0 as null in `source` column. It means to say that only `source`, `target`, `arrivaldate`, `hscode` and `weight` columns will be helpful in our analysis.

```{r}
# Check for null values in each column
null_counts <- sapply(MC2_edges_no_dup, function(x) sum(is.null(x) | is.na(x) | x==0))

# Calculate the percentage of null values for each column
null_percentages <- null_counts / nrow(MC2_edges_no_dup) * 100

# Display the results
#print(null_percentages)

knitr::kable(null_percentages, "simple", col.names = c('Percentage null'))

```

We will be dropping the `valueofgoods_omu` , `valueofgoodusd`and `volumeteu` columns from our dataframe.

```{r}
MC2_edges_no_dup <- MC2_edges_no_dup %>% select('source','target', 'arrivaldate', 'hscode','weightkg')
```

```{r}
#| eval: false
#| echo: false

# Filter rows where 'source' column contains 0
filtered_df <- MC2_edges_no_dup %>% filter(source == 0)

# Display the filtered dataframe
print(filtered_df)

```

### 1.3.3 Check on the HScodes

Check the unique number of hscodes in the dataset. There are 4761 unique HScodes.

```{r}
# Find the number of unique values in hscode
length(unique(MC2_edges_no_dup$hscode))

```

With reference to [World Custom Organisation Harmonized System codes](https://www.wcoomd.org/en/topics/nomenclature/instrument-and-tools/hs-nomenclature-2022-edition/hs-nomenclature-2022-edition.aspx), only Section 1 and 4 are related to seafood trade. We will filter for records that have HScodes starting with `1604` and `1605` as they refer to seafood commodities, thus removing many other transactions like 'television', 'steel parts' etc... that are not related to our project goals.

```{r}
mc2_seafood_edges<- MC2_edges_no_dup[grepl('^1605|^1604', MC2_edges_no_dup$hscode), ]

```

## 2.3 Preparation of Edges

We will perform a group by 'source', 'target' and 'arrivaldate' and aggregate the total count of interactions, 'Weight', between each pair of companies. We will not consider weight 10 and below. Because we are interested to see whether there are patterns of self-loops, we will not be removing any company shipping to itself.

```{r}
#unique(mc2_seafood_edges$hscode)
#unique(mc2_seafood_edges$source)
mc2_seafood_edges_agg <- mc2_seafood_edges %>%  
  group_by(source, target,arrivaldate) %>% 
  summarise(Weight=n(),
            Totalweight = sum(weightkg),
            hscode=first(hscode)) %>% 
  filter(Weight >=8) %>% 
  ungroup()
```

Lets wrangle the date columns to prepare dataframe for temporal analysis later.

\(1\) change the arrivaldate column to date data type

```{r}
mc2_seafood_edges_agg$arrivaldate <- as.Date(mc2_seafood_edges_agg$arrivaldate)

```

\(2\) create year, month, weekday, weeknumber columns

```{r}
mc2_seafood_edges_agg <- mc2_seafood_edges_agg %>% 
  mutate(year = year(arrivaldate)) %>% 
  mutate(month = month(arrivaldate)) %>% 
  mutate(day = day(arrivaldate)) %>% 
  mutate(weekday = wday(arrivaldate,
                        label= TRUE,
                        abbr = FALSE)) %>% 
  mutate(weeknumber = isoweek(arrivaldate))
```

Inspect the frequency of source and target actors, and remove those actors below a frequency count of 5.

First , we remove low frequency source actors under 5 counts.

```{r}
# Calculate the frequency count of values in 'source'
frequency_table <- table(mc2_seafood_edges_agg$source)

# Get the values in 'col1' with a frequency count greater than or equal to 5
valid_source <- names(frequency_table[frequency_table >= 5])

# Subset the dataframe to keep only rows with valid values in 'col1'
mc2_seafood_edges_agg <- mc2_seafood_edges_agg[mc2_seafood_edges_agg$source %in% valid_source, ]

```

Next, remove target actors with frequency count less than 5:

```{r}
# Calculate the frequency count of values in 'source'
frequency_table <- table(mc2_seafood_edges_agg$target)

# Get the values in 'col1' with a frequency count greater than or equal to 5
valid_target <- names(frequency_table[frequency_table >= 5])

# Subset the dataframe to keep only rows with valid values in 'col1'
mc2_seafood_edges_agg <- mc2_seafood_edges_agg[mc2_seafood_edges_agg$target %in% valid_target, ]


# Print the filtered dataframe
#print(mc2_seafood_edges_agg)
```

Based on some checks on the dataset, there were three pairs of actors that exist as disconnected components. They are 'Rift Valley fishery OJSC', 'Bujagali Falls Pic Family', 'Neptune's Realm NV Navigation', 'Rybachit Sagl and Son's', 'Mar de la Aventura Rybachit' and 'Olas del Sur Ltd'. Lets remove the edge records if either `source` or `target` columns contains any of these four nodes.

```{r}
# Specify the values to be excluded
#values_to_exclude <- c('Rift Valley fishery OJSC', 'Bujagali Falls Pic Family', 'Neptune\'s Realm NV Navigation', 'Rybachit Sagl and Son\'s', 'Mar de la Aventura Rybachit', 'Olas del Sur Ltd')

# Delete rows with specified values in 'from' or 'to' columns
#mc2_seafood_edges_agg <- mc2_seafood_edges_agg %>%
  #filter(!(source %in% values_to_exclude | target %in% values_to_exclude))

# Display the updated data frame
#print(mc2_seafood_edges_agg)

```

```{r}
#| eval: false
#| echo: false
sort(table(mc2_seafood_edges_agg$target))
```

## 2.4 Preparation of Nodes

We will include only nodes that are in source and target columns in the `mc2_seafood_edges_agg` dataframe

```{r}
nodes_seafood <- MC2_nodes %>%
  filter (id %in% c(mc2_seafood_edges_agg$source, mc2_seafood_edges_agg$target))
```

## 2.5 Creating the network graph dataframe using tbl_graph() of the tidygraph package.

::: callout-note
Node file needs to have ID of nodes as first column.

Edge file need to contain source and target as column 1 and 2.
:::

To create the network graph dataframe

```{r}
seafood_graph<- tbl_graph(nodes=nodes_seafood,
                          edges = mc2_seafood_edges_agg,
                          directed = TRUE)
```

Taking a look at the dataframe..

```{r}
#| echo: false
seafood_graph
```

We can run the code below to check that seafood_graph is a connected graph:

```{r}
is.connected(seafood_graph)
```

## 2.6 Calculate the various centrality measures of seafood_graph.

The top 10 nodes with reference to various centrality scores are printed using `kable()` function from `knitr`.

Reference was made from this [link](https://hohenfeld.is/posts/graphs-are-fun-an-introduction-to-graphs-in-r/). The tidyverse centrality functions can be taken from [here](https://cran.r-project.org/web/packages/tidygraph/tidygraph.pdf).

First compute 'in-deg', 'out-deg' and 'pagerank' scores. All my betweenness scores were zero (Investigation in progress)...

```{r}
seafood_graph<- seafood_graph %>%
  activate("nodes") %>% 
  mutate(betweenness_centrality = centrality_betweenness(directed = TRUE)) %>% 
  mutate(in_deg_centrality = centrality_degree(weights = Weight, 
                                               mode = "in")) %>% 
  mutate(out_deg_centrality = centrality_degree(weights = Weight, 
                                               mode = "out")) %>% 
  mutate(pagerank = centrality_pagerank(weights = Weight,
                                        directed = TRUE)) %>% 
  mutate(community = as.factor(group_edge_betweenness(weights = Weight, 
                                                      directed = TRUE,
                                                      n = 10)))

```

To see the top 10 nodes with 'in-deg' scores:

```{r}
seafood_graph %>% 
  activate("nodes") %>% 
  as_tibble() %>% 
  arrange(desc(in_deg_centrality), desc(pagerank)) %>% 
  select(id,in_deg_centrality,pagerank) %>% 
  head(n=10) %>% 
  kable()
```

To see the top 10 nodes with 'out-deg' scores:

```{r}
seafood_graph %>% 
  activate("nodes") %>% 
  as_tibble() %>% 
  arrange(desc(out_deg_centrality)) %>% 
  select(id,out_deg_centrality) %>% 
  head(n=10) %>% 
  kable()
```

```{r}
#| eval: false
#| echo: false
#| fig-width: 12
#| fig-asp: 0.618
set.seed (1234)
a <- ggraph(seafood_graph, layout = 'fr') +
  geom_edge_link(aes(width=Weight, alpha= 0.2),
                 arrow = arrow(length = unit(2, 'mm')), #<<< delete
                 end_cap = circle(1, 'mm')) +           #<<< delete
  scale_edge_width(range = c(0.1, 5)) +
  geom_node_point(aes(size = in_deg_centrality, colour=rcvcountry)) +
  geom_edge_loop()

a + theme_graph()

```

```{r}
#| eval: false
#| echo: false
#| fig-width: 12
#| fig-asp: 0.618

set.seed (1234)
b <- seafood_graph %>%
  mutate(community = as.factor(group_edge_betweenness(weights = Weight, 
                                                      directed = TRUE,
                                                      n = 20))) %>%
  ggraph(layout = "fr") + 
  geom_edge_link(aes(width=Weight), 
                 alpha=0.2) +
  scale_edge_width(range = c(0.1, 5)) +
  geom_node_point(aes(colour = community))  

b  + theme_graph() + theme(legend.key.size = unit(1, "lines"),
          legend.position = 'bottom')

```

# 3 Interactive graphs of network structure, temporal analysis and business patterns detection

## 3.1 Interactive graph grouped by IN-DEGREE CENTRALITY scores

We first need to rename the edge file first two columns to `from` and `to` for visNetwork to be able to regconise them. `title` column has been created for tooltip when we hover over each of the edges.

```{r}
mc2_seafood_edges_agg_vis <- mc2_seafood_edges_agg %>% 
  rename(from = source) %>% 
  rename(to = target) %>% 
  mutate(title = paste('Total Weight = ',Totalweight, "\n HSCODE =", hscode))
```

The code chunk below extracts the node table from tbl_graph() object 'seafood_graph' created earlier. The reason for donig so is because it contains the centrality values that were calculated using the tidyverse centrality functions.

Next, add a column `title` because it is the column that VisNetwork will search for to display tooltip when the mouse hovers over the nodes. We will be displaying the 'in-deg', 'pagerank' and 'out-deg' scores in the tooltip. If we want to colour the nodes by their shipping countries, then we would have to rename the `shpcountry` column to `group` because visNetwork looks for `group` column to colour the nodes. However, we will not do this now.

```{r}
# extract nodes file from seafood_graph as a data frame
nodes_seafood_vis <- as.data.frame(seafood_graph %>% activate(nodes))

# further processing
nodes_seafood_vis <- nodes_seafood_vis %>% 
  #rename(group= rcvcountry)  %>% 
  mutate(pagerank = round(pagerank, 5)) %>% 
  mutate(title = paste('shpcountry =', shpcountry, ',',
                       'rcvcountry =', rcvcountry, ',',
                       '\n In-deg = ',in_deg_centrality, ',',
                       "\n Pagerank =", pagerank, ',',
                       "\n Out-deg =", out_deg_centrality))

```

The code chunk below binned the in-deg scores into intervals of 50 using the `cut()` function. Next, rename the `in_deg_grp` column to `group` column for VisNetwork to colour nodes by in-deg intervals.

```{r}
in_deg_brks <- c(0, 500, 1000, 2000, 3000, 7000)
grps <- c('500 & Below','501-1000', '1001-2000', '2001-3000', '3001-6132')

nodes_seafood_vis$in_deg_grp <- cut(nodes_seafood_vis$in_deg_centrality, breaks=in_deg_brks, labels = grps,include.lowest = TRUE)

nodes_seafood_vis$in_deg_grp <- factor(nodes_seafood_vis$in_deg_grp, ordered = TRUE, levels = c('3001-6132','2001-3000','1001-2000','501-1000','500 & Below'))

nodes_seafood_vis <- nodes_seafood_vis %>% 
  rename(group = in_deg_grp)
```

The code chunk below plots in interactive network graph using visNetwork.

```{r}
#| fig-width: 12
#| fig-asp: 0.618
visNetwork(nodes_seafood_vis,
           mc2_seafood_edges_agg_vis,
           main = "Seafood graph grouped by In-Deg centrality intervals",
           height = "500px", width = "100%") %>%
  visIgraphLayout(layout = "layout_nicely") %>%
  visEdges(arrows = 'to',
           smooth = list(enables = TRUE,
                         type= 'curvedCW'),
           shadow = FALSE,
           dash = FALSE) %>% 
  visOptions(highlightNearest = list(enabled = T, degree = 1, hover = T),
             nodesIdSelection = TRUE,
             selectedBy = "group") %>%
  visInteraction(hideEdgesOnDrag = TRUE) %>% 
  visLegend() %>%
  visLayout(randomSeed = 123)
```

::: callout-note
## Interactivity features of this graph

\(1\) Select Id dropdown list

\(2\) Select Group dropdown list: The values inside refers to the range of 'in-deg' centrality scores of the nodes. The pink colour node will represent the highest in-deg centrality score, followed by green, yellow, red and blue.

\(3\) Zoom in to see the node labels, and arrows direction.

\(4\) Drag a particular node away from the cluster to admire it.

\(5\) Hover mouse over a node will display tooltip (shpcountry, rcvcountry, In-deg, pagerank and out-deg score). It will also display the 'ego' network with itself at the ego. Click on the node to freeze the ego network. Click on blank space to reset.

\(6\) Hovering the mouse over an edge will display tooltip (Total weight of cargo, hscode of cargo)

\(7\) Click and Drag on the graph to move the canvas around, will also temporary disable the edge lines.
:::

From the plot above, we can see there are a few top shipping companies that has high interactions with receiving companies. Try selecting '1001 - 2000' from the group drop down list, we will see three companies with similar range of 'in-deg' centrality scores. The company with the highest 'in-deg' centrality score is 'Fresh Wharf SRL Consulting', but note that it receives only from one shipping company 'Playa del Tesoro OJSC' .

## 3.2 Temporal analysis of top 10 'in-deg' centrality companies in trading occurrence over the years

Use the code chunk below to get top 10 buyer companies.

```{r}
top_10_in_list <- mc2_seafood_edges_agg_vis %>%  
  group_by(to) %>%  
  summarise(Allweight = sum(Weight)) %>% 
  arrange(desc(Allweight)) %>% top_n(10) %>%
  pull(to)


kable(top_10_in_list, col.names=c('Top 10 in-deg companies'))
```

Subset the dataset to filter records from top 10 buyer companies

```{r}
top_10_indeg <- mc2_seafood_edges_agg_vis %>%
  filter(to %in% top_10_in_list)
```

Next, filter records where Weight value does not fall in outlier regions

```{r}
cutpoints_top10_indeg <- top_10_indeg  %>% 
  mutate(
    outlier = between(
      Weight, 
      quantile(Weight, 0.25, na.rm=T)-
        1.5*IQR(Weight, na.rm=T),
      quantile(Weight, 0.75, na.rm=T)+
        1.5*IQR(Weight, na.rm=T))) %>% 
  filter(outlier)
```

Set the fold value by finding the midpoint of the max and min Weight values for the entire Horizon plot. the ori value will be used in the origin parameter which indicates the origin of the horizon plot.

Then set the intervals of Weighs value using the seq() function. The sca vector will be used to colour the horizon plot later by using the parameter fill.

```{r}
ori <- sum(range(top_10_indeg$Weight))/2

sca <- seq(range(top_10_indeg$Weight)[1], 
           range(top_10_indeg$Weight)[2], 
           length.out = 7)[-4]
```

Last preparation to do would be to fix the arrivaldate column such that all the year value are the same (for the purpose for plotting horizon chart later). All the year values will get a default '2021'.

```{r}
top_10_indeg$mine_date <- sprintf("2021-%s-%s", substr(top_10_indeg$arrivaldate, 6, 7), substr(top_10_indeg$arrivaldate, 9, 10))

top_10_indeg$mine_date <- as.Date(top_10_indeg$mine_date)

```

Plotting the horizon plot

```{r}
#| fig-width: 12
#| fig-asp: 0.618
top_10_indeg %>% ggplot() +
  geom_horizon(aes(arrivaldate, 
                   Weight,
                   fill = ..Cutpoints..), 
               origin = ori, horizonscale = sca) +
  scale_fill_hcl(palette = 'RdBu', reverse = T) +
  facet_grid(to~.) +
  theme_few() +
  theme(
    panel.spacing.y=unit(0, "lines"),
    strip.text.y = element_text(size = 7, angle = 0, hjust = 0),
    axis.text.y = element_blank(),
    axis.title.y = element_blank(),
    axis.ticks.y = element_blank(),
    panel.border = element_blank()
    ) +
  scale_x_date(expand=c(0,0), 
               date_breaks = "3 month",
               date_labels = "%b %Y") +
  xlab('Date') +
  ggtitle('Trading interactions of top 10 receving companies from 2028 to 2034') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 6))
```

Analysis of the plot above:

'Fresh Wharf SRL Consulting' exhibits similar patterns to top shipping company 'Playa del Tesoro OJSC' because of they are close trading partners (refer to interactive graph). The buying pattern of 'Fresh Wharf SRL Consulting' can be considered unusual due to the spikes we see happening at certain time periods (eg. end 2029 and 3rd quarter of 2033).

## 3.3 Trading patterns of Volga River LLC Enterprises

Let us examine the trading patterns of 'Volga River LLC Enterprises', one of the few top leading companies in terms of ''in-deg' with its four biggest suppliers (as seen from the interactive graph).

First, filter records with only Volga River LLC Enterprises and its suppliers.

```{r}
 volga_in_df<- mc2_seafood_edges_agg_vis %>%
  filter(to %in% 'Volga River LLC Enterprises')
```

Next, plot a time series using `geom_line()` and `geom_point_interactive()`.

```{r}
#| fig-width: 12
#| fig-height: 30
volga_in_df <- volga_in_df %>% 
  mutate(tooltip = paste0('# of interaction: ', Weight, '\nDate :', arrivaldate))

volga_in1<- ggplot(volga_in_df %>% filter(from=='Estrella de la Costa SRL'), aes(x=arrivaldate, y=Weight)) +
  geom_line( color="steelblue", size = 0.8) + 
  geom_point_interactive(aes(tooltip= tooltip), 
                         size = 0.5) +
  xlab("") +
  theme_light() +
  theme(#panel.spacing = unit(2, "lines"),
        axis.text.x=element_text(angle=60, hjust=1),
        panel.grid.major.x = element_blank(),
        axis.title.y = element_text(size = 10)) +
  scale_x_date(
    breaks = seq(as.Date("2028-01-01"), as.Date("2034-12-31"), by = "3 months"),
    labels = function(x) format(x, "%b %Y")) +
  labs(title='Estrella de la Costa SRL', 
       x = 'Date',
       y='Number of trading occurrence')

volga_in2<- ggplot(volga_in_df %>% filter(from=='Náutica del Sol Brothers'), aes(x=arrivaldate, y=Weight)) +
  geom_line( color="steelblue", size = 0.8) + 
  geom_point_interactive(aes(tooltip= tooltip),
                         size = 0.5) +
  xlab("") +
  theme_light() +
  theme(#panel.spacing = unit(2, "lines"),
        axis.text.x=element_text(angle=60, hjust=1),
        panel.grid.major.x = element_blank(),
        axis.title.y = element_text(size = 10)) +
  scale_x_date(
    breaks = seq(as.Date("2028-01-01"), as.Date("2034-12-31"), 
                 by = "3 months"),
    limits = c(as.Date("2028-01-01"), as.Date("2034-12-31")),
    labels = function(x) format(x, "%b %Y")) +
  scale_y_continuous(
    limits = c(0, 30),  # Set the y-axis limits
    breaks = seq(0, 30, by = 5),  # Set the y-axis breaks at intervals of 5
    #minor_breaks = seq(0, 30, by = 1),  # Set the y-axis minor breaks at intervals of 1
    expand = c(0, 0)) +  # Remove padding around the y-axis limits

      
  labs(title='Náutica del Sol Brothers', 
       x = 'Date',
       y='Number of trading occurrence')


volga_in3<- ggplot(volga_in_df %>% filter(from=='Pez Dorado Inc Freight '), aes(x=arrivaldate, y=Weight)) +
  geom_line( color="steelblue", size = 0.8) + 
  geom_point_interactive(aes(tooltip= tooltip),
                         size = 0.5) +
  xlab("") +
  theme_light() +
  theme(#panel.spacing = unit(2, "lines"),
        axis.text.x=element_text(angle=60, hjust=1),
        panel.grid.major.x = element_blank(),
        axis.title.y = element_text(size = 10)) +
  scale_x_date(
    breaks = seq(as.Date("2028-01-01"), as.Date("2034-12-31"), by = "3 months"),
    limits = c(as.Date("2028-01-01"), as.Date("2034-12-31")),
    labels = function(x) format(x, "%b %Y")) +
  scale_y_continuous(
    limits = c(0, 30),
    breaks = seq(0, 30, by = 5), 
    expand = c(0, 0)) +
  
  labs(title='Pez Dorado Inc Freight', 
       x = 'Date',
       y='Number of trading occurrence')

volga_in4<- ggplot(volga_in_df %>% filter(from=='Seaside Summit SE Merchants'), aes(x=arrivaldate, y=Weight)) +
  geom_line( color="steelblue", size = 0.8) + 
  geom_point_interactive(aes(tooltip= tooltip),
                         size = 0.5) +
  xlab("") +
  theme_light() +
  theme(#panel.spacing = unit(2, "lines"),
        axis.text.x=element_text(angle=60, hjust=1),
        panel.grid.major.x = element_blank(),
        axis.title.y = element_text(size = 10)) +
  scale_x_date(
    breaks = seq(as.Date("2028-01-01"), as.Date("2034-12-31"), by = "3 months"),
    limits = c(as.Date("2028-01-01"), as.Date("2034-12-31")),
    labels = function(x) format(x, "%b %Y")) +
  scale_y_continuous(
    limits = c(0, 30),
    breaks = seq(0, 30, by = 5), 
    expand = c(0, 0)) +
  labs(title='Seaside Summit SE Merchants', 
       x = 'Date',
       y='Number of trading occurrence')

girafe(code = print(volga_in1 / volga_in2 / volga_in3 / volga_in4),
       #width_svg = 6,
       height_svg =8,
       options = list(
         opts_hover(css = "fill: #202020;"),
         opts_hover_inv(css = "opacity:0.2;")
         )
       ) 
```

```{r}
#| eval: false
#| echo: false
volga_in5<- ggplot(volga_in_df %>% filter(from=='irish trout NV Carriers'), aes(x=arrivaldate, y=Weight)) +
  geom_line( color="steelblue", size = 0.8) + 
  geom_point_interactive(aes(tooltip= tooltip),
                         size = 0.5) +
  xlab("") +
  theme_light() +
  theme(#panel.spacing = unit(2, "lines"),
        axis.text.x=element_text(angle=60, hjust=1),
        panel.grid.major.x = element_blank()) +
  scale_x_date(
    breaks = seq(as.Date("2028-01-01"), as.Date("2034-12-31"), by = "3 months"),
    limits = c(as.Date("2028-01-01"), as.Date("2034-12-31")),
    labels = function(x) format(x, "%b %Y")) +
  scale_y_continuous(
    limits = c(0, 30),
    breaks = seq(0, 30, by = 5), 
    expand = c(0, 0)) +
  labs(title='irish trout NV Carriers', 
       x = 'Date',
       y='Number of trading occurrence')

volga_in6<- ggplot(volga_in_df %>% filter(from=='Mar y Viento Abalone N.V. Marine conservation'), aes(x=arrivaldate, y=Weight)) +
  geom_line( color="steelblue", size = 0.8) + 
  geom_point_interactive(aes(tooltip= tooltip),
                         size = 0.5) +
  xlab("") +
  theme_light() +
  theme(#panel.spacing = unit(2, "lines"),
        axis.text.x=element_text(angle=60, hjust=1),
        panel.grid.major.x = element_blank()) +
  scale_x_date(
    breaks = seq(as.Date("2028-01-01"), as.Date("2034-12-31"), by = "3 months"),
    limits = c(as.Date("2028-01-01"), as.Date("2034-12-31")),
    labels = function(x) format(x, "%b %Y")) +
  scale_y_continuous(
    limits = c(0, 30),
    breaks = seq(0, 30, by = 5), 
    expand = c(0, 0)) +
  labs(title='Mar y Viento Abalone N.V. Marine conservation', 
       x = 'Date',
       y='Number of trading occurrence')
```

Analysis of the plot above: Throughout the years, Volga River LLC Enterprises has interactions with Esstrella de la Coasta SRL, and with spikes in interaction in recent years. There were four interactions with 'Seaside Summit SE Merchants' and only 3 interactions with Nautical del Sol Brothers; these are considered short and abrupt interactions. It dawned on me that we can identify IUU companies that frequently close down and re-register their companies from the tye of plot above. For such companies, I would expect the buyer's graph to show that buyer has been changing suppliers very frequently.

For our group project we can consider creating drop down list of 'buying companies' for user to interact with and see each of the buyer's interaction with their top n suppliers over the years. A coordinated view can be created with social network graph such that when a buyer / supplier node is selected on the network graph, its trading activity over time with top n suppliers/ buyers is automatically generated.

## 3.4 Interactive graph grouped by OUT-DEGREE CENTRALITY scores

The code chunk below binned the out-deg scores into intervals of 50 using the `cut()` function. Next, rename the `group` column back to `in-deg` column followed by `out_deg_grp` column to `group` column for VisNetwork to colour nodes by out-deg intervals.

```{r}
out_deg_brks <- c(0, 500, 1000, 2000, 3000, 7000)
grps <- c('500 & Below','501-1000', '1001-2000', '2001-3000', '3001-6132')

nodes_seafood_vis$out_deg_grp <- cut(nodes_seafood_vis$out_deg_centrality, breaks=in_deg_brks, labels = grps,include.lowest = TRUE)

nodes_seafood_vis$out_deg_grp <- factor(nodes_seafood_vis$out_deg_grp, ordered = TRUE, levels = c('3001-6132','2001-3000','1001-2000','501-1000','500 & Below'))

nodes_seafood_vis <- nodes_seafood_vis %>% 
  rename(in_deg_grp = group) %>% 
  rename(group = out_deg_grp)
```

The code chunk below plots the interactive graph.

```{r}
#| fig-width: 12
#| fig-asp: 0.618
visNetwork(nodes_seafood_vis,
           mc2_seafood_edges_agg_vis,
           main = "Seafood graph grouped by Out-Deg centrality intervals",
           height = "500px", width = "100%") %>%
  visIgraphLayout(layout = "layout_nicely") %>%
  visEdges(arrows = 'to',
           smooth = list(enables = TRUE,
                         type= 'curvedCW'),
           shadow = FALSE,
           dash = FALSE) %>% 
  visOptions(highlightNearest = list(enabled = T, degree = 1, hover = T),
             nodesIdSelection = TRUE,
             selectedBy = "group") %>%
  visInteraction(hideEdgesOnDrag = TRUE) %>% 
  visLegend() %>%
  visLayout(randomSeed = 123)
```

The chart highlights actors with high out-deg centrality scores over 2028 to 2034. In this default view, we can quickly identify the coloured nodes as top few suppliers.

## 3.3 Temporal analysis of top supplier company in trading occurrence over the years

Let us visualise the horizon plot of the number of trading activities of the top supplier company 'Playa del Tesoro OJSC' over the years.

First filter records of this company.

```{r}
playa <- mc2_seafood_edges_agg_vis %>%
  filter(from == "Playa del Tesoro OJSC")
```

Next, filter records where `Weight` value does not fall in outlier regions

```{r}
cutpoints_playa <- playa  %>% 
  mutate(
    outlier = between(
      Weight, 
      quantile(Weight, 0.25, na.rm=T)-
        1.5*IQR(Weight, na.rm=T),
      quantile(Weight, 0.75, na.rm=T)+
        1.5*IQR(Weight, na.rm=T))) %>% 
  filter(outlier)
```

Set the fold value by finding the midpoint of the max and min Weight values for the entire Horizon plot. the `ori` value will be used in the `origin` parameter which indicates the origin of the horizon plot.

Then set the intervals of Weighs value using the `seq()` function. The `sca` vector will be used to colour the horizon plot later by using the parameter `fill.`

```{r}
ori <- sum(range(cutpoints_playa$Weight))/2

sca <- seq(range(cutpoints_playa$Weight)[1], 
           range(cutpoints_playa$Weight)[2], 
           length.out = 7)[-4]
```

Last preparation to do would be to fix the arrivaldate column such that all the year value are the same (for the purpose for plotting horizon chart later). All the year values will get a default '2021'.

```{r}
playa$mine_date <- sprintf("2021-%s-%s", substr(playa$arrivaldate, 6, 7), substr(playa$arrivaldate, 9, 10))
playa$mine_date <- as.Date(playa$mine_date)
```

We are finally ready to plot....

```{r}
#| fig-width: 12
#| fig-asp: 0.618
playa %>% ggplot() +
  geom_horizon(aes(mine_date, 
                   Weight,
                   fill = ..Cutpoints..), 
               origin = ori, horizonscale = sca) +
  scale_fill_hcl(palette = 'RdBu', reverse = T) +
  facet_grid(year~.) +
  theme_few() +
  theme(
    panel.spacing.y=unit(0, "lines"),
    strip.text.y = element_text(size = 7, angle = 0, hjust = 0),
    axis.text.y = element_blank(),
    axis.title.y = element_blank(),
    axis.ticks.y = element_blank(),
    panel.border = element_blank()
    ) +
  scale_x_date(expand=c(0,0), 
               date_breaks = "1 month", 
               date_labels = "%b") +
  xlab('Date') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle('Trading interactions of Playa del Tesoro OJSC from 2028 to 2034')
```

Blue regions represents cold trading intervals while red regions represents high trading occurrence for this company. The chart is faceted by year. Observe that the company was cold from Apr 2031 to May 2033 and trading occurrence pick up in the last quarter of 2033. This pattern with occassional spikes is indeed unusual and some investigation could be done regarding this company and its buyer (discussed earlier).

## 3.4 Temporal analysis of top 10 'out-deg' centrality companies in trading occurrence over the years

We would like to see if there are other supplier companies that has patterns like 'Playa del Tesoro OJSC' so we will plot multiple horizon graphs for quick comparison.

Use the code chunk below to get the top 10 supplier companies

```{r}
mc2_seafood_edges_agg_vis %>%  group_by(from) %>%  summarise(Allweight = sum(Weight)) %>% arrange(desc(Allweight))
```

```{r}
top_10_out_list <- mc2_seafood_edges_agg_vis %>%  
  group_by(from) %>%  
  summarise(Allweight = sum(Weight)) %>% 
  arrange(desc(Allweight)) %>% top_n(10) %>%
  pull(from)

kable(top_10_out_list, col.names=c('Top 10 out-deg companies'))
```

Subset the entire dataset to filter records of these 10 companies

```{r}
top10_outdeg <-subset(mc2_seafood_edges_agg_vis, from %in% top_10_out_list)
```

Repeat the steps as explained previously to prepare for the horizon plot

```{r}
cutpoints_top10_outdeg <- top10_outdeg  %>% 
  mutate(
    outlier = between(
      Weight, 
      quantile(Weight, 0.25, na.rm=T)-
        1.5*IQR(Weight, na.rm=T),
      quantile(Weight, 0.75, na.rm=T)+
        1.5*IQR(Weight, na.rm=T))) %>% 
  filter(outlier)

ori <- sum(range(top10_outdeg$Weight))/2

sca <- seq(range(top10_outdeg$Weight)[1], 
           range(top10_outdeg$Weight)[2], 
           length.out = 7)[-4]

top10_outdeg$mine_date <- sprintf("2021-%s-%s", substr(top10_outdeg$arrivaldate, 6, 7), substr(top10_outdeg$arrivaldate, 9, 10))

top10_outdeg$mine_date <- as.Date(top10_outdeg$mine_date)
```

Plotting the horizon plot of top 10 shipping companies over the years

```{r}
#| fig-width: 12
#| fig-asp: 0.618
top10_outdeg %>% ggplot() +
  geom_horizon(aes(arrivaldate, 
                   Weight,
                   fill = ..Cutpoints..), 
               origin = ori, horizonscale = sca) +
  scale_fill_hcl(palette = 'RdBu', reverse = T) +
  facet_grid(from~.) +
  theme_few() +
  theme(
    panel.spacing.y=unit(0, "lines"),
    strip.text.y = element_text(size = 7, angle = 0, hjust = 0),
    axis.text.y = element_blank(),
    axis.title.y = element_blank(),
    axis.ticks.y = element_blank(),
    panel.border = element_blank()
    ) +
  scale_x_date(expand=c(0,0), 
               date_breaks = "3 month",
               date_labels = "%b %Y") +
  xlab('Date') +
  ggtitle('Trading interactions of top 10 shipping companies from 2028 to 2034') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 6))
```

Analysis of the plot above:

Observe the different shipping companies were active for different period of time. Most of them have low interactions consistently throughout 2028-2034 (Like 'Estrella', 'Oceanic' and 'Shou gan') while some have stopped activity for some time (like 'Gujarat', 'Nautica' and 'Diao er'). The most unique of all is 'Playa del Tesoro OJSC' - some of it interactions are extremely high for a specific period of time. To capture suspicious companies that are in operation for only a short period of time, we can consider plotting more horizon plots.

## 3.6 Comparison of centrality values across shipping countries

In this section, we will compare the centrality values of companies from different countries.

### 3.6.1 Comparison of  out-deg centrality between top shipping countries

Let us compute top 5 shipping countries in terms of out-deg centrality scores.

```{r}
nodes_seafood_vis %>% 
  group_by(shpcountry) %>% 
  summarise(sum_out_deg = sum(out_deg_centrality)) %>% 
  arrange(desc(sum_out_deg)) %>% 
  head(n=5) %>% kable()
```

The code chunk below filters the top 5 shipping countries and non parametric one way anova test is performed to compare for significance in difference in median of number of interactions between them.

```{r}
#| fig-width: 12
#| fig-asp: 0.618
ggbetweenstats(data = nodes_seafood_vis %>% 
                 filter(shpcountry %in% c("Quirinelle", "Marebak", "Arreciviento", "Mawazam", "Merigrad")),
               x = shpcountry, 
               y = out_deg_centrality,
               xlab = "Shipping Country", ylab = "Out-Deg centrality",
               type = "np", pairwise.comparisons = TRUE, pairwise.display = "s",
               sort = "descending",
               sort.fun = median,
               mean.ci = T, p.adjust.method = "fdr",  conf.level = 0.95,
               title = "Comparison of Median Out-Deg centrality across shipping Countries") +
  scale_y_continuous(limits = c(0, 4000)) +
  theme(axis.title.y=element_text(angle = 0,
                                  vjust=0.9))
```

The P - value is above 0.05, so there is not enough statistical evidence to reject the null hypothesis that the median out-deg centrality scores between top 5 shipping countries are different.

### 3.6.2 Comparison of in-deg centrality between top receiving countries

Let us compute top 5 receiving countries in terms of in-deg centrality scores.

```{r}
nodes_seafood_vis %>% 
  group_by(rcvcountry) %>% 
  summarise(sum_in_deg = sum(in_deg_centrality)) %>% 
  arrange(desc(sum_in_deg)) %>% 
  head(n=5)
```

There are only 3 major receiving countries in our filtered dataset .

```{r}
ggbetweenstats(data = nodes_seafood_vis %>% filter(rcvcountry %in% c("Utoporiana", "Oceanus",'Coralmarica')), x = rcvcountry, y = in_deg_centrality,
               xlab = "Shipping Country", ylab = "In-Deg centrality",
               type = "np", pairwise.comparisons = TRUE, pairwise.display = "s",
               sort = "descending",
               sort.fun = median,
               mean.ci = T, p.adjust.method = "fdr",  conf.level = 0.95,
               title = "Comparison of Median In-Deg centrality across receiving Countries") +
  scale_y_continuous(limits = c(0, 215)) +
   theme(axis.title.y=element_text(angle = 0,
                                  vjust=0.9))
```

The P - value is above 0.05, so there is not enough statistical evidence to reject the null hypothesis that the median in-deg centrality scores between top 5 receiving countries are different.

## 

3.7 Correlationship between partnership intervals (in days) and total number of interactions between companies

We will prepare the dataframe needed for the plot. First, for each group of `from`, `to`, `year`:

1\) `partner_days` : the number of days within the year that each pair of companies had interactions

2\) `total_interaction` : sum of all the Weights between each pair of companies

```{r}
cor <- mc2_seafood_edges_agg_vis %>% 
  group_by(from, to,year) %>% 
  summarise(partnership_days=as.integer(max(arrivaldate)-min(arrivaldate)+1),
            total_interaction = sum(Weight),
            median_interaction = median(Weight)) %>% 
  ungroup() %>% 
  arrange(partnership_days)
```

Filter the above dateframe by year

```{r}
#| fig-width: 12
#| fig-asp: 0.618
library(scales)
correl_2028 <- ggscatterstats(data = cor %>% filter(year==2028), 
                           x = partnership_days, y = total_interaction,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 365), 
                     breaks=seq(0, 365, 30), 
                     labels= comma) + 
  scale_y_continuous(limits = c(0, 1250), 
                     breaks=seq(0, 1250, 250), 
                     labels= comma) +
  
  labs(title = "Sum of interactions and partnership duration (days) in 2028", 
       x = "days", y = "Number of interactions") 

correl_2029 <- ggscatterstats(data = cor %>% filter(year==2029), 
                           x = partnership_days, y = total_interaction,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 365), 
                     breaks=seq(0, 365, 30), 
                     labels= comma) + 
  scale_y_continuous(limits = c(0, 1250), 
                     breaks=seq(0, 1250, 250), 
                     labels= comma) +
  
  labs(title = "Sum of interactions and partnership duration (days) in 2029", 
       x = "days", y = "Number of interactions") 

correl_2028 <- ggscatterstats(data = cor %>% filter(year==2028), 
                           x = partnership_days, y = total_interaction,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 365), 
                     breaks=seq(0, 365, 30), 
                     labels= comma) + 
  scale_y_continuous(limits = c(0, 1250), 
                     breaks=seq(0, 1250, 250), 
                     labels= comma) +
  
  labs(title = "Sum of interactions and partnership duration (days) in 2028", 
       x = "days", y = "Number of interactions") 


correl_2030 <- ggscatterstats(data = cor %>% filter(year==2030), 
                           x = partnership_days, y = total_interaction,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 365), 
                     breaks=seq(0, 365, 30), 
                     labels= comma) + 
  scale_y_continuous(limits = c(0, 1250), 
                     breaks=seq(0, 1250, 250), 
                     labels= comma) +
  
  labs(title = "Sum of interactions and partnership duration (days) in 2030", 
       x = "days", y = "Number of interactions") 


correl_2031 <- ggscatterstats(data = cor %>% filter(year==2031), 
                           x = partnership_days, y = total_interaction,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 365), 
                     breaks=seq(0, 365, 30), 
                     labels= comma) + 
  scale_y_continuous(limits = c(0, 1250), 
                     breaks=seq(0, 1250, 250), 
                     labels= comma) +
  
  labs(title = "Sum of interactions and partnership duration (days) in 2031", 
       x = "days", y = "Number of interactions") 


correl_2032 <- ggscatterstats(data = cor %>% filter(year==2032), 
                           x = partnership_days, y = total_interaction,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 365), 
                     breaks=seq(0, 365, 30), 
                     labels= comma) + 
  scale_y_continuous(limits = c(0, 1250), 
                     breaks=seq(0, 1250, 250), 
                     labels= comma) +
  
  labs(title = "Sum of interactions and partnership duration (days) in 2032", 
       x = "days", y = "Number of interactions") 


correl_2033 <- ggscatterstats(data = cor %>% filter(year==2033), 
                           x = partnership_days, y = total_interaction,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 365), 
                     breaks=seq(0, 365, 30), 
                     labels= comma) + 
  scale_y_continuous(limits = c(0, 1250), 
                     breaks=seq(0, 1250, 250), 
                     labels= comma) +
  
  labs(title = "Sum of interactions and partnership duration (days) in 2033", 
       x = "days", y = "Number of interactions") 



correl_2034 <- ggscatterstats(data = cor %>% filter(year==2034), 
                           x = partnership_days, y = total_interaction,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 365), 
                     breaks=seq(0, 365, 30), 
                     labels= comma) + 
  scale_y_continuous(limits = c(0, 1250), 
                     breaks=seq(0, 1250, 250), 
                     labels= comma) +
  
  labs(title = "Sum of interactions and partnership duration (days) in 2034", 
       x = "days", y = "Number of interactions") 

# combining plots using patchwork
p_correl <- (correl_2028 + correl_2029) / (correl_2030 + correl_2031) / (correl_2032 + correl_2033) # + plot_spacer() + plot_spacer()
p_correl + plot_annotation(title = "Correlation between Numer of interactions and partnership duration (days)", 
                           theme = theme(plot.title = element_text(size = 18),
                                         plot.subtitle = element_text(size = 12))) + plot_layout(ncol = 1, nrow = 3,
                                                                                                 heights = c(2,2))
```

The plots (non-parametric) above has p-values less than 0.05 and it suggests that there is a correlation between the rank-transformed data . The upper outliers could be worth investigating because they have exceptionally high number of interactions for a particular partnership duration with another company. For example, if a company A had interaction with company B for only 3 months but with exceptionally high number of trading interactions, should both companies be worth investigating?

```{r}
cor <- cor %>%
  mutate(label1 = group_indices(., from, to))
```

```{r}
#| fig-width: 12
#| fig-asp: 0.618
scatter_2034 <- ggplot(data=cor%>% filter(year==2034),
       aes(x=partnership_days, y=total_interaction)) +
  geom_point_interactive(aes(data_id = label1,
                             tooltip= label1)) +
  geom_smooth(method='lm') +
  #ylim(0,100) +
  #xlim(0,100) +
  #geom_vline(xintercept=50, linetype='dashed') +
  #geom_hline(yintercept=50, linetype='dashed') +
  ggtitle('Scatterplot of Number of interactions and Partnership duration (Days)') +
  theme_minimal()
  #theme(legend.position='bottom') +
  #scale_color_gradient(low="darkgreen", high="green")

scatter_2033 <- ggplot(data=cor%>% filter(year==2033),
       aes(x=partnership_days, y=total_interaction)) +
  geom_point_interactive(aes(data_id = label1,
                             tooltip= label1)) +
  geom_smooth(method='lm') +
  #ylim(0,100) +
  #xlim(0,100) +
  #geom_vline(xintercept=50, linetype='dashed') +
  #geom_hline(yintercept=50, linetype='dashed') +
  ggtitle('Scatterplot of # of interactions and Partnership duration (Days) in 2033') +
  theme_minimal()


girafe(code = print(scatter_2033 / scatter_2034),
       width_svg = 6,
       height_svg = 4,
       options = list(
         opts_hover(css = "fill: #202020;"),
         opts_hover_inv(css = "opacity:0.2;")
         )
       ) 
```

girafe(ggobj=scatter_2033,

width_svg = 6,

height_svg = 6\*0.618

)

## 3.7 Treemap of business relationship between shipping and receiving companies

We have almost come to the end of this exercise. Before we finish, lets build a treemap to get a high level view of the current status of this business (who are the bigger suppliers and their corresponding buyers).

The code chunk below groups the data by from and to columns and aggregating the TotalInteractions and MedianCargoWeight_daily between each pair shipping and receiving company by hscode.

```{r}
seafood_tree <-mc2_seafood_edges_agg_vis %>% 
  group_by(from,to,hscode) %>% 
  summarise(TotalInteractions=sum(Weight),
            MedianCargoWeight_daily= median(Totalweight)) %>% 
  ungroup() %>% 
  arrange(desc(TotalInteractions))
```

The code chunk below plots the treemap using the treemap library.

```{r}
#| fig-width: 12
#| fig-asp: 0.618
tm<- treemap(seafood_tree,
        index=c("from", "to"),
        vSize="TotalInteractions",
        vColor="MedianCargoWeight_daily",
        type="value",
        palette="RdYlBu", 
        algorithm = "squarified",
        title='Shipping and receiving companies interaction pattern',
        title.legend = "Median Cargo Weight per day"
        )
```

The most outer layer refers to shipping companies while the tiles within represents the companies that they shipped their goods to. The bigger the tile size, the more the interaction. The darker the colour, the greater the daily median cargo weight.

The largest player here is 'Playa del Tesoro OJSC' (no pun intended) and it ships in high frequency and large volume mainly to one receiving compmany called 'Fresh Wharf SRL Consulting' over the years 2028 to 2034.

## 3.7 Interactive graph grouped by community

Are there communities inside this network graph?

The group_edge_betweenness() function is typically used in community detection algorithms, such as the Girvan-Newman algorithm. It is a top down approach by calculating the edge betweenness centrality for each edge in the graph (in each iteration) and progressively removes the edges with the highest betweenness centrality until the desired number of communities is reached. The `n` parameter specifies the number of edges to remove. The more times we cut an edge, the more communities we get. I have specified for 20 cuts, however 10 communities were detected.

I am not very certain at the number of communities I should get, in R shiny, we could set `n` as an interactive component for users to play with. The tags obtained from community detection could be analysed with the nodes attributes.

```{r}
#| fig-width: 12
#| fig-asp: 0.618

# let the community community column be called group column
nodes_seafood_vis <- nodes_seafood_vis %>% 
  rename(out_deg_grp = group) %>% 
  rename(group = community)


visNetwork(nodes_seafood_vis,
           mc2_seafood_edges_agg_vis,
           main = "Seafood graph grouped by Communities",
           height = "500px", width = "100%") %>%
  visIgraphLayout(layout = "layout_nicely") %>%
  visEdges(arrows = 'to',
           smooth = list(enables = TRUE,
                         type= 'curvedCW'),
           shadow = FALSE,
           dash = FALSE) %>% 
  visOptions(highlightNearest = list(enabled = T, degree = 1, hover = T),
             nodesIdSelection = TRUE,
             selectedBy = "shpcountry") %>%
  visInteraction(hideEdgesOnDrag = TRUE) %>% 
  #visLegend() %>%
  visLayout(randomSeed = 123)
```

```{r}
#| eval: false
#| echo: false
saveRDS(mc2_seafood_edges_agg_vis, "C:/yixin-neo/ISSS608-VAA/Project/data/mc2_seafood_edges_agg_vis.rds")
```

# 4 References

Hohenfeld, F. (2021, August 12). Graphs Are Fun: An Introduction to Graphs in R. Hohenfeld.is. Retrieved from **https://hohenfeld.is/posts/graphs-are-fun-an-introduction-to-graphs-in-r/**

On ggraph edgelink
R Core Team. (2021, September 13). ggraph: A Grammar of Graphics for Graphs and Networks. The Comprehensive R Archive Network (CRAN). Retrieved from <https://cran.r-project.org/web/packages/ggraph/vignettes/Edges.html>

[Visnetwork]{.underline}
Datastorm-Open. (n.d.). visNetwork. GitHub Pages. Retrieved from http://datastorm-open.github.io/visNetwork/

Horizon plot

Rivasiker, G. (n.d.). ggHoriPlot: Interactive Horizon Plot for R. GitHub Pages. Retrieved from <https://rivasiker.github.io/ggHoriPlot/>
