---
title: "Take-home_Ex02"
author: "NeoYX"
date: '15 May 2023'
date-modified: "`r Sys.Date()`"
editor: visual
execute: 
  freeze: auto
  warning: false
  echo: true
  message: true
format:
  html:
    code-fold: true
    code-overflow: scroll
    code-summary: "Show the code"
    code-line-numbers: true
---

::: callout-note
**Edge data** should be organised as such: (can use dplyr methods)

First column: Source id (FK to Node second column) - compulsory

Second column: Target id (FK to Node second column) - compulsory

**Node data**

First column: ID (contains all the distinct values of source and target in Edge data) - compulsory

-   Nodes present in edge data must exists in ID of node data, must not have missing in node ID.

Second column: Label (only need if Id are all integers)
:::

::: callout-warning
Try not to use R built-in NA/NULL function. Manually type "unknown' / 'missing' as a value instead.
:::

# Vast Challenge 2023 Mini Challenge 2 (Subtask: 1)

In this challenge, my group and I seek to use visual analytics to identify temporal patterns for individual entities and between entities using the knowledge graph the FishEye Organisation has provided us with. We will also be categorising the type of business relationship patterns found. The visualisation outputs:

1\) Interactive network graph with nodes coloured by varying range of in-deg and out-deg centrality scores to spot the companies with high / low centrality scores easily.

2\) Horizon plot for top n companies (shipping and receiving) over the years 2028 to 2034 allows us to see all trading activities at one glance. We could try to spot companies with short trading duration.

3\) Using a top receiving company 'Volga River LLC Enterprise' as an example, an interactive time-series chart (line chart) is plot with all of its supplier companies to spot trends and anomalies. We could try to spot receiving companies who keeps changing suppliers with this.

4\) Coordinated and interactive scatterplots of 'number of interactions' and 'partnership duration' between each unique pair of ship-receive companies were plotted. We could try to spot outliers and investigate them!

# 1 About the dataset

## 1.1 Data dictionary

**Node Attributes:**

-   id \-- Name of the company that originated (or received) the shipment

-   shpcountry \-- Country the company most often associated with when shipping

-   rcvcountry \-- Country the company most often associated with when receiving

-   dataset \-- Always 'MC2'

**Edge Attributes:**

-   arrivaldate \-- Date the shipment arrived at port in YYYY-MM-DD format.

-   hscode \-- Harmonized System code for the shipment. Can be joined with the hscodes table to get additional details.

-   valueofgoods_omu \-- Customs-declared value of the total shipment, in Oceanus

-   Monetary Units (OMU)

-   volumeteu \-- The volume of the shipment in 'Twenty-foot equivalent units', roughly how many 20-foot standard containers would be required. (Actual number of containers may have been different as there are 20ft and 40ft standard containers and tankers that do not use containers)

-   weightkg \-- The weight of the shipment in kilograms (if known)

-   dataset \-- Always 'MC2'

-   type \-- Always 'shipment' for MC2

-   generated_by \-- Name of the program that generated the edge. (Only found on 'bundle' records.)

## 1.2 Importing the datasets

Import libraries

The new libraries used today are :

-   `jsonlite` to import json file

```{r}
pacman::p_load(jsonlite, igraph, tidygraph, ggraph,
               visNetwork, lubridate, clock,
               tidyverse, graphlayouts,knitr,plotly, 
               ggHoriPlot, ggthemes,hrbrthemes,treemap,patchwork, ggiraph,
               ggstatsplot)
```

```{r}
MC2 <- jsonlite::fromJSON("C:/yixin-neo/ISSS608-VAA/Project/data/mc2_challenge_graph.json")
```

Pull out the nodes and edge data and save them as tibble data frames.

```{r}
MC2_nodes <- as_tibble(MC2$nodes) %>% 
  select(id,shpcountry,rcvcountry)
```

```{r}
#| echo: false
glimpse(MC2_nodes)
```

Rearranging the columns in edge file as we require `source` and `target` columns to be the first two columns.

```{r}
MC2_edges <- as_tibble(MC2$links) %>% 
  select(source,target,arrivaldate,hscode,valueofgoods_omu,volumeteu,weightkg,valueofgoodsusd)  
# can exclude dataste column as they all contain the same values.
```

```{r}
#| echo: false
glimpse(MC2_edges)
```

# 2 Data cleaning

## 2.1 Lets check for duplicates

For MC2_nodes dataframe:

There are no duplicated nodes, which is great.

```{r}
#| eval: false
# check for any duplicates
any(duplicated(MC2_nodes))
```

For MC2_edges dataframe:

There are about 155291 records (2% out of total records) that are duplicated.

```{r}
#duplicated only
# print(any(duplicated(MC2_edges)))
MC2_edges_dup <- MC2_edges[duplicated(MC2_edges), ]
print(nrow(MC2_edges_dup))
```

We will drop the duplicates.

```{r}
# Drop duplicate rows from the dataframe
MC2_edges_no_dup <- MC2_edges[!duplicated(MC2_edges), ]
```

## 2.2 Check for null values

Check whether each column in MC2_nodes and MC2_edges contains null and prints the percentage of null for each column.

**For MC2_nodes dataframe:**

There are no null values in the id column of Nodes file, which is great.

```{r}
# Check for null values in each column
null_counts_nodes <- sapply(MC2_nodes, function(x) sum(is.null(x) | is.na(x)))

# Calculate the percentage of null values for each column
null_percentages_nodes <- null_counts_nodes / nrow(MC2_nodes) * 100

# Display the results
#print(null_percentages)

knitr::kable(null_percentages_nodes, "simple", col.names = c("Null Percentage"))
```

**For MC2_edges dataframe:**

As there are a lot zeros inside MC2_edges\$volumteu col, we will consider 0 as equivalent to null values.

We can see that the columns `valueofgoods_omu` and `volumeteu` are mainly null. `valueofgoodusd` column contains more than 50% null values. There are 4 records of `source` with 0 as value, but 0 is their unique identifier so we do not consider 0 as null in `source` column. It means to say that only `source`, `target`, `arrivaldate`, `hscode` and `weight` columns will be helpful in our analysis.

```{r}
# Check for null values in each column
null_counts <- sapply(MC2_edges_no_dup, function(x) sum(is.null(x) | is.na(x) | x==0))

# Calculate the percentage of null values for each column
null_percentages <- null_counts / nrow(MC2_edges_no_dup) * 100

# Display the results
#print(null_percentages)

knitr::kable(null_percentages, "simple", col.names = c('Percentage null'))

```

We will be dropping the `valueofgoods_omu` , `valueofgoodusd`and `volumeteu` columns from our dataframe by selecting only the columns that we need.

```{r}
MC2_edges_no_dup <- MC2_edges_no_dup %>% select('source','target', 'arrivaldate', 'hscode','weightkg')
```

### 1.3.3 Check on the HScodes

Check the unique number of hscodes in the dataset. There are 4761 unique HScodes, however many are not related to fishing related activties.

```{r}
# Find the number of unique values in hscode
length(unique(MC2_edges_no_dup$hscode))

```

With reference two websites on "Harmonized System of Nomenclature" namely, [World Custom Organisation Harmonized System codes](https://www.wcoomd.org/en/topics/nomenclature/instrument-and-tools/hs-nomenclature-2022-edition/hs-nomenclature-2022-edition.aspx) and [connect2India](https://connect2india.com/hs-classification.html) , we will filter for records that have HScodes starting with `1604xx`, `1605xx` and `301xxx` to `308xxx` as they refer to seafood commodities, thus removing many other transactions like 'television', 'steel parts' etc... This will help to filter away the noises and help us to focus on trading activities related to the fishing industry.

```{r}
mc2_seafood_edges<- MC2_edges_no_dup[grepl('^1605|^1604|^301|^302|^303|^304|^305|^306|^307|^308', MC2_edges_no_dup$hscode), ]

```

## 2.3 Preparation of Edges

We will perform a group by 'source', 'target' and 'arrivaldate' and aggregate the total count of interactions, 'Weight', between each pair of companies. At this moment, we should not be filtering the records because we would like to calculate the network centrality scores first before zooming into records of interest. As we are interested to see whether there are patterns of self-loops, we will not be removing any company shipping to itself.

```{r}
#unique(mc2_seafood_edges$hscode)
#unique(mc2_seafood_edges$source)
mc2_seafood_edges_agg <- mc2_seafood_edges %>%  
  group_by(source, target,arrivaldate) %>% 
  summarise(weight=n(),
            sum_goods_weightkg = sum(weightkg),
            hscode=first(hscode)) %>% 
  #filter(Weight >=8) %>% 
  ungroup()
```

Let us wrangle the date columns to prepare dataframe for temporal analysis later.

\(1\) change the `arrivaldate` column to date data type

```{r}
mc2_seafood_edges_agg$arrivaldate <- as.Date(mc2_seafood_edges_agg$arrivaldate)

```

\(2\) create year, month, weekday, weeknumber columns

```{r}
mc2_seafood_edges_agg <- mc2_seafood_edges_agg %>% 
  mutate(year = year(arrivaldate)) %>% 
  mutate(month = month(arrivaldate)) %>% 
  mutate(day = day(arrivaldate)) %>% 
  mutate(weekday = wday(arrivaldate,
                        label= TRUE,
                        abbr = FALSE)) %>% 
  mutate(weeknumber = isoweek(arrivaldate))
```

TBC: Inspect the frequency of source and target actors, and remove those actors below a frequency count of 5.

TBC: First , we remove low frequency source actors under 5 counts.

```{r}
#| eval: false
#| echo: false
# Calculate the frequency count of values in 'source'
frequency_table <- table(mc2_seafood_edges_agg$source)

# Get the values in 'source' with a frequency count greater than or equal to 5
valid_source <- names(frequency_table[frequency_table >= 5])

# Subset the dataframe to keep only rows with valid values in 'source'
mc2_seafood_edges_agg <- mc2_seafood_edges_agg[mc2_seafood_edges_agg$source %in% valid_source, ]

```

Next, remove target actors with frequency count less than 5:

```{r}
#| eval: false
#| echo: false
# Calculate the frequency count of values in 'source'
frequency_table <- table(mc2_seafood_edges_agg$target)

# Get the values in 'col1' with a frequency count greater than or equal to 5
valid_target <- names(frequency_table[frequency_table >= 5])

# Subset the dataframe to keep only rows with valid values in 'col1'
mc2_seafood_edges_agg <- mc2_seafood_edges_agg[mc2_seafood_edges_agg$target %in% valid_target, ]


# Print the filtered dataframe
#print(mc2_seafood_edges_agg)
```

TBC: For community detection, we will try to remove the disconnected components of the graph so that as to detect groups within the connected component. Using the interactive network graph created earlier, there were several pairs of actors that exist as disconnected components. They are 'Rift Valley fishery OJSC', 'Bujagali Falls Pic Family', 'Neptune's Realm NV Navigation', 'Rybachit Sagl and Son's', 'Mar de la Aventura Rybachit' and 'Olas del Sur Ltd'. Lets remove the edge records if either `source` or `target` columns contains any of these four nodes.

```{r}
# Specify the values to be excluded
#values_to_exclude <- c('Rift Valley fishery OJSC', 'Bujagali Falls Pic Family', 'Neptune\'s Realm NV Navigation', 'Rybachit Sagl and Son\'s', 'Mar de la Aventura Rybachit', 'Olas del Sur Ltd')

# Delete rows with specified values in 'from' or 'to' columns
#mc2_seafood_edges_agg <- mc2_seafood_edges_agg %>%
  #filter(!(source %in% values_to_exclude | target %in% values_to_exclude))

# Display the updated data frame
#print(mc2_seafood_edges_agg)

```

```{r}
#| eval: false
#| echo: false
#sort(table(mc2_seafood_edges_agg$target))
```

## 2.4 Preparation of Nodes

We will include only nodes that are in 'source' and 'target' columns in the `mc2_seafood_edges_agg` dataframe after the first round of data filtering.

```{r}
nodes_seafood <- MC2_nodes %>%
  filter (id %in% c(mc2_seafood_edges_agg$source, mc2_seafood_edges_agg$target))
```

## 2.5 Creating the network graph dataframe using tbl_graph() of the tidygraph package.

::: callout-note
Node file needs to have ID of nodes as first column.

Edge file need to contain source and target as column 1 and 2.
:::

To create the network graph dataframe

```{r}
seafood_graph<- tbl_graph(nodes=nodes_seafood,
                          edges = mc2_seafood_edges_agg,
                          directed = TRUE)
```

The dataframe 'seafood_graph' has 11539 nodes with 374709 edges. It is a directed graph with 214 components.

```{r}
#| echo: false
seafood_graph
```

Running the code chunk below to confirm that 'seafood_graph' is not a connected graph.

```{r}
is.connected(seafood_graph)
```

## 2.6 Calculate the various centrality measures of seafood_graph.

The top 10 nodes with reference to various centrality scores are printed using `kable()` function from `knitr`.

Reference was made from this [link](https://hohenfeld.is/posts/graphs-are-fun-an-introduction-to-graphs-in-r/). The tidyverse centrality functions can be taken from [here](https://cran.r-project.org/web/packages/tidygraph/tidygraph.pdf).

First compute 'betweenness', 'in-deg' and 'out-deg' and 'pagerank' scores. All my betweenness scores were zero (Investigation in progress)...

```{r}
seafood_graph<- seafood_graph %>%
  activate("nodes") %>% 
  mutate(betweenness_centrality = centrality_betweenness(directed = TRUE)) %>% 
  mutate(in_deg_centrality = centrality_degree(weights = weight, 
                                               mode = "in")) %>% 
  mutate(out_deg_centrality = centrality_degree(weights = weight, 
                                               mode = "out")) %>% 
  mutate(pagerank = centrality_pagerank(weights = weight,
                                        directed = TRUE)) #%>% 
  #mutate(community = as.factor(group_edge_betweenness(weights = Weight, 
                                                      #directed = TRUE,
                                                      #n = 10)))

```

Let us take a look at the top 10 nodes with high 'betweenness' centrality scores:

```{r}
#| eval: false
#| echo: false
seafood_graph %>% 
  activate("nodes") %>% 
  as_tibble() %>% 
  arrange(desc(betweenness_centrality)) %>% 
  select(id,betweenness_centrality) %>% 
  head(n=20) %>% 
  kable()
```

To see the top 20 nodes with 'out-deg' scores:

```{r}
#| eval: false
#| echo: false
seafood_graph %>% 
  activate("nodes") %>% 
  as_tibble() %>% 
  arrange(desc(out_deg_centrality)) %>% 
  select(id,out_deg_centrality) %>% 
  head(n=20) %>% 
  kable()
```

```{r}
#| eval: false
#| echo: false
#| fig-width: 12
#| fig-asp: 0.618
set.seed (1234)
a <- ggraph(seafood_graph, layout = 'fr') +
  geom_edge_link(aes(width=Weight, alpha= 0.2),
                 arrow = arrow(length = unit(2, 'mm')), #<<< delete
                 end_cap = circle(1, 'mm')) +           #<<< delete
  scale_edge_width(range = c(0.1, 5)) +
  geom_node_point(aes(size = in_deg_centrality, colour=rcvcountry)) +
  geom_edge_loop()

a + theme_graph()

```

```{r}
#| eval: false
#| echo: false
#| fig-width: 12
#| fig-asp: 0.618

set.seed (1234)
b <- seafood_graph %>%
  mutate(community = as.factor(group_edge_betweenness(weights = Weight, 
                                                      directed = TRUE,
                                                      n = 20))) %>%
  ggraph(layout = "fr") + 
  geom_edge_link(aes(width=Weight), 
                 alpha=0.2) +
  scale_edge_width(range = c(0.1, 5)) +
  geom_node_point(aes(colour = community))  

b  + theme_graph() + theme(legend.key.size = unit(1, "lines"),
          legend.position = 'bottom')

```

# 3 Interactive graphs of network structure, temporal analysis and business patterns detection

## 3.1 Interactive graph grouped by IN-DEGREE CENTRALITY scores

Obtain the list of top 20 in deg companies

```{r}
 top_20_in_list <- seafood_graph %>% 
  activate("nodes") %>% 
  as_tibble() %>% 
  arrange(desc(in_deg_centrality)) %>% 
  top_n(20,wt = in_deg_centrality) %>%
  pull(id)
 
 #kable(top_20_in_list, col.names=c('Top 20 in-deg companies'))
```

Preparing the edges dataframe by filtering to keep only nodes in the top 20 in-deg centrality list above. To further reduce the number of nodes, we will also remove records when the 'weight' column of these nodes is less than 10. There are 3196 edges after this step.

```{r}
# Subset the dataframe to keep only rows with valid values (top 20 in-deg) in 'target' column
mc2_seafood_edges_agg_in <- mc2_seafood_edges_agg[mc2_seafood_edges_agg$target %in% top_20_in_list, ]

# further removal of records where 'weight' column is less than  10
mc2_seafood_edges_agg_in <- mc2_seafood_edges_agg_in %>% 
  filter(weight>=8)
```

Prepare the nodes dataframe by including nodes found only in the 'from' and 'target' columns in 'mc2_seafood_edges_agg_in' edge file. There are 288 nodes after this step.

```{r}
nodes_seafood_in <- as.data.frame(seafood_graph %>% activate(nodes))

nodes_seafood_in <- nodes_seafood_in %>%
  filter (id %in% c(mc2_seafood_edges_agg_in$source, mc2_seafood_edges_agg_in$target))
```

We first need to rename the edge file first two columns to `from` and `to` for visNetwork to be able to regconise them. `title` column has been created for tooltip when we hover over each of the edges.

```{r}
mc2_seafood_edges_agg_vis_in <- mc2_seafood_edges_agg_in %>% 
  rename(from = source) %>% 
  rename(to = target) %>% 
  mutate(title = paste('Total Weight = ',sum_goods_weightkg, "\n HSCODE =", hscode))
```

The code chunk below extracts the node table from tbl_graph() object 'seafood_graph' created earlier. The reason for donig so is because it contains the centrality values that were calculated using the tidyverse centrality functions.

Next, add a column `title` because it is the column that VisNetwork will search for to display tooltip when the mouse hovers over the nodes. We will be displaying the 'in-deg', 'betweenness' and 'out-deg' scores in the tooltip. If we want to colour the nodes by their shipping countries, then we would have to rename the `shpcountry` column to `group` because visNetwork looks for `group` column to colour the nodes. However, we will not do this now.

```{r}
# extract nodes file from seafood_graph as a data frame
#nodes_seafood_vis <- as.data.frame(seafood_graph %>% activate(nodes))

# further processing
nodes_seafood_vis_in <- nodes_seafood_in %>% 
  #rename(group= rcvcountry)  %>% 
  mutate(pagerank = round(pagerank, 5)) %>% 
  mutate(title = paste('shpcountry =', shpcountry, ',',
                       'rcvcountry =', rcvcountry, ',',
                       '\n In-deg = ',in_deg_centrality, ',',
                       "\n Betweenness =", betweenness_centrality, ',',
                       "\n Out-deg =", out_deg_centrality))

```

The code chunk below binned the in-deg scores into intervals using the `cut()` function. Next, rename the `in_deg_grp` column to `group` column for VisNetwork to colour nodes by in-deg intervals.

```{r}
in_deg_brks <- c(0, 10000, 20000,30000,40000,50000, 60000,70000)
grps <- c('10,000 & Below','10,001-20,000', '20,001-30,000', '30,001-40,000','40,001-50,000', '50,001-60,000','60,001-70,000')

nodes_seafood_vis_in$in_deg_grp <- cut(nodes_seafood_vis_in$in_deg_centrality, breaks=in_deg_brks, labels = grps,include.lowest = TRUE)

#nodes_seafood_vis_in$in_deg_grp <- factor(nodes_seafood_vis$in_deg_grp, ordered = TRUE, levels = c('3001-6132','2001-3000','1001-2000','501-1000','500 & Below'))

nodes_seafood_vis_in <- nodes_seafood_vis_in %>% 
  rename(group = in_deg_grp)
```

The code chunk below plots in interactive network graph using visNetwork.

```{r}
#| fig-width: 12
#| fig-asp: 0.618
visNetwork(nodes_seafood_vis_in,
           mc2_seafood_edges_agg_vis_in,
           main = "Seafood graph grouped by In-Deg centrality intervals",
           height = "500px", width = "100%") %>%
  visIgraphLayout(layout = "layout_nicely") %>%
  visEdges(arrows = 'to',
           smooth = list(enables = TRUE,
                         type= 'straightCross'),
           shadow = FALSE,
           dash = FALSE) %>% 
  visOptions(highlightNearest = list(enabled = T, degree = 1, hover = T),
             nodesIdSelection = TRUE,
             selectedBy = "group") %>%
  visInteraction(hideEdgesOnDrag = TRUE) %>% 
  visLegend() %>%
  visLayout(randomSeed = 123)
```

::: callout-note
Interactivity features of this graph

\(1\) Select Id dropdown list

\(2\) Select Group dropdown list: The values inside refers to the range of 'in-deg' centrality scores of the nodes. The pink colour node will represent the highest in-deg centrality score, followed by green, yellow, red and blue.

\(3\) Zoom in to see the node labels, and arrows direction.

\(4\) Drag a particular node away from the cluster to admire it.

\(5\) Hover mouse over a node will display tooltip (shpcountry, rcvcountry, In-deg, pagerank and out-deg score). It will also display the 'ego' network with itself at the ego. Click on the node to freeze the ego network. Click on blank space to reset.

\(6\) Hovering the mouse over an edge will display tooltip (Total weight of cargo, hscode of cargo)

\(7\) Click and Drag on the graph to move the canvas around, will also temporary disable the edge lines.
:::

Try selecting '50,001 to 60,000' from the group drop down list, we will see two companies with similar range of 'in-deg' centrality scores. The company with the highest 'in-deg' centrality score is 'Mar del Este CJSC', that has interactions with a lot of supplier companies. The table below shows the names of the top 5 in-deg companies.

```{r}
seafood_graph %>% 
  activate("nodes") %>% 
  as_tibble() %>% 
  arrange(desc(in_deg_centrality), desc(pagerank)) %>% 
  select(id,in_deg_centrality,pagerank) %>% 
  head(n=3) %>% 
  kable()
```

## 3.2 Temporal analysis of top 20 'in-deg' centrality companies in trading occurrence over the years

Use the code chunk below to compute the sum of monthly weights.

```{r}
hm <- mc2_seafood_edges_agg_vis_in %>%
  mutate(month = floor_date(arrivaldate, unit = "month")) %>%
  group_by(to, month) %>%
  summarise(total_weight_by_month = sum(weight)) %>% 
  ungroup() 

hm <- hm  %>%  group_by(to) %>%
  mutate(maxweightmonth = as.Date(month[which.max(total_weight_by_month)])) %>%
  ungroup()
```

Now lets plot heatmap

```{r}
#| fig-width: 12
#| fig-asp: 0.618
plotfrom <- "2028-01-02"
plotto <- '2034-01-02'

ggplot(hm, aes(x = month, y = fct_reorder(to, maxweightmonth), fill = total_weight_by_month)) +
  geom_tile(colour="White", show.legend=FALSE) +
  scale_fill_distiller(palette="Spectral") +
  scale_y_discrete(name="", expand=c(0,0))+
  scale_x_date(name="Arrival Date", 
               limits=as.Date(c(plotfrom, plotto)), 
               expand=c(0,0),date_breaks = "1 year", 
               date_labels = "%Y") +
  labs(title="Heatmap of shipping interactions",
       subtitle=paste0("Top receiving companies from ", 
                       plotfrom, ' to ', plotto)) +
  theme_classic() +
  
  theme(axis.line.y=element_blank(), plot.subtitle=element_text(size=rel(0.78)),
        plot.title.position="plot",
        axis.text.y=element_text(colour="Black",size=5), 
        plot.title=element_text(size=rel(2.3)))
```

Analysis of the plot above:

The first observation from the chart above is that not all receiving companies have interactions throughout the months and years. For example, '3 Oceanography' and 'Sailors and Surfers' - why do they only have interactions with their suppliers in certain months?

## 3.3 Trading patterns of Pao gan SE Seal

Let us examine the trading patterns of 'Pao gan SE Seal', one of the few top leading companies in terms of ''in-deg' with four out of its many suppliers (as seen from the interactive graph).

First, filter records with only Volga River LLC Enterprises and its suppliers.

```{r}
paogan_in_df<- mc2_seafood_edges_agg_vis_in %>%
  filter(to %in% 'Pao gan SE Seal')
```

Next, plot a time series using `geom_line()` and `geom_point_interactive()`.

```{r}
#| fig-width: 12
#| fig-height: 30
paogan_in_df <-  paogan_in_df %>%
  mutate(tooltip = paste0('# of interaction: ', weight, '\nDate :', arrivaldate))

 
paogan_in_df1<- ggplot(paogan_in_df %>%
                          filter(from=='Paradera S.A. de C.V.'),
                        aes(x=arrivaldate, y=weight)) +
  geom_line( color="steelblue", size = 0.8) +
  geom_point_interactive(aes(tooltip= tooltip), 
                         size = 0.5) +
  xlab("") +
  theme_light() +
  theme(#panel.spacing = unit(2, "lines"),
        axis.text.x=element_text(angle=60, hjust=1),
        panel.grid.major.x = element_blank(),
        axis.title.y = element_text(size = 10)) +
  scale_x_date(
    breaks = seq(as.Date("2028-01-01"), as.Date("2034-12-31"), by = "3 months"),
    limits = c(as.Date("2028-01-01"), as.Date("2034-12-31")),
    labels = function(x) format(x, "%b %Y")) +
  scale_y_continuous(
    limits = c(0, 100), 
    breaks = seq(0, 100, by = 20),
    expand = c(0, 0)) +
  
  labs(title='Paradera S.A. de C.V.', 
       x = 'Date',
       y='Number of trading occurrence')

paogan_in_df2<- ggplot(paogan_in_df %>% filter(from=='Greek Octopus SRL Logistics'), aes(x=arrivaldate, y=weight)) +
  geom_line( color="steelblue", size = 0.8) + 
  geom_point_interactive(aes(tooltip= tooltip),
                         size = 0.5) +
  xlab("") +
  theme_light() +
  theme(#panel.spacing = unit(2, "lines"),
        axis.text.x=element_text(angle=60, hjust=1),
        panel.grid.major.x = element_blank(),
        axis.title.y = element_text(size = 10)) +
  scale_x_date(
    breaks = seq(as.Date("2028-01-01"), as.Date("2034-12-31"), 
                 by = "3 months"),
    limits = c(as.Date("2028-01-01"), as.Date("2034-12-31")),
    labels = function(x) format(x, "%b %Y")) +
  scale_y_continuous(
    limits = c(0, 100),  # Set the y-axis limits
    breaks = seq(0, 100, by = 20),  # Set the y-axis breaks at intervals of 5
    #minor_breaks = seq(0, 30, by = 1),  # Set the y-axis minor breaks at intervals of 1
    expand = c(0, 0)) +  # Remove padding around the y-axis limits

      
  labs(title='Greek Octopus SRL Logistics', 
       x = 'Date',
       y='Number of trading occurrence')


paogan_in_df3<- ggplot(paogan_in_df %>% filter(from=='Madhya Pradesh  Market LLC'), aes(x=arrivaldate, y=weight)) +
  geom_line( color="steelblue", size = 0.8) + 
  geom_point_interactive(aes(tooltip= tooltip),
                         size = 0.5) +
  xlab("") +
  theme_light() +
  theme(#panel.spacing = unit(2, "lines"),
        axis.text.x=element_text(angle=60, hjust=1),
        panel.grid.major.x = element_blank(),
        axis.title.y = element_text(size = 10)) +
  scale_x_date(
    breaks = seq(as.Date("2028-01-01"), as.Date("2034-12-31"), by = "3 months"),
    limits = c(as.Date("2028-01-01"), as.Date("2034-12-31")),
    labels = function(x) format(x, "%b %Y")) +
  scale_y_continuous(
    limits = c(0, 100),
    breaks = seq(0, 100, by = 20), 
    expand = c(0, 0)) +
  
  labs(title='Madhya Pradesh  Market LLC', 
       x = 'Date',
       y='Number of trading occurrence')

paogan_in_df4<- ggplot(paogan_in_df %>% filter(from=='Sea Breezes S.A. de C.V. Freight '), aes(x=arrivaldate, y=weight)) +
  geom_line( color="steelblue", size = 0.8) + 
  geom_point_interactive(aes(tooltip= tooltip),
                         size = 0.5) +
  xlab("") +
  theme_light() +
  theme(#panel.spacing = unit(2, "lines"),
        axis.text.x=element_text(angle=60, hjust=1),
        panel.grid.major.x = element_blank(),
        axis.title.y = element_text(size = 10)) +
  scale_x_date(
    breaks = seq(as.Date("2028-01-01"), as.Date("2034-12-31"), by = "3 months"),
    limits = c(as.Date("2028-01-01"), as.Date("2034-12-31")),
    labels = function(x) format(x, "%b %Y")) +
  scale_y_continuous(
    limits = c(0, 100), 
    breaks = seq(0, 100, by = 20),  
    expand = c(0, 0)) +
  labs(title='Sea Breezes S.A. de C.V. Freight ', 
       x = 'Date',
       y='Number of trading occurrence')

girafe(code = print(paogan_in_df1 /paogan_in_df2 /paogan_in_df3 /paogan_in_df4),
       #width_svg = 6,
       height_svg =8,
       options = list(
         opts_hover(css = "fill: #202020;"),
         opts_hover_inv(css = "opacity:0.2;")
         )
       ) 
```

Analysis of the plot above: Throughout the years, 'Pao gan SE Seal' has interactions many suppliers but some of these relationships are short term. . It dawned on me that we can identify IUU companies that frequently close down and re-register their companies from the tpye of plot above. For such companies, I would expect the buyer's graph to show that buyer has been changing suppliers very frequently.

For our group project we can consider creating drop down list of 'buying companies' for user to interact with and see each of the buyer's interaction with their top n suppliers over the years. A coordinated view can be created with social network graph such that when a buyer / supplier node is selected on the network graph, its trading activity over time with top n suppliers/ buyers is automatically generated.

## 3.4 Interactive graph grouped by OUT-DEGREE CENTRALITY scores

Let us get the top 20 company names in terms of out-deg centrality scores.

```{r}
top_20_out_list <- seafood_graph %>% 
  activate("nodes") %>% 
  as_tibble() %>% 
  arrange(desc(out_deg_centrality)) %>% 
  top_n(20, wt = out_deg_centrality) %>%
  pull(id)
#kable(top_20_out_list, col.names=c('Top 20 out-deg companies'))
```

Preparing the edges dataframe by filtering to keep only nodes in the top 20 out-deg centrality list above. To further reduce the number of nodes, we will also remove records when the 'weight' column of these nodes is less than 10. There are 3938 edges after this step.

```{r}
# Subset the dataframe to keep only rows with valid values (top 20 out-deg) in 'from' column
mc2_seafood_edges_agg_out <- mc2_seafood_edges_agg[mc2_seafood_edges_agg$source %in% top_20_out_list, ]

# further removal of records where 'weight' column is less than  10
mc2_seafood_edges_agg_out <- mc2_seafood_edges_agg_out %>% 
  filter(weight>=8)
```

The first code chunk below extracts the 'nodes' table from tbl_graph() object 'seafood_graph' created earlier. The reason for doing so is because it contains the out-deg centrality values that were calculated using the tidyverse centrality functions. We would like to trim this nodes list to contain only companies in edges file.

Prepare the nodes dataframe by including nodes found only in the 'from' and 'target' columns in 'mc2_seafood_edges_agg_out' edge file. There are 288 nodes after this step.

```{r}
nodes_seafood_out <- as.data.frame(seafood_graph %>% activate(nodes))

nodes_seafood_out <- nodes_seafood_out %>%
  filter (id %in% c(mc2_seafood_edges_agg_out$source, mc2_seafood_edges_agg_out$target))
```

Rename the edge file's first two columns to `from` and `to` for visNetwork to be able to regconise them. `title` column has been created for tooltip when we hover over each of the edges.

```{r}
mc2_seafood_edges_agg_vis_out <- mc2_seafood_edges_agg_out %>% 
  rename(from = source) %>% 
  rename(to = target) %>% 
  mutate(title = paste('Total Weight = ',sum_goods_weightkg, "\n HSCODE =", hscode))
```

Next, add a column title because it is the column that VisNetwork will search for to display tooltip when the mouse hovers over the nodes. We will be displaying the 'in-deg', 'betweenness' and 'out-deg' scores in the tooltip.

```{r}
# extract nodes file from seafood_graph as a data frame

# further processing
nodes_seafood_vis_out <- nodes_seafood_out %>% 
  #rename(group= rcvcountry)  %>% 
  mutate(pagerank = round(pagerank, 5)) %>% 
  mutate(title = paste('shpcountry =', shpcountry, ',',
                       'rcvcountry =', rcvcountry, ',',
                       '\n In-deg = ',in_deg_centrality, ',',
                       "\n Betweenness =", betweenness_centrality, ',',
                       "\n Out-deg =", out_deg_centrality))
```

The code chunk below binned the out-deg scores into intervals using the `cut()` function. Next, rename the `group` column back to `in-deg` column followed by `out_deg_grp` column to `group` column for VisNetwork to colour nodes by out-deg intervals.

```{r}
out_deg_brks <- c(0,10000, 20000, 30000)
grps <- c('10,000 & Below','10,001-20,001', '20,001-27,570')

nodes_seafood_vis_out$out_deg_grp <- cut(nodes_seafood_vis_out$out_deg_centrality, breaks=out_deg_brks, labels = grps,include.lowest = TRUE)


nodes_seafood_vis_out <- nodes_seafood_vis_out %>% 
  rename(group = out_deg_grp)
```

The code chunk below plots the interactive graph.

```{r}
#| fig-width: 12
#| fig-asp: 0.618
visNetwork(nodes_seafood_vis_out,
           mc2_seafood_edges_agg_vis_out,
           main = "Seafood graph grouped by Out-Deg centrality intervals",
           height = "500px", width = "100%") %>%
  visIgraphLayout(layout = "layout_nicely") %>%
  visEdges(arrows = 'to',
           smooth = list(enables = TRUE,
                         type= 'curvedCW'),
           shadow = FALSE,
           dash = FALSE) %>% 
  visOptions(highlightNearest = list(enabled = T, degree = 1, hover = T),
             nodesIdSelection = TRUE,
             selectedBy = "group") %>%
  visInteraction(hideEdgesOnDrag = TRUE) %>% 
  visLegend() %>%
  visLayout(randomSeed = 123)
```

The chart highlights actors with high out-deg centrality scores over 2028 to 2034. In this default view, we can quickly identify the 2 coloured nodes as top 2 suppliers.

## 3.5 Temporal analysis of top 20 'out-deg' centrality companies in trading occurrence over the years

Use the code chunk below to compute the sum of monthly weights (total monthly shipping interactions of each company.

```{r}
hm <- mc2_seafood_edges_agg_vis_out %>%
  mutate(month = floor_date(arrivaldate, unit = "month")) %>%
  group_by(from, month) %>%
  summarise(total_weight_by_month = sum(weight)) %>% 
  ungroup() 

hm <- hm  %>%  group_by(from) %>%
  mutate(maxweightmonth = as.Date(month[which.max(total_weight_by_month)])) %>%
  ungroup()
```

We will now plot the heatmap of top 20 out-deg companies to show their shipping interactions over the years.

```{r}
#| fig-width: 12
#| fig-asp: 0.618
plotfrom <- "2028-01-02"
plotto <- '2034-01-02'

ggplot(hm, aes(x = month, y = fct_reorder(from, maxweightmonth), fill = total_weight_by_month)) +
  geom_tile(colour="White", show.legend=FALSE) +
  scale_fill_distiller(palette="Spectral") +
  scale_y_discrete(name="", expand=c(0,0))+
  scale_x_date(name="Arrival Date", 
               limits=as.Date(c(plotfrom, plotto)), 
               expand=c(0,0),date_breaks = "1 year", 
               date_labels = "%Y") +
  labs(title="Heatmap of shipping interactions",
       subtitle=paste0("Top supplier companies from ", 
                       plotfrom, ' to ', plotto)) +
  theme_classic() +
  
  theme(axis.line.y=element_blank(), plot.subtitle=element_text(size=rel(0.78)),
        plot.title.position="plot",
        axis.text.y=element_text(colour="Black",size=5), 
        plot.title=element_text(size=rel(2.3)))
```

Analysis of the plot above:

At a quick glance, three companies are hot, they are 'nian yu Ltd Corporation' ,'Playa del Tesoro OJSC'. and 'Sea Breezes SA'.

'nian yu Ltd Corporation' had several instances of very high shipping activities in 2031 and 2032, which is worth looking into.

There are also some supplier companies that do not have shipping interactions frequently. What is their main business? How are they involved in the fishing industry actually?

### 3.5.1 Treemap of business relationship between shipping and receiving companies

Finally, lets build a treemap to get a high level view of the current status of this business network (who are the bigger suppliers and their corresponding buyers).

The code chunk below groups the data by from and to columns and aggregating the TotalInteractions and MedianCargoWeight_daily between each pair shipping and receiving company by hscode.

```{r}
seafood_tree <-mc2_seafood_edges_agg_vis_out %>% 
  group_by(from,to,hscode) %>% 
  summarise(TotalInteractions=sum(weight),
            MedianCargoWeight_daily= median(sum_goods_weightkg)) %>% 
  ungroup() %>% 
  arrange(desc(TotalInteractions))

```

The code chunk below plots the treemap using the treemap library.

```{r}
#| fig-width: 12
#| fig-asp: 0.618
tm<- treemap(seafood_tree,
        index=c("from", "to"),
        vSize="TotalInteractions",
        vColor="MedianCargoWeight_daily",
        type="value",
        palette="RdYlBu", 
        algorithm = "squarified",
        title='Shipping and receiving companies interaction pattern',
        title.legend = "Median Cargo Weight per day"
        )

```

The most outer layer refers to shipping companies while the tiles within represents the companies that they shipped their goods to. The bigger the tile size, the more the interaction. The darker the colour, the greater the daily median cargo weight.

The largest player here is 'nian yu Ltd Corporation' .

'Playa del Tesoro OJSC' is the second ranked in terms of out-deg centrailty and it ships in high frequency and large volume mainly to one receiving company called 'Fresh Wharf SRL Consulting' over the years 2028 to 2034.

## 3.6 Correlationship between partnership intervals (in days) and total number of interactions between company pairs

In this section, lets examine whether there is a correlationship between the `interval of interaction within a year` and the `number of interactions` between each pairs of companies. Will there be companies with short partnership duration and high number of interactions (e.g. shipping in high frequency for only 1 week within a year) ?

We will prepare the dataframe needed for the plot.

First, for each group of `from`, `to`, `year`:

1\) `partnership_days` : the number of days within the year that each pair of companies had interactions

2\) `total_interaction` : sum of all the Weights between each pair of companies

```{r}
cor <- mc2_seafood_edges_agg_vis_in %>% 
  group_by(from, to,year) %>% 
  summarise(partnership_days=as.integer(max(arrivaldate)-min(arrivaldate)+1),
            total_interaction = sum(weight),
            median_interaction = median(weight)) %>% 
  ungroup() %>% 
  arrange(partnership_days)
```

### 3.6.1 Checking for statistical significance in correlationship

```{r}
#| fig-width: 12
#| fig-asp: 0.618
library(scales)
correl_2028 <- ggscatterstats(data = cor %>% filter(year==2028), 
                           x = partnership_days, y = total_interaction,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 365), 
                     breaks=seq(0, 365, 30), 
                     labels= comma) + 
  scale_y_continuous(limits = c(0, 1250), 
                     breaks=seq(0, 1250, 250), 
                     labels= comma) +
  
  labs(title = "Number of interactions and partnership duration in 2028", 
       x = "Partnership days", y = "Total interactions") 

correl_2029 <- ggscatterstats(data = cor %>% filter(year==2029), 
                           x = partnership_days, y = total_interaction,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 365), 
                     breaks=seq(0, 365, 30), 
                     labels= comma) + 
  scale_y_continuous(limits = c(0, 1250), 
                     breaks=seq(0, 1250, 250), 
                     labels= comma) +
  
  labs(title = "Number of interactions and partnership duration in 2029", 
       x = "Partnership days", y = "Total interactions") 


correl_2030 <- ggscatterstats(data = cor %>% filter(year==2030), 
                           x = partnership_days, y = total_interaction,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 365), 
                     breaks=seq(0, 365, 30), 
                     labels= comma) + 
  scale_y_continuous(limits = c(0, 1250), 
                     breaks=seq(0, 1250, 250), 
                     labels= comma) +
  
  labs(title = "Number of interactions and partnership duration in 2030", 
       x = "Partnership days", y = "Total interactions") 


correl_2031 <- ggscatterstats(data = cor %>% filter(year==2031), 
                           x = partnership_days, y = total_interaction,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 365), 
                     breaks=seq(0, 365, 30), 
                     labels= comma) + 
  scale_y_continuous(limits = c(0, 1250), 
                     breaks=seq(0, 1250, 250), 
                     labels= comma) +
  
  labs(title = "Number of interactions and partnership duration in 2031", 
       x = "Partnership days", y = "Total interactions") 


correl_2032 <- ggscatterstats(data = cor %>% filter(year==2032), 
                           x = partnership_days, y = total_interaction,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 365), 
                     breaks=seq(0, 365, 30), 
                     labels= comma) + 
  scale_y_continuous(limits = c(0, 1250), 
                     breaks=seq(0, 1250, 250), 
                     labels= comma) +
  
  labs(title = "Number of interactions and partnership duration in 2032", 
       x = "Partnership days", y = "Total interactions") 


correl_2033 <- ggscatterstats(data = cor %>% filter(year==2033), 
                           x = partnership_days, y = total_interaction,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 365), 
                     breaks=seq(0, 365, 30), 
                     labels= comma) + 
  scale_y_continuous(limits = c(0, 1250), 
                     breaks=seq(0, 1250, 250), 
                     labels= comma) +
  
  labs(title = "Number of interactions and partnership duration in 2033", 
       x = "Partnership days", y = "Total interactions") 



correl_2034 <- ggscatterstats(data = cor %>% filter(year==2034), 
                           x = partnership_days, y = total_interaction,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 365), 
                     breaks=seq(0, 365, 30), 
                     labels= comma) + 
  scale_y_continuous(limits = c(0, 1250), 
                     breaks=seq(0, 1250, 250), 
                     labels= comma) +
  
  labs(title = "Number of interactions and partnership duration in 2034", 
       x = "Partnership days", y = "Total interactions") 

# combining plots using patchwork
p_correl <- (correl_2034 + correl_2033) / (correl_2032 + correl_2031) / (correl_2030 + correl_2029) # + plot_spacer() + plot_spacer()
p_correl + plot_annotation(title = "Correlation between Number of interactions and partnership duration (days)", 
                           theme = theme(plot.title = element_text(size = 18),
                                         plot.subtitle = element_text(size = 12))) + plot_layout(ncol = 1, nrow = 3,
                                                                                                 heights = c(2,2))
```

The plots (non-parametric) above has p-values less than 0.05 and it suggests that there is a correlationship between the rank-transformed data of total interactions and partnership duration between companies . The upper outliers pairs of companies could be worth investigating because they have high number of interactions for a particular partnership duration in a year. For example, if a company A had interaction with company B for only 3 months but with exceptionally high number of trading interactions, should both companies be worth investigating?

### 3.6.2 Coordinated and interactive scatterplot

For usability , lets us plot an interactive and coordinate equivalent plot of the above scatterplot chart for the most recent four years 2034, 2033, 2032 and 2031.

First we will prepare the tooltip to be shown.

```{r}
cor <- cor %>%
  mutate(label1 = group_indices(., from, to)) %>% 
  mutate(fromto = paste('From: ', from,
                        'To: ', to)) %>% 
  mutate(tooltip = paste(fromto,
                         '\nTotal interaction: ', total_interaction,
                         '\nPartnership duration: ', partnership_days, 'days'))

```

Next, we will filter and use `geom_point_interactive()` of ggiraph library to plot.

```{r}
#| fig-width: 12
#| fig-asp: 0.618
scatter_2034 <- ggplot(data=cor%>% filter(year==2034),
       aes(x=partnership_days, y=total_interaction)) +
  geom_point_interactive(aes(data_id = label1,
                             tooltip= tooltip),
                         size = 0.8) +
  geom_smooth(method='lm',
              size = 0.5) +
  scale_x_continuous(limits = c(0, 365), breaks = seq(0, 365, 30)) +
  scale_y_continuous(limits = c(0, 1000), breaks = seq(0, 1000, 200)) +

  labs(title = "Scatterplot of # of interactions and Partnership duration in 2034",
       y = "Total interactions",
       x = "Partnership duration") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face ='bold'),
        axis.title = element_text(size = 8, face= 'bold'),
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text = element_text(size = 8))


scatter_2033 <- ggplot(data=cor%>% filter(year==2033),
       aes(x=partnership_days, y=total_interaction)) +
  geom_point_interactive(aes(data_id = label1,
                             tooltip= tooltip),
                         size = 0.8) +
  geom_smooth(method='lm',
              size = 0.5) +
  scale_x_continuous(limits = c(0, 365), breaks = seq(0, 365, 30)) +
  scale_y_continuous(limits = c(0, 1000), breaks = seq(0, 1000, 200)) +

  labs(title = "Scatterplot of # of interactions and Partnership duration in 2033",
       y = "Total interactions",
       x = "Partnership duration") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12,face = 'bold'),
        axis.title = element_text(size = 8, face= 'bold'),
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text = element_text(size = 8))

scatter_2032 <- ggplot(data=cor%>% filter(year==2032),
       aes(x=partnership_days, y=total_interaction)) +
  geom_point_interactive(aes(data_id = label1,
                             tooltip= tooltip),
                         size = 0.8) +
  geom_smooth(method='lm',
              size = 0.5) +
  scale_x_continuous(limits = c(0, 365), breaks = seq(0, 365, 30)) +
  scale_y_continuous(limits = c(0, 1000), breaks = seq(0, 1000, 200)) +

  labs(title = "Scatterplot of # of interactions and Partnership duration in 2032",
       y = "Total interactions",
       x = "Partnership duration") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12,face = 'bold'),
        axis.title = element_text(size = 8, face= 'bold'),
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text = element_text(size = 8))


scatter_2031 <- ggplot(data=cor%>% filter(year==2031),
       aes(x=partnership_days, y=total_interaction)) +
  geom_point_interactive(aes(data_id = label1,
                             tooltip= tooltip),
                         size = 0.8) +
  geom_smooth(method='lm',
              size = 0.5) +
  scale_x_continuous(limits = c(0, 365), breaks = seq(0, 365, 30)) +
  scale_y_continuous(limits = c(0, 1000), breaks = seq(0, 1000, 200)) +

  labs(title = "Scatterplot of # of interactions and Partnership duration in 2031",
       y = "Total interactions",
       x = "Partnership duration") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12,face = 'bold'),
        axis.title = element_text(size = 8, face= 'bold'),
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text = element_text(size = 8))




girafe(code = print(scatter_2034 / scatter_2033 /scatter_2032 /scatter_2031),
       width_svg = 6,
       height_svg = 7,
       options = list(
         opts_hover(css = "fill: #202020;"),
         opts_hover_inv(css = "opacity:0.2;")
         )
       ) 
```

::: callout-note
Features of the chart above

-   Each point in chart represents a pair of companies that ships and receives, hover mouse over to see 'company pair names', 'total interaction' and 'partnership days' inside tooltip

-   If a particular company pair exists in more than one chart , its corresponding point will also be highlighted in the other charts.
:::

If two companies consistently have similar number of interactions within similar partnership days across the years, then there is no issue. Explore the interactive chart to spot pairs of companies with 'solo' occurrence throughout the years and is also one of the outlier pairs. Those pair of companies could be worth investigating.

## 3.7 Comparison of centrality values across shipping countries

In this section, we will compare the centrality values of companies from different countries.

### 3.7.1 Comparison of out-deg centrality between top shipping countries

Let us compute top 5 shipping countries in terms of out-deg centrality scores.

```{r}
nodes_seafood_vis_out %>% 
  group_by(shpcountry) %>% 
  summarise(sum_out_deg = sum(out_deg_centrality)) %>% 
  arrange(desc(sum_out_deg)) %>% 
  head(n=5) %>% kable()
```

The code chunk below filters the top 5 shipping countries and non parametric one way anova test is performed to compare for significance in difference in median of number of interactions between them.

```{r}
#| fig-width: 12
#| fig-asp: 0.618
ggbetweenstats(data = nodes_seafood_vis_out %>% 
                 filter(shpcountry %in% c("Isliandor", "Osterivaria", "Vesperanda", "Mawazam", "Merigrad")),
               x = shpcountry, 
               y = out_deg_centrality,
               xlab = "Shipping Country", ylab = "Out-Deg centrality",
               type = "np", pairwise.comparisons = TRUE, pairwise.display = "s",
               sort = "descending",
               sort.fun = median,
               mean.ci = T, p.adjust.method = "fdr",  conf.level = 0.95,
               title = "Comparison of Median Out-Deg centrality across shipping Countries") +
  scale_y_continuous(limits = c(0, 4000)) +
  theme(axis.title.y=element_text(angle = 0,
                                  vjust=0.9))
```

The P - value is above 0.05, so there is not enough statistical evidence to reject the null hypothesis that the median out-deg centrality scores between top 5 shipping countries are different.

### 3.7.2 Comparison of in-deg centrality between top receiving countries

Let us compute top 5 receiving countries in terms of in-deg centrality scores.

```{r}
nodes_seafood_vis_in %>% 
  group_by(rcvcountry) %>% 
  summarise(sum_in_deg = sum(in_deg_centrality)) %>% 
  arrange(desc(sum_in_deg)) %>% 
  head(n=5)
```

There are only 3 major receiving countries in our filtered dataset .

```{r}
ggbetweenstats(data = nodes_seafood_vis_in %>% filter(rcvcountry %in% c("Jiraputra", "Oceanus",'Coralmarica','Marebak','Mawazam')), x = rcvcountry, y = in_deg_centrality,
               xlab = "Shipping Country", ylab = "In-Deg centrality",
               type = "np", pairwise.comparisons = TRUE, pairwise.display = "s",
               sort = "descending",
               sort.fun = median,
               mean.ci = T, p.adjust.method = "fdr",  conf.level = 0.95,
               title = "Comparison of Median In-Deg centrality across receiving Countries") +
  scale_y_continuous(limits = c(0, 150)) +
   theme(axis.title.y=element_text(angle = 0,
                                  vjust=0.9))
```

The P - value is above 0.05, so there is not enough statistical evidence to reject the null hypothesis that the median in-deg centrality scores between top 5 receiving countries are different.

## 3.8 Interactive graph grouped by community

Are there communities inside this network graph?

The group_edge_betweenness() function is typically used in community detection algorithms, such as the Girvan-Newman algorithm. It is a top down approach by calculating the edge betweenness centrality for each edge in the graph (in each iteration) and progressively removes the edges with the highest betweenness centrality until the desired number of communities is reached. The `n` parameter specifies the number of edges to remove. The more times we cut an edge, the more communities we get. I have specified for 20 cuts, however 10 communities were detected.

I am not very certain at the number of communities I should get, in R shiny, we could set `n` as an interactive component for users to play with. The tags obtained from community detection could be analysed with the nodes attributes.

```{r}
#| echo: false
#| eval: false
#| fig-width: 12
#| fig-asp: 0.618
# use the out vis graph to calculate communitys
# let the community community column be called group column
nodes_seafood_vis <- nodes_seafood_vis %>% 
  rename(out_deg_grp = group) %>% 
  rename(group = community)


visNetwork(nodes_seafood_vis,
           mc2_seafood_edges_agg_vis,
           main = "Seafood graph grouped by Communities",
           height = "500px", width = "100%") %>%
  visIgraphLayout(layout = "layout_nicely") %>%
  visEdges(arrows = 'to',
           smooth = list(enables = TRUE,
                         type= 'curvedCW'),
           shadow = FALSE,
           dash = FALSE) %>% 
  visOptions(highlightNearest = list(enabled = T, degree = 1, hover = T),
             nodesIdSelection = TRUE,
             selectedBy = "shpcountry") %>%
  visInteraction(hideEdgesOnDrag = TRUE) %>% 
  #visLegend() %>%
  visLayout(randomSeed = 123)
```

```{r}
#| eval: false
#| echo: false
saveRDS(mc2_seafood_edges_agg_vis, "C:/yixin-neo/ISSS608-VAA/Project/data/mc2_seafood_edges_agg_vis.rds")
```

# 4 References

Hohenfeld, F. (2021, August 12). Graphs Are Fun: An Introduction to Graphs in R. Hohenfeld.is. Retrieved from **https://hohenfeld.is/posts/graphs-are-fun-an-introduction-to-graphs-in-r/**

On ggraph edgelink R Core Team. (2021, September 13). ggraph: A Grammar of Graphics for Graphs and Networks. The Comprehensive R Archive Network (CRAN). Retrieved from <https://cran.r-project.org/web/packages/ggraph/vignettes/Edges.html>

[Visnetwork]{.underline} Datastorm-Open. (n.d.). visNetwork. GitHub Pages. Retrieved from http://datastorm-open.github.io/visNetwork/

Horizon plot

Rivasiker, G. (n.d.). ggHoriPlot: Interactive Horizon Plot for R. GitHub Pages. Retrieved from <https://rivasiker.github.io/ggHoriPlot/>
