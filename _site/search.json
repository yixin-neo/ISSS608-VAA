[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am currently a student at MITB learning to enhance my skills in visual analytics using R and tableau.\nI welcome related discussions at yixin.neo.2022@mitb.smu.edu.sg =)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Getting Started Resources:\nMarkdown – useful for markdowns\nExecutionoptions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "title": "Hands-on Exercise 1",
    "section": "1.3 Introducing ggplot",
    "text": "1.3 Introducing ggplot\nFor more details, visit ggplot2.\nSmall cheatsheet\n\n\n\nggplot2\n\n\n\n1.3.1 R Graphics VS ggplot\nPlotting a simple bar chart\n\nR Graphicsggplot2\n\n\n\nhist(exam_data$MATHS, ylab='Number of students', xlab='score', main='Distribution of Math scores')\n\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x=MATHS)) + \n  geom_histogram(bins=10,\n                 boundary = 100,\n                 color='black',\n                 fill='grey',size = 0.3) +\n  ggtitle('Distribution of Math Scores')\n\n\n\n\n\n\n\ntabsets — follow this guide to create a panel tabset\nWhy use ggplot2 instead of built-in plot function?\nHadley Wickham\n\n\n\n\n\n\nThe transferable skills from ggplot2 are not the idiosyncrasies of plotting syntax, but a powerful way of thinking about visualisation, as a way of mapping between variables and the visual properties of geometric objects that you can perceive."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "title": "Hands-on Exercise 1",
    "section": "1.4 Grammar of Graphics",
    "text": "1.4 Grammar of Graphics\nBefore we getting started using ggplot2, it is important for us to understand the principles of Grammer of Graphics.\nGrammar of Graphics is a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. It was introduced by Leland Wilkinson (1999) Grammar of Graphics, Springer. The grammar of graphics is an answer to a question:\nWhat is a statistical graphic?\nIn the nutshell, Grammar of Graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\nA good grammar of graphics will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978). It also provides a strong foundation for understanding a diverse range of graphics. Furthermore, it may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\n\n1.4.1 A Layered Grammar of Graphics\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics. “A layered grammar of graphics.”\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics: Take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line. Facets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics: Statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "Hands-on Exercise 1",
    "section": "1.5 Essential Grammatical Elements in ggplot2: data",
    "text": "1.5 Essential Grammatical Elements in ggplot2: data\nLet us call the ggplot() function using the code chunk on the right.\n\nggplot(data=exam_data)\n\n\n\n\n\n\n\n\n\n\n\nA blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "title": "Hands-on Exercise 1",
    "section": "1.6 Essential Grammatical Elements in ggplot2: Aesthetic mappings",
    "text": "1.6 Essential Grammatical Elements in ggplot2: Aesthetic mappings\nThe aesthetic mappings take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency. Each visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call (in later part of this lesson, you will see that each geom layer can have its own aes specification)\nCode chunk below adds the aesthetic element into the plot.\n\nggplot(data=exam_data,\n       aes(x=MATHS))\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nggplot includes the x-axis and the axis’s label\n\n\n\n1.7 Essential Grammatical Elements in ggplot2: geom\nGeometric objects are the actual marks we put on a plot.\nExamples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\nA plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\nFor complete list, please refer to here.\n\n\n1.7.1 Geometric Objects: geom_bar\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data,\n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n1.7.2 Geometric Objects: geom_dotplot\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_dotplot(dotsize=0.5)\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe y scale is not very useful, in fact it is very misleading.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_dotplot(binwidth=2.5,\n               dotsize = 0.5) +\n  scale_y_continuous(NULL,\n                     breaks= NULL)\n\n\n\n\n\n\n1.7.3 Geometric Objects: geom_histogram()\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(binwidth=10,color='white')\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the default bin is 30.\n\n\n\n\n1.7.4 Modifying a geometric object by changing geom()\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n1.7.5 Modifying a geometric object by changing aes()\n\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\n\nggplot(data=exam_data,\n       aes(x=MATHS,\n           fill = GENDER)) +\n         geom_histogram(bins =20,\n                        color='grey40')\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis approach can be used to colour, fill and alpha of the geometric.\n\n\n\n\n1.7.6 Geometric Objects: geom-density()\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_density(color='orange')\n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\nI have to first remove the ‘color’ within geom_density.\n\nggplot(data=exam_data,\n       aes(x=MATHS,\n           color=GENDER)) +\n  geom_density()\n\n\n\n\n\n\n1.7.7 Geometric Objects: geom_boxplot\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data, \n       aes(y=MATHS,\n           x=GENDER)) +\n  geom_boxplot()\n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n1.7.8 Geometric Objects: geom_violin\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n1.7.9 Geometric Objects: geom_point()\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\nNYX: groupby gender\nSet color by group\nColor-hex\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= ENGLISH,\n           color = GENDER)) +\n  geom_point() +\n  scale_color_manual(values = c(\"#ca7dcc\",  #manually st the color\n                                \"#1b98e0\",\n                                \"#353436\",  #not applicable\n                                \"#02e302\"))  #not applicable\n\n\n\n\n\n\n1.7.10 geom objects can be combined\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\n\nCode\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n\n  geom_point(position = 'jitter',\n             size=0.5) +\n  geom_boxplot()\n\n\n\n\n\nAbove: NYX’s mistake in the layer order\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +\n  geom_point(position = 'jitter',\n             size=0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands-on Exercise 1",
    "section": "1.8 Essential Grammatical Elements in ggplot2: stat",
    "text": "1.8 Essential Grammatical Elements in ggplot2: stat\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n1.8.1 Working with stat()\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data,\n       aes( y= MATHS, x = GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n1.8.2 Working with stat - the stat_summary() method\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\nNYX: Add the mean to the boxplot\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = 'point',\n               fun.y='mean',\n               colour = 'red',\n               size=4)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ncolour is spelled in UK ENG\n\n\n\n\n1.8.3 Working with stat - the geom() method\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)          \n\n\n\n\n\n\n1.8.4 Adding a best fit curve on a scatterplot?\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe default method used is loess.\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5, method = lm)\n\n\n\n\nNYX: To add Add equation and R^2 to the plot, we can use the library ggpmisc.\n\nlibrary(ggpmisc)\n\n\n\n\n\n\n\nNote\n\n\n\nAbout the error: annotate is masked from ggplot2. To use annotate from ggplot2, we can call it out explicitly.\nEg.: # Call out the ggplot2 annotate() function explicitly p + ggplot2::annotate(“text”, x = 4, y = 20, label = “More text”)\nOther references:\nhttps://stackoverflow.com/questions/39137110/what-does-the-following-object-is-masked-from-packagexxx-mean\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  stat_poly_line() +\n  stat_poly_eq(use_label(c(\"eq\", \"R2\"))) +\n  geom_point()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "Hands-on Exercise 1",
    "section": "1.9 Essential Grammatical Elements in ggplot2: Facets",
    "text": "1.9 Essential Grammatical Elements in ggplot2: Facets\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_wrap and facet_grid().\n\n1.9.1 Working with facet_wrap()\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20) +\n  facet_wrap(~CLASS) +\n  labs(y='Number of students', x='Math scores')\n\n\n\n\nData manipulation, supposed we only want to visualise classes 3A, 3B, 3C, 3D. We could subset the exam data to include only these students.\n\nsub_data <- exam_data[exam_data$CLASS %in% c('3A','3B', '3C','3D'),]\nggplot(data=sub_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20) +\n  facet_wrap(~CLASS) +\n  labs(y='Number of students', x='Math scores')\n\n\n\n\nNYX: We can also overlay multiple histograms together.\nStatisticsGlobe\nFacetted histograms with overlaid normal curves\n\nggplot(data=sub_data,\n       aes(x=MATHS, fill = GENDER)) +\n  geom_histogram(position = \"identity\", alpha=0.2, bins=20) +\n\n  labs(y='Number of students', x='Math scores')\n\n\n\n\n\n\n1.9.2 facet_grid() function\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20) +\n  facet_grid(~CLASS) +\n  labs(y='Number of students', x='Math scores')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "Hands-on Exercise 1",
    "section": "1.10 Essential Grammatical Elements in ggplot2: Coordinates",
    "text": "1.10 Essential Grammatical Elements in ggplot2: Coordinates\nThe Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n-   [`coord_cartesian()`](https://ggplot2.tidyverse.org/reference/coord_cartesian.html): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out).\n-   [`coord_flip()`](https://ggplot2.tidyverse.org/reference/coord_flip.html): a cartesian system with the x and y flipped.\n-   [`coord_fixed()`](https://ggplot2.tidyverse.org/reference/coord_fixed.html): a cartesian system with a \"fixed\" aspect ratio (e.g. 1.78 for a \"widescreen\" plot).\n-   [`coord_quickmap()`](https://ggplot2.tidyverse.org/reference/coord_map.html): a coordinate system that approximates a good aspect ratio for maps.\n\n1.10.1 Working with Coordinate\nBy the default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n1.10.2 Changing the y- and x-axis range\nThe scatterplot on the right is slightly misleading because the y-aixs and x-axis range are not equal.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5) +\n  coord_cartesian (xlim=c(0,100),\n                   ylim= c(0,100))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "title": "Hands-on Exercise 1",
    "section": "1.11 Essential Grammatical Elements in ggplot2: themes",
    "text": "1.11 Essential Grammatical Elements in ggplot2: themes\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n1.11.1 Working with theme\nThe code chunk below plot a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\nA horizontal bar chart plotted using theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()\n\n\n\n\nTo modify components of a theme , refer to this ggplot2 webpage"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "title": "Hands-on Exercise 1",
    "section": "1.12 Reference",
    "text": "1.12 Reference\n\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "In this chapter, I will be learning several ggplot2 extensions for creating more elegant and effective statistical graphics. They are\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package.\n\n\n\n\n\n\nIn this exercise, beside tidyverse, four R packages will be used. They are:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nCode chunk below will be used to check if these packages have been installed and also will load them onto my working R environment.\n\npacman:: p_load(ggrepel, patchwork, ggthemes, hrbrthemes, tidyverse)\n\n\n\n\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data <- read_csv('data/Exam_data.csv')\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\n\n\n\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(y=ENGLISH, x=MATHS)) + \n  geom_point() +\n  geom_label(aes(label=ID))\n\n\n\n\nggrepel  is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in our examples on the right.\n\nWe simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\n\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\", max.overlaps = 15) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\nggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=MATHS)) +\n  geom_histogram(binwidth=5, \n                 color= 'black',\n                 fill='grey90') +\n  theme_gray() +\n  theme(panel.background=element_rect(fill='grey96')) +\n  ggtitle('Distribution of Math scores')\n\n\n\n\nRefer to this link to learn more about ggplot2 Themes\n\n\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\nIn the example below, The Economist theme is used.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=MATHS)) +\n  geom_histogram(binwidth=5,\n                 boundary=100,\n                 color='grey25',\n                 fill='grey90',size=0.8) +\n  theme_economist() +\n  labs(y= 'No. of \\nPupils') +\n  theme(axis.title.y=element_text(angle = 0,\n                                  vjust=0.9)) +\n  ggtitle('Distribution of Math scores')\n\n\n\n\nIt also provides some extra geoms and scales for ‘ggplot2’. Consult this vignette to learn more.\n\n\n\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=MATHS)) +\n  geom_histogram(binwidth=5,\n                 boundary=100,\n                 color='grey25',\n                 fill='grey90') +\n  theme_ipsum() +\n  labs(y= 'No. of \\nPupils') +\n  theme(axis.title.y=element_text(angle = 0,\n                                  vjust=0.9)) +\n  ggtitle('Distribution of Math scores')\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=MATHS)) +\n  geom_histogram(binwidth=5,\n                 boundary=100,\n                 color='grey25',\n                 fill='grey90') +\n  theme_ipsum(axis_title_size = 15,\n              base_size=15,\n              grid= 'Y') +\n labs(y= 'No. of \\nPupils') +\n theme(axis.title.y=element_text(angle = 0,\n                                  vjust=0.9)) +\n  ggtitle('Distribution of Math scores')\n\n\n\n\n\n\n\n\n\n\nWhat can we learn from the code chunk above?\n\n\n\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines.\n\n\n\n\n\n\n\nIt is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, I will create composite plot by combining multiple graphs. First, create three statistical graphics by using the code chunk below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\np1 <- ggplot(data=exam_data, \n       aes(x=MATHS)) +\n  geom_histogram(binwidth=5,\n                 boundary=100,\n                 color='grey25',\n                 fill='grey90') +\n  coord_cartesian(xlim=c(0,100)) +\n  theme_ipsum(axis_title_size = 10,\n              base_size=10,\n              grid= 'Y') +\n labs(y= 'No. of \\nPupils') +\n theme(axis.title.y=element_text(angle = 0,\n                                  vjust=0.9),\n       plot.title=element_text(size =10)) +\n  ggtitle('Distribution of Math scores')\n\n\n\n\nNext\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\np2 <- ggplot(data=exam_data, \n       aes(x=ENGLISH)) +\n  geom_histogram(binwidth=5,\n                 boundary=100,\n                 color='grey25',\n                 fill='grey90') +\n  coord_cartesian(xlim=c(0,100)) +\n  theme_ipsum(axis_title_size = 10,\n              base_size=10,\n              grid= 'Y') +\n labs(y= 'No. of \\nPupils') +\n theme(axis.title.y=element_text(angle = 0,\n                                  vjust=0.9),\n       plot.title=element_text(size =10)) +\n  ggtitle('Distribution of English scores')\n\n\n\n\nLastly, draw a scatterplot for English score versus Maths score by as shown below\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\np3 <-ggplot(data=exam_data, \n       aes(x=MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size = 0.5 )+\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  theme_ipsum(axis_title_size = 10,\n              base_size=10) +\n labs(y= 'EL score', x= 'Math score') +\n theme(axis.title.y=element_text(angle = 0,\n                                  vjust=0.9),\n       plot.title=element_text(size =10)) +\n  ggtitle('English scores vesus Math scores \\nfor Primary 3')\n\n\n\n\n\n\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package. In this section, I am going to shared with you an ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n\n\nFigure in the tabset below shows a composite of two histograms created using patchwork. Note how simple the syntax used to create the plot!\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\np1 + p2\n\n\n\n\n\n\n\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n“|” operator to stack two ggplot2 graphs,\n“/” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n(p1 / p2) | p3\n\n\n\n\nOther interesting plot layouts\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n((p1 / p2) | p3) + grid:: textGrob('I can place \\nsome text here.',\n                                   hjust=0, \n                                   x=-0, \n                                   gp=grid::gpar(font=3, \n                                                 fontsize = 12))\n\n\n\n\nTo learn more about, refer to Plot Assembly.\n\n\n\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n((p1 / p2) | p3) +\n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\np4 <- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np5 <- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np6 <- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\np6 +  inset_element(p5,\n                    left = 0.02,\n                    bottom=0.7,\n                    right= 0.5,\n                    top=1)\n\n\n\n\n\n\n\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\npatchwork <- (p4/p5) | p6\npatchwork &   theme_economist() + theme(plot.title=element_text(size =10),\n                                        axis.title.y=element_text(size = 9,\n                                                                  angle = 0,\n                                                                  vjust=0.9),\n                                         axis.title.x=element_text(size = 9))\n\n\n\n\n\n\n\n\n\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "In this hands-on exercise, I will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "title": "Hands-on_Ex03",
    "section": "3.2 Getting Started",
    "text": "3.2 Getting Started\nUse the pacman package to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\n\npacman:: p_load(ggiraph, plotly, patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "title": "Hands-on_Ex03",
    "section": "3.3 Importing Data",
    "text": "3.3 Importing Data\nIn this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\nglimpse(exam_data)\n\nRows: 322\nColumns: 7\n$ ID      <chr> \"Student321\", \"Student305\", \"Student289\", \"Student227\", \"Stude…\n$ CLASS   <chr> \"3I\", \"3I\", \"3H\", \"3F\", \"3I\", \"3I\", \"3I\", \"3I\", \"3I\", \"3H\", \"3…\n$ GENDER  <chr> \"Male\", \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Male\", \"M…\n$ RACE    <chr> \"Malay\", \"Malay\", \"Chinese\", \"Chinese\", \"Malay\", \"Malay\", \"Chi…\n$ ENGLISH <dbl> 21, 24, 26, 27, 27, 31, 31, 31, 33, 34, 34, 36, 36, 36, 37, 38…\n$ MATHS   <dbl> 9, 22, 16, 77, 11, 16, 21, 18, 19, 49, 39, 35, 23, 36, 49, 30,…\n$ SCIENCE <dbl> 15, 16, 16, 31, 25, 16, 25, 27, 15, 37, 42, 22, 32, 36, 35, 45…\n\nsummary(exam_data)\n\n      ID               CLASS              GENDER              RACE          \n Length:322         Length:322         Length:322         Length:322        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    ENGLISH          MATHS          SCIENCE     \n Min.   :21.00   Min.   : 9.00   Min.   :15.00  \n 1st Qu.:59.00   1st Qu.:58.00   1st Qu.:49.25  \n Median :70.00   Median :74.00   Median :65.00  \n Mean   :67.18   Mean   :69.33   Mean   :61.16  \n 3rd Qu.:78.00   3rd Qu.:85.00   3rd Qu.:74.75  \n Max.   :96.00   Max.   :99.00   Max.   :96.00"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on_Ex03",
    "section": "3.4 Interactive Data Visualisation - ggiraph methods",
    "text": "3.4 Interactive Data Visualisation - ggiraph methods\nggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n3.4.1 Tooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np <- ggplot(data=exam_data,\n            aes(x=MATHS)) +\n  geom_dotplot_interactive(aes(tooltip=ID),\n                           stackgroups = TRUE,\n                           binwidth = 1,\n                           method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks= NULL)  #null to suppress axis labels\n\ngirafe(ggobj=p,\n       width_svg = 6,\n       height_svg = 6*0.618)\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\nNYX: steps in creating an interactive graphic 1. instead of geom_point (i.e.), use geom_point_interactive - provide at least one of the aesthetics tools (tooltip, data_id or onclick) 2. call function girafe with the ggplot object to translate graphic into a web interactive graphic.\n\n\n\n\n\n\nNote\n\n\n\nBy hovering the mouse pointer on an data point of interest, the student’s ID will be displayed. To set index as the tooltip, replace with row.names(exam_data). To set numeric values as tooltip, replace with factor(MATHS).\n\n\n\n\n\n\n\n\n\n\n3.4.2 Displaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below. We create a new column [tooltip] in exam_data by concatenating ID and Class info.\n\nexam_data$tooltip <- c(paste0(\"Name= \",\n                              exam_data$ID,\n                              \"\\n Class= \",\n                              exam_data$CLASS))\n\np <- ggplot(data=exam_data,\n            aes(x=MATHS)) +\n  geom_dotplot_interactive(aes(tooltip=tooltip),\n                           stackgroups = TRUE,\n                           binwidth = 1,\n                           method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks= NULL)  #null to suppress axis labels\n\ngirafe(ggobj=p,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\n\n\n\n\n\nInteractivity\n\n\n\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n\n\n\n\n\n\n3.4.3 Customising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css <- 'background-color:palegreen; font-style:bold; color:black;'  #<<<\n\nexam_data$tooltip <- c(paste0(\"Name= \",\n                              exam_data$ID,\n                              \"\\n Class= \",\n                              exam_data$CLASS))\n\np <- ggplot(data=exam_data,\n            aes(x=MATHS)) +\n  geom_dotplot_interactive(aes(tooltip=tooltip),\n                           stackgroups = TRUE,\n                           binwidth = 1,\n                           method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks= NULL)  #null to suppress axis labels\n\ngirafe(ggobj=p,\n       width_svg = 8,\n       height_svg = 8*0.618,\n       options = list(          #<<<\n         opts_tooltip(          #<<<\n           css=tooltip_css\n         )\n       ))\n\nNotice that the background colour of the tooltip is palegreen and the font colour is black and bold. For demonstration purposes, we can also make the font italic and change the font size.\n\n\n\n\n\n\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\n3.4.4 Displaying statistics on tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip <- function(y, ymax, accuracy = 0.01) {\n  mean <- scales::number(y, accuracy = accuracy)\n  sem <- scales:: number (ymax-y, accuracy = accuracy)\n  paste(\"mean maths scores:\" , mean, \"+/-\", sem)\n}\n\n\ngg_point <- ggplot(data=exam_data,\n                   aes(x = RACE)) +\n  stat_summary(aes(y=MATHS,\n                   tooltip = after_stat(tooltip(y, ymax))),\n               fun.data = mean_se,\n               geom = GeomInteractiveCol,\n               fill = 'lightblue') +\n  stat_summary(aes(y= MATHS),\n               fun.data = mean_se,\n               geom= 'errorbar',\n               width = 0.2,\n               size = 0.2)\n\ngirafe(ggobj=gg_point,\n       width_svg = 8,\n       height_svg = 8 * 0.618)\n\n\n\n\n\nEXPLANATION of the codes above\n\nTooltip self defined function:\n\n\nIt takes in two arguments (y and ymax) from results of stat_summary() via after_stat(). accuracy is a fixed parameter and has a value of 0.01.\nscales:: number is to convert number to text, with formatting.\nsem output: If ymax = y + se , then in tooltip, sem = ymax-y, isnt sem = se?\nIt outputs \"mean maths scores: 57.44 +/- 2.03\"\n\n\nStat_summary function creates another geom layer. The first stat summary function has two aes mappings to visual: (1)MATHS as Y (2)tooltip output\n\n\nIt first applies mean_se method to output y, ymin, ymax for each X value (usually categorical)\nAfter this, these groups of 3 values are send into tooltip function via after_stat() helper function\nGeomInteractive makes the columns interactive so tooltips is displayed when users hover over\n\n\nThe second stat summary uses y,ymin, ymax obtained from method= mean_se to plot the error bar\n\nDOUCUMENTATION\nmean_se\nstat_summary(aes(fun.data=mean_se) is default. mean_se(x, mult = 1). When input a list of values, it returns a data frame with three columns:\ny: The mean.\nymin: The mean minus the multiples of the standard error.\nymax: The mean plus the multiples of the standard error.\nThere are a few summary functions from the Hmisc package which are reformatted for use in stat_summary(). They all return aesthetics for y, ymax, and ymin.\nmean_cl_normal() Returns sample mean and 95% confidence intervals assuming normality (i.e., t-distribution based)\nmean_sdl() Returns sample mean and a confidence interval based on the standard deviation times some constant\nmean_cl_boot() Uses a bootstrap method to determine a confidence interval for the sample mean without assuming normality.\nmedian_hilow() Returns the median and an upper and lower quantiles.\n\n\n3.4.5 Hover effect with data_id aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np <- ggplot(data= exam_data,\n            aes(x=MATHS)) +\n  geom_dotplot_interactive(aes(data_id=CLASS),\n                           stackgroups = TRUE,\n                           binwidth= 1,\n                           method = 'histodot') +\n  scale_y_continuous( NULL,\n                      breaks = NULL)\n\ngirafe(ggobj=p,\n       width_svg = 8,\n       height_svg = 8 *0.618)\n\n\n\n\n\n\n\nInfo\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\n\n\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n3.4.6 Styling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np <- ggplot(data=exam_data,\n            aes(x=MATHS)) +\n  geom_dotplot_interactive(aes(data_id = CLASS),\n                           stackgroups = TRUE,\n                           binwidth = 1,\n                           method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks= NULL)  #null to suppress axis labels\n\ngirafe(ggobj=p,\n       width_svg = 6,\n       height_svg = 6*0.618,\n       options = list(                          #<<<\n         opts_hover(css='fill: #202020;'),      #<<<\n         opts_hover_inv(css = 'opacity: 0.2;')  #<<<\n         )\n       )\n\n\n\n\n\n\n\nInfo\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\n\n\nNote: Different from previous example (tooltip_css is pre-defined as input to a parameter in girafe(options=list(opts_tooltip(css=tooltip_css)))), in this example the ccs customisation request are encoded directly as girafe(options=list(opts_hover(css='tooltip_css'fill:#202020;')))\n\n\n3.4.7 Combining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np <- ggplot(data=exam_data,\n            aes(x=MATHS)) +\n  geom_dotplot_interactive(aes(tooltip = CLASS,  #<<<\n                               data_id = CLASS),  #<<<\n                           stackgroups = TRUE,\n                           binwidth = 1,\n                           method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks= NULL)  #null to suppress axis labels\n\ngirafe(ggobj=p,\n       width_svg = 6,\n       height_svg = 6*0.618,\n       options = list(                          #<<<\n         opts_hover(css='fill: blue;'),      #<<<\n         opts_hover_inv(css = 'opacity: 0.2;')  #<<<\n         )\n       )\n\n\n\n\n\n\n\nInfo\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\n\n\n\n\n\n\n3.4.8 Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick <- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)\n\n\n\n\n\n\n\nInfo\n\n\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\n\n3.4.9 Coordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\np1 <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID,\n        tooltip= ID),      #<<< NYX added this          \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) +    #<<< p1 same as p2 x-axis\n  scale_y_continuous(NULL,            # suppress y axis\n                     breaks = NULL)\n\np2 <- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) +    #<<< p1 same as p2 x-axis\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2),         #<<< coordinated multiple views\n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\nNYX: hover effects can be encoded directly in girafe unlike tooltips and data_id . Added tooltip aes effects as well.\n\n\n\n\n\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on_Ex03",
    "section": "3.5 Interactive Data Visualisation - plotly methods!",
    "text": "3.5 Interactive Data Visualisation - plotly methods!\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\n\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n3.5.1 Creating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly()\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data=exam_data,\n        x=~MATHS,\n        y=~ENGLISH)\n\n\n\n\n\n\n3.5.2 Working with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data=exam_data,\n        x= ~ENGLISH,\n        y= ~MATHS,\n        color=~RACE)\n\n\n\n\n\n\n3.5.3 Creating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\np <- ggplot(data = exam_data,\n            aes(x= MATHS,\n                y= ENGLISH)) +\n  geom_point (size =1) +\n  geom_smooth(method=lm)+\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  labs(y= 'ENGLISH') +                                    \n  theme(axis.title.y=element_text(angle = 0,\n                                  vjust=0.9)) +   #<<< does not work in ggplotly\n  ggtitle('English and Math scores')\n\nggplotly(p)\n\n\n\n\n\n\n3.5.4 Coordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nd <- highlight_key(exam_data)\n\np1 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  labs(x='math',\n       y='english')\n\nsubplot(ggplotly(p1),\n        ggplotly(p2)) %>% \n  layout(xaxis = list(title = \"math\"),\n         yaxis = list(title = \"english\"))\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk\n\n\n\n\n\n\n\nNote\n\n\n\nDifference between 3.4.9 and 3.5.4\n3.4.9:interactive geom functions of ggiraph & girafe(patchwork) used\n3.5.4 : highlight_key() , normal ggplot + geom_obj , subplot(ggplot(p1), ggplot(p2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on_Ex03",
    "section": "3.6 Interactive Data Visualisation - crosstalk methods!",
    "text": "3.6 Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n3.6.1 Interactive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class='compact')\n\n\n\n\n\n\n\n\n3.6.2 Linked brushing: crosstalk method\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd <- highlight_key(exam_data) \np <- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg <- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,\n                  DT::datatable(d),\n                  widths=5)\n\n\n\n\nThe highlight_key() function is used to create a unique identifier for each row in a data frame, based on its values. The resulting identifier is used to keep track of the rows that have been selected or highlighted on a plot, particularly when using the highlight() function.\nplotly_selected is a built-in plotly attribute that represents the currently selected points on the plot.\nSo, highlight(ggplotly(p), “plotly_selected”) is taking the ggplotly(p) object and highlighting the currently selected points on the plot by changing their appearance in some way, such as by changing their color or size.\ncrosstalk::bscols() is a function in R that creates a Bootstrap column layout. The first argument is the left column, and the second argument is the right column. The widths argument is used to specify the relative width of the two columns, with the default value being 6 for both.\ncrosstalk::bscols() is particularly useful when working with interactive data visualizations, as it allows for easy linking of different components of the dashboard, such as brushing and highlighting on the plot and filtering on the data table."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#reference",
    "title": "Hands-on_Ex03",
    "section": "3.7 Reference",
    "text": "3.7 Reference\n\n3.7.1 ggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n3.7.2 plotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, I will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, I will also learn how to\n(i) reshape data by using tidyr package, and\n(ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBeforewe start making animated graphs, we should first ask ourself: Does it makes sense to go through the effort? If we are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if we are giving a presentation, a few well-placed animated graphics can help an audience connect with our topic remarkably better than static counterparts.\n\n\n\n\n\n\n\n\nWe will use p_load from pacman package to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder, plotly, gganimate, tidyverse)\n\n\n\n\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol <- c('Country', 'Continent')\n\nglobalPop <- read_xls('data/GlobalPopulation.xls',\n                      sheet='Data') %>% \n  mutate_each_(funs(factor(.)), col) %>%\n  mutate(Year = as.integer(Year))\n\n\nglimpse(globalPop)\n\nRows: 6,204\nColumns: 6\n$ Country    <fct> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\",…\n$ Year       <int> 1996, 1998, 2000, 2002, 2004, 2006, 2008, 2010, 2012, 2014,…\n$ Young      <dbl> 83.6, 84.1, 84.6, 85.1, 84.5, 84.3, 84.1, 83.7, 82.9, 82.1,…\n$ Old        <dbl> 4.5, 4.5, 4.5, 4.5, 4.5, 4.6, 4.6, 4.6, 4.6, 4.7, 4.7, 4.7,…\n$ Population <dbl> 21559.9, 22912.8, 23898.2, 25268.4, 28513.7, 31057.0, 32738…\n$ Continent  <fct> Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia,…\n\n\n\n\n\n\n\n\nThings to learn from the code\n\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\n\nThis line applies the factor() function to each column specified in the col argument. Character to factor. It takes column indices or column names in strings format as inputs, and returns a data frame with new columns for each column in the input data frame, where each new column is the result of applying the specified function to the corresponding column in the input data frame.\nThe fun argument specifies the function to apply to each column, and factor(.) is a way to specify the factor works as an argument.\n\nmutate of dplyr package is used to convert data values of Year field into integer.\n\nas.character(x), as.integer(x), as.numeric(x), as.factor(x) (for categorical data)\n\n\n\n\n\n\n\n\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot\n\n\n\n\n\n\nNote\n\n\n\nA bubble plot is created when a third numeric variable is assigned to size argument inside a ggplot with geom_point.\n\n\n\nggplot(data= globalPop,\n       aes(x= Old,\n           y=Young,\n           size= Population,\n           color=Country)) +\n  geom_point(alpha = 0.7,\n             show.legend = FALSE) +\n  scale_color_manual(values=country_colors) +  #<<< who has defined country_colors?\n  scale_size(range= c(2,12)) +\n  labs(title='Year:{frame_time}',\n       x = '% Aged',\n       y= '% Young')\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code\n\n\n\n\nThe scale_size(range= c(2,12)) sets the range of point sizes to be used in the plot to between 2 and 12.\nPopulation is mapped to size aes in ggplot, thus this range parameter controls the min nad max size of the points.\n\n\n\n\n\n\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(data= globalPop,\n       aes(x= Old,\n           y=Young,\n           size= Population,\n           color=Country)) +\n  geom_point( alpha = 0.7,\n             show.legend = FALSE) +\n  scale_color_manual(values=country_colors) +  #<<< gapminder lib\n  scale_size(range= c(2,12)) +\n  labs(title='Year:{frame_time}',\n       x = '% Aged',\n       y= '% Young') +\n  transition_time(Year) +\n  ease_aes(\"linear\")\n\n\n\n\n\n\n\n\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n\nIn this sub-section, I will learn how to create an animated bubble plot by using ggplotly() method.\n\ngg <- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,    #<<< perform aes mapping for each frame\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object.\n\n\n\n\n\n\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nbp <- globalPop %>% \n  plot_ly( x = ~Old,\n           y= ~Young,\n           color = ~Continent,#<< 6 unique\n           frame= ~Year,\n           text= ~Country,\n           hoverinfo='text',\n           type = 'scatter',\n           mode= 'markers')\n\n\nbp\n\n\n\n\n\n\n\n\n\n\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters\n\n\n\n\n\n\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting. For example, here are results from a robust t-test:\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nparameter refers to the degree of freedom\nAn effect size of 0.77 is a standardized measure of the magnitude of a treatment or intervention effect, or the strength of an association between two variables. Guideline is that an effect size of 0.2 is considered small, 0.5 is considered moderate, and 0.8 is considered large.\nCI of 95% means if we replicate our sampling from underlying distribution many times, 95% of our samples will have their means within this interval.\n\n\n\n\n\n\n\n\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse,nortest, ggdist)\n\n\n\n\nLets import the Exam_data.csv using the read_xls() function.\n\nexam <- read_csv('data/Exam_data.csv')\n\nTake a glimpse at the data.\n\nexam\n\n# A tibble: 322 × 7\n   ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n   <chr>      <chr> <chr>  <chr>     <dbl> <dbl>   <dbl>\n 1 Student321 3I    Male   Malay        21     9      15\n 2 Student305 3I    Female Malay        24    22      16\n 3 Student289 3H    Male   Chinese      26    16      16\n 4 Student227 3F    Male   Chinese      27    77      31\n 5 Student318 3I    Male   Malay        27    11      25\n 6 Student306 3I    Female Malay        31    16      16\n 7 Student313 3I    Male   Chinese      31    21      25\n 8 Student316 3I    Male   Malay        31    18      27\n 9 Student312 3I    Male   Malay        33    19      15\n10 Student297 3H    Male   Indian       34    49      37\n# ℹ 312 more rows\n\n\n\nglimpse(exam)\n\nRows: 322\nColumns: 7\n$ ID      <chr> \"Student321\", \"Student305\", \"Student289\", \"Student227\", \"Stude…\n$ CLASS   <chr> \"3I\", \"3I\", \"3H\", \"3F\", \"3I\", \"3I\", \"3I\", \"3I\", \"3I\", \"3H\", \"3…\n$ GENDER  <chr> \"Male\", \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Male\", \"M…\n$ RACE    <chr> \"Malay\", \"Malay\", \"Chinese\", \"Chinese\", \"Malay\", \"Malay\", \"Chi…\n$ ENGLISH <dbl> 21, 24, 26, 27, 27, 31, 31, 31, 33, 34, 34, 36, 36, 36, 37, 38…\n$ MATHS   <dbl> 9, 22, 16, 77, 11, 16, 21, 18, 19, 49, 39, 35, 23, 36, 49, 30,…\n$ SCIENCE <dbl> 15, 16, 16, 31, 25, 16, 25, 27, 15, 37, 42, 22, 32, 36, 35, 45…\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nA one-sample test is a statistical hypothesis test used to determine whether the mean of a single sample of data differs significantly from a known or hypothesized value.\nIt is a statistical test that compares the mean of a sample to a specified value, such as a population mean, to see if there is enough evidence to reject the null hypothesis that the sample comes from a population with the specified mean.\n\nH0: EL average score is 60.\n\nset.seed(1234)  #<<< important to set if we use bayes statistics\n\ngghistostats(data=exam,\n             x = ENGLISH,\n             type='bayes',  #<< '\n             test.value =60,\n             xlab = 'English scores')\n\n\n\n\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\nReference website from r-bloggers\nThe one-sample Wilcoxon test (non parametric) will tell us whether the scores are significantly different from 60 or not (and thus whether they are different from 60 in the population or not)\nH0: EL scores = 60\nH1: EL scores != 60\nThe scores are assumed to be independent (a student’s score is not impacted or influenced by the score of another student)\n\nwilcox.test(exam$ENGLISH,\n            mu = 60)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  exam$ENGLISH\nV = 38743, p-value = 3.435e-16\nalternative hypothesis: true location is not equal to 60\n\n\nInterpretation\nP-value<0.05, we have enough statistical evidence to reject the null hypothesis and conclude that the EL scores are significantly different from 60.\n\n\n\n\n\n\nNote\n\n\n\nBy default, it is a two-tailed test that is done. As for the t.test() function, we can specify that a one-sided test is required by using either the alternative = “greater” or alternative = “less argument in the wilcox.test() function.\n\n\nCombine statistical test and plot\n\nset.seed(1234)\n\ngghistostats(data=exam,\n             x = ENGLISH,\n             type='nonparametric', #nonparametric (median) = Wilcoxon, parametric = t-test (default is look for mean and unequal variance method)\n             test.value =60,\n             conf.level = 0.95,\n             xlab = 'English scores')\n\n\n\n\nDid we forget to check if English scores follow a normal distribution? Use ad.test from nortest library.\nH0: EL scores follows normal distribution\nH1: EL scores do not follow normal distribution.\n\nad.test(exam$ENGLISH)\n\n\n    Anderson-Darling normality test\n\ndata:  exam$ENGLISH\nA = 4.3661, p-value = 7.341e-11\n\n\nResults from the Anderson_darling normality test shows enough statistical evidence to reject the null hypothesis and conclude that the EL scores do not follow normal distribution . Thus the use of non parametric test is correct.\n\n\n\n\n\n\nOn Parametric and Non-parametric types\n\n\n\ntype= parametric: default look for mean and assumes unequal variance method\ntype = Non parametric: student-t test and use median (not mean!!)\n\n\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender (independent).\nH0: Mean of F and M Math scores are the same.\nH1: Mean of F and M Math scores are not the same.\n\nggbetweenstats(data=exam,\n               x=GENDER,\n               y=MATHS,\n               type='np',\n               messages=FALSE)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\nSince p-value > 0.05, we do not have enough statistical evidence to reject the null hypothesis that mean of Math scores of both gender are the same.\nHowever, if we check for normality of Math scores of each gender.\n\n# perform Shapiro-Wilk test on math scores by gender\nshapiro_test <- by(exam$MATHS, exam$GENDER, shapiro.test)\n\n# extract p-values\np_values <- sapply(shapiro_test, function(x) x$p.value)\n# print results\nprint(p_values)\n\n      Female         Male \n1.603536e-07 6.268520e-08 \n\n\n\n\n\n\n\n\nNote\n\n\n\nThe by() function is used to apply a function to subsets of a data frame or vector split by one or more factors. In the above code, we use by() to split the math_score column by gender, and apply the shapiro.test() function to each group.\n\n\nH0: Math scores by gender follows normal distribution.\nH1: Math scores by gender do not follow normal distribution.\nFrom the Shapiro-Wilk test results, we have enough statistical evidence to reject the null hypothesis and conclude that the Math scores by gender does not follow a normal distribution. Thus the use of ‘np’ is appropriate.\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race (Independent 4 sample mean).\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci=TRUE,\n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",  # 'ns': shows only non-sig, 's': shows only sig, 'all': both \n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n## might need to call library(PMCMRplus) and library(rstantools) if this code chunck doesnt work.\n\nSince p-value < 0.05, we have enough statistical evidence to reject the null hypothesis and conclude that NOT ALL means of EL scores by race are the same. The results shows that the means of EL scores of Chinese, Indian and Malay are significantly different.\nOnce again, lets go backwards and confirm that the distribution of EL scores by RACE conforms to normal distribution.\n\n# perform Shapiro-Wilk test on math scores by gender\nshapiro_test <- by(exam$ENGLISH, exam$RACE, shapiro.test)\n\n# extract p-values\np_values <- sapply(shapiro_test, function(x) x$p.value)\n# print results\nprint(p_values)\n\n     Chinese       Indian        Malay       Others \n1.305153e-07 8.482600e-01 1.251020e-02 5.181740e-01 \n\n\nH0: EL scores by Race follow normal distribution. H1: EL scores by Race do not follow normal distribution.\nThe results of the Shapiro-wilk test shows p_value of all EL score distribution by race follows normal distribution.\n\n\n\ntype argument entered by us will determine the centrality tendency measure displayed\n\n\nmean for parametric statistics\nmedian for non-parametric statistics\ntrimmed mean for robust statistics\nMAP estimator for Bayesian statistics\n\n\n\n\n\n\n\n\nEarlier, we have checked that EL scores do not follow a normal distribution. Now we will do the same for Math scores.\n\nad.test(exam$MATHS)\n\n\n    Anderson-Darling normality test\n\ndata:  exam$MATHS\nA = 7.9125, p-value < 2.2e-16\n\n\nSince the p-value < 0.05, we have enough statistical evidence to reject the null hypothesis and conclude that the Math scores also do not follow normal distribution.\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  type='nonparametric', # 'parametric', 'robust', 'bayes'\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nI have chosen a non parametric version of this test as both Math and EL scores do not follow normal distribution.\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\nWe will create a new dataframe exam1 similar to exam df but with extra column called ‘MATHS_bins’.\n\nexam1 <- exam %>% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\n\nexam1\n\n# A tibble: 322 × 8\n   ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE MATHS_bins\n   <chr>      <chr> <chr>  <chr>     <dbl> <dbl>   <dbl> <fct>     \n 1 Student321 3I    Male   Malay        21     9      15 (0,60]    \n 2 Student305 3I    Female Malay        24    22      16 (0,60]    \n 3 Student289 3H    Male   Chinese      26    16      16 (0,60]    \n 4 Student227 3F    Male   Chinese      27    77      31 (75,85]   \n 5 Student318 3I    Male   Malay        27    11      25 (0,60]    \n 6 Student306 3I    Female Malay        31    16      16 (0,60]    \n 7 Student313 3I    Male   Chinese      31    21      25 (0,60]    \n 8 Student316 3I    Male   Malay        31    18      27 (0,60]    \n 9 Student312 3I    Male   Malay        33    19      15 (0,60]    \n10 Student297 3H    Male   Indian       34    49      37 (0,60]    \n# ℹ 312 more rows\n\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association.\n(Two categorical variables) H0: There is no association between mathbin and gender.\nH1: There is an association between mathbin and gender.\n\nggbarstats(exam1,\n            x=MATHS_bins,\n            y=GENDER)\n\n\n\n\nFrom the results above , p-value > 0.05 thus we have not enough statistical evidence to reject the null hypothesis that there is not association between the mathbin and gender variables.\n\n\n\n\nIn this section, I will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n\n\n\n\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale <- read_xls('data/ToyotaCorolla.xls',\n                       sheet='data')\n\n\nglimpse(car_resale)\n\nRows: 1,436\nColumns: 38\n$ Id               <dbl> 81, 1, 2, 3, 4, 5, 6, 7, 8, 44, 45, 46, 47, 49, 51, 6…\n$ Model            <chr> \"TOYOTA Corolla 1.6 5drs 1 4/5-Doors\", \"TOYOTA Coroll…\n$ Price            <dbl> 18950, 13500, 13750, 13950, 14950, 13750, 12950, 1690…\n$ Age_08_04        <dbl> 25, 23, 23, 24, 26, 30, 32, 27, 30, 27, 22, 23, 27, 2…\n$ Mfg_Month        <dbl> 8, 10, 10, 9, 7, 3, 1, 6, 3, 6, 11, 10, 6, 11, 11, 11…\n$ Mfg_Year         <dbl> 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002,…\n$ KM               <dbl> 20019, 46986, 72937, 41711, 48000, 38500, 61000, 9461…\n$ Quarterly_Tax    <dbl> 100, 210, 210, 210, 210, 210, 210, 210, 210, 234, 234…\n$ Weight           <dbl> 1180, 1165, 1165, 1165, 1165, 1170, 1170, 1245, 1245,…\n$ Guarantee_Period <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…\n$ HP_Bin           <chr> \"100-120\", \"< 100\", \"< 100\", \"< 100\", \"< 100\", \"< 100…\n$ CC_bin           <chr> \"1600\", \">1600\", \">1600\", \">1600\", \">1600\", \">1600\", …\n$ Doors            <dbl> 5, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 3, 3,…\n$ Gears            <dbl> 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,…\n$ Cylinders        <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,…\n$ Fuel_Type        <chr> \"Petrol\", \"Diesel\", \"Diesel\", \"Diesel\", \"Diesel\", \"Di…\n$ Color            <chr> \"Blue\", \"Blue\", \"Silver\", \"Blue\", \"Black\", \"Black\", \"…\n$ Met_Color        <dbl> 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,…\n$ Automatic        <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Mfr_Guarantee    <dbl> 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,…\n$ BOVAG_Guarantee  <dbl> 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ ABS              <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Airbag_1         <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Airbag_2         <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Airco            <dbl> 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Automatic_airco  <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,…\n$ Boardcomputer    <dbl> 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ CD_Player        <dbl> 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,…\n$ Central_Lock     <dbl> 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Powered_Windows  <dbl> 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Power_Steering   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Radio            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Mistlamps        <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Sport_Model      <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,…\n$ Backseat_Divider <dbl> 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Metallic_Rim     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Radio_cassette   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Tow_Bar          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\nNotice that the output object car_resale is a tibble data frame.\n\n\n\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period,\n            data=car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\n\n\n\nWe can see high collinearity between Age and Mfg_Year. One is derived from the other. We should remove one of them and repeat muliti collinearity check again for the new model.\n\n\n\nIn the code chunk, check_normality() of performance package.\nNotice that the Mfg_Year variable has been removed from the independent variables list.\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_c1 <- check_collinearity(model1)\nplot(check_c1)\n\n\n\n\n\ncheck_n <- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\n\n\n\n\n\n\nRecap: Assumptions of linear regression\n\n\n\nIn linear regression, one of the key assumptions is that the residuals (the differences between the predicted values and the actual values) are normally distributed. The normality assumption is important because it affects the validity of statistical inference procedures such as hypothesis testing and confidence intervals.\nIf the residuals are not normally distributed, it may indicate that the linear regression model is not a good fit for the data and that alternative modeling approaches may be needed.\n\n\n\n\n\nIn the code chunk, check_heteroscedasticity() of performance package.\nHeteroscedasticity refers to a situation where the variance of the errors (or residuals) in the linear regression model is not constant across different levels of the predictor variable(s).\nIf heteroscedasticity is detected, there are several ways to address it, including transforming the data, using weighted least squares regression, or using robust standard errors. In DAl, we rebuild another model by creating subclasses out of the original Y variable.\n\ncheck_h <- check_heteroscedasticity(model1)\n\n\nplot(check_h)\n\n\n\n\nFrom the graph above, there is a slight sign of heteroscedasticity as the residuals seem to be funnelled outwards as the fitted values increase.\n\n\n\nWe can also perform the complete check by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\n\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on_Ex06",
    "section": "",
    "text": "A point estimate is a single number, such as a mean.\n\nUncertainty is expressed as standard error, confidence interval, or credible interval\n\n\n\n\n\n\nImportant\n\n\n\nDon’t confuse the uncertainty of a point estimate (mean, median..) with the variation in the sample (standard deviation sigma, and variation sigma square etc).\nThe standard deviation measures the variation of the values from the mean of ONE sample.\nThe standard error is the standard deviation of both sides of the ‘mother of all means’ of all the sample means. <- refer lecture 4 slide 23\n\n\n\npacman::p_load(tidyverse, plotly, crosstalk, DT, ggdist, gganimate, ggiraph)\n\n\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualizing distributions and uncertainty.\nLets load the student exam data.csv\n\n\nexam <- read_csv('C:/yixin-neo/ISSS608-VAA/Hands-on_Ex/Hands-on_Ex05/data/Exam_data.csv')\n\n\n\nThe code chunk below performs the followings:\n\ngroup the observation by RACE,\ncomputes the count of observations, mean, standard deviation and standard error of Maths by RACE, and\nsave the output as a tibble data table called my_sum.\n\nmy_sum <- exam %>% \n  group_by(RACE) %>% \n  summarise(n=n(),\n            mean=mean(MATHS),\n            sd = sd(MATHS)) %>% \n  mutate(se=sd/sqrt(n-1))   #<<< standard error formula\n\n\nRefer to lecture 4 slide 20 for mathematical formula explanation.\nmy_sum is specially created for visualisation later using ggplot2.\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438 \n  \n\n\n\n\n\n\n\n\nThe code chunk below is used to reveal the standard error of mean maths score by race. It shows one standard deviation away from the ‘mother of all means’ for all the means from all the samples.\n\n\n\n\n\n\nNote\n\n\n\nStandard error is a measure of the variation of the mean of all the means from all samples of an underlying distribution.\n\n\n\n\nCode\nggplot(my_sum) +\n  geom_errorbar(aes(x=RACE,\n                    ymin=mean-se,\n                    ymax=mean+se),\n                width = 0.2,\n                colour = 'black',\n                alpha = 0.9,\n                size=0.5) +\n    geom_point(aes(x=RACE,\n                 y=mean),\n             stat = 'identity', #<<< actual points refer to mean \n             color='red', \n             size = 1.5,\n             alpha = 1) + \n  ggtitle('Standard error of mean maths score by race')\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the code above, stat = 'identity' means that the y values in the geom_point layer correspond to the actual values in the data frame, rather than a summary statistic like mean or median.\n\n\n\n\n\nLets plot a 95% confidence interval of mean maths score by race. The error bars should be sorted by the average maths scores. (Refer to take-home ex 1 on sorting by mean)\n\n\nCode\nggplot(my_sum) +\n  geom_errorbar(aes(x=reorder(RACE,-mean),  # reorder(x,y) means to reorder x based on increasing or decreasing values of y. To sort by descending values of Y, use -Y.\n                    ymin=mean-1.96*se,    #<<<< formula to calc 95% CI\n                    ymax=mean+ 1.96*se),  #<<<<\n                width = 0.2,\n                colour = 'black',\n                alpha = 0.9,\n                size=0.5) +\n    geom_point(aes(x=RACE,\n                 y=mean),\n             stat = 'identity', #<<< actual points refer to mean \n             color='red', \n             size = 1.5,\n             alpha = 1) + \n  ggtitle('95% confidence interval of maths score by race')\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat is the difference between standard error plot above and this 95% confidence interval plot?\nEarlier , we plot error bars of 1 standard deviation away from the mother of all means.\nHere, we are plotting 1.96 * standard deviation away from the mother of all means. The higher the % CI, the greater the margin or error.\n\n\n\n\n\nTask: Plot an interactive error bars for the 99% confidence interval of mean maths score by race., and add the source data table on the right. Table and plot have coordinated views.\nRecall in hands-on 3 that we create can create interactive plots using ggiraph and ggplot geometries that can understand 3 arguments; namely tooltip, data_id and onclick.\nI will use one of them methods (geom_errorbar_interactive with girafe) to construct here. The other method is to use plotly.\nSTEP 1: CREATE INTERACTIVE ERROR BAR for 99% CI\n\n\nCode\n# create a new column tooltip to contain the tooltip text.\nmy_sum$tooltip <- c(paste0(\"RACE: \",\n                           my_sum$RACE,\n                           \"\\n N= \",\n                            my_sum$n,\n                           \"\\n Ave Score: \",\n                           round(my_sum$mean, digits=2)\n                           ))\n\np <- ggplot(my_sum) +\n  geom_errorbar_interactive(aes(x=reorder(RACE,-mean),\n                    ymin=mean-2.58*se,    #<<<< formula to calc 95% CI\n                    ymax=mean+ 2.58*se,\n                    tooltip=tooltip),  \n                width = 0.2,\n                colour = 'black',\n                alpha = 0.9,\n                size=0.5) +\n    geom_point(aes(x=RACE,\n                 y=mean),\n             stat = 'identity', #<<< actual points refer to mean \n             color='red', \n             size = 1.5,\n             alpha = 1) + \n  labs(title='99% confidence interval of maths score by race',\n       x = 'Race') +\n  theme(axis.title.y=element_text(angle = 0,\n                                  vjust=0.9),\n        axis.text.x = element_text(angle = 45, hjust = 1),\n        axis.title = element_text(face = \"bold\"),\n        axis.line = element_line(size = 0.2))\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\nSTEP 2: CREATE AN INTERACTIVE DATA TABLE USING DT()\n\nWe use the %>% operator to pipe the data frame into the mutate_if() function, where we specify the condition is.numeric to select only the numeric columns. We use the tilde ~ symbol to specify the rounding function, and pass the digits argument to round to two decimal places. The resulting data frame df will have all numerical columns rounded to two decimal places.\n\n\n\nCode\n# Round all numerical columns to two decimal places\nmy_sum <- my_sum %>% \n  mutate_if(is.numeric, ~ round(., digits = 2))\n\nDT::datatable(my_sum, class='compact')\n\n\n\n\n\n\n\nSTEP 3: COMBINE BOTH\nNext, combine uncertainty graph and plotly interactive table using Crosstalk, which is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n(Refer to hands-on 3)\nThe datatable is linked to the visualisation on the left. Click on multiple rows to filter according.\n\n\nCode\n# Use highlight_key() to add a unique key to the data frame my_sum3 so that it can be linked to interactive plots later\nd <- highlight_key(my_sum) \n\n\np <- ggplot(d) +\n  geom_errorbar(aes(x=reorder(RACE,-mean),\n                    ymin=mean-2.58*se,    #<<<< formula to calc 95% CI\n                    ymax=mean+ 2.58*se),  \n                width = 0.2,\n                colour = 'black',\n                alpha = 0.9,\n                size=0.5) +\n    geom_point(aes(x=RACE,\n                 y=mean),\n             stat = 'identity', #<<< actual points refer to mean \n             color='red', \n             size = 1.5,\n             alpha = 1) + \n  labs(title='99% confidence interval of maths score by race',\n       x = 'Race') +\n  theme(axis.title.y=element_text(angle = 0,\n                                  vjust=0.9),\n        axis.text.x = element_text(angle = 45, hjust = 1),\n        axis.title = element_text(face = \"bold\"),\n        axis.line = element_line(size = 0.2))\n\n# Convert ggplot to an interactive plotly plot using the ggplotly(), \"plotly click\" specifies that highlight should be based on click\ngg <- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(list(width = 7,gg),\n                  list(width=5,DT::datatable(d)),\n                  widths=5)\n\n\n\n\n\n\n7\n\n\n\n\n5\n\n\n\n\n\n\n\nMy mistakes on the attempt to produce this plot:\n\nDid not use d in ggplot(d) and datatable(d) in crosstalk. As a result, the plot and table were both not able to communicate with each other.\nWrongly added geom_errorbar_interactive(aes(tooltip) and girafe together with plotly and crosstalk::bscols. As as result, no error bars were seen.\n\n\n\n\n\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\nstat_pointinterval means points and multiple intervals. The default confidence interval us 95%. To change the level to 99%, add conf.level = 0.99 to stat_pointinterval function.\nTake note that the default .width values are set to c(0.66, 0.95) confidence intervals.\n\n\nCode\nexam %>% \n  ggplot(aes(x=RACE,       #<< plot the base layer\n             y=MATHS)) +\n  stat_pointinterval() +   #<< .width=c(0.66,0.95)\n  labs(\n    title='Visualising confidence intervals of mean math score',\n    subtitle = \"Mean Point + Multiple-interval plot 66% and 95%\")\n\n\n\n\n\nSome of the arguments (there are many , have to read the syntax reference for more details)\n\n.width: For intervals, the interval width as a numeric value in [0, 1]. For slabs, the width of the smallest interval containing that value of the slab.\npoint_interval: This function determines the point summary (typically mean, median, or mode) and interval type (quantile interval, qi; highest-density interval, hdi; or highest-density continuous interval, hdci)\n\n\nCode\nexam %>%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot, 95% only\")\n\n\n\n\n\n\n\n\n\nTask: Makeover the plot on previous slide by showing 95% and 99% confidence intervals.\n\n\nCode\nexam %>%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  \n  #Using stat_pointinterval to plot the points and intervals\n  stat_pointinterval(.width = c(0.95,0.99),\n  .point = median,\n  .interval = qi,\n  aes(interval_color=stat(level)),\n  show.legend = FALSE) +\n  \n  #Defining the color of the intervals \n  scale_color_manual(\n    values = c(\"blue\", \"darkblue\"),\n    aesthetics = \"interval_color\") +\n  \n  #Title, subtitle, and caption\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot, 95% and 99%\")\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nstat(level) calculates the confidence interval limits based on the specified conf.level argument, and interval_color maps the calculated interval color to the interval_color argument.\n\n\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\n\nCode\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"green\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\n\n\n\n\n\nStep 1: Installing ungeviz package\n\n#devtools::install_github(\"wilkelab/ungeviz\")\n\n\nlibrary(ungeviz)\n\nWhat are HOPs? Rather than showing a continuous probability distribution, Hypothetical Outcome Plots (or HOPs) visualize a set of draws from a distribution, where each draw is shown as a new plot in either a small multiples or animated form.\nExplanation of the code below:\nThe code is creating a ggplot object to visualize the distribution of MATHS scores for different races in the exam dataset using the geom_point() and geom_hpline() functions from ggplot2.\nSpecifically, it is creating a scatterplot (geom_point()) of MATHS scores against RACE with some jitter (position_jitter()) added to the points to avoid overplotting. The factor() function is used to convert the RACE variable to a categorical variable.\nAdditionally, a horizontal line (geom_hpline()) is added to the plot to represent the median MATHS score for each race, calculated using sampler() function with 25 samples drawn from the original dataset for each race. The line is colored in #D55E00.\nThe transition_states() function is used to create an animation by specifying the .draw column as the states for the animation. The animation has 3 states (1, 2, 3) and will animate the plot with a transition between each state.\nFinally, the theme_bw() function is used to set the theme of the plot to a black and white color scheme.\n\n\nCode\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)\n\n\n\n\n\nA jitter plot is a variant of the strip plot with a better view of overlapping data points, used to visualise the distribution of many individual one-dimensional values. The values are plotted as dots along one axis, and the dots are then shifted randomly along the other axis, which has no meaning in itself data-wise, allowing the dots not to overlap."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#overview",
    "title": "Hands-on_Ex07",
    "section": "11.1 Overview",
    "text": "11.1 Overview\nFunnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#installing-and-launching-r-packages",
    "title": "Hands-on_Ex07",
    "section": "11.2 Installing and Launching R Packages",
    "text": "11.2 Installing and Launching R Packages\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-data",
    "title": "Hands-on_Ex07",
    "section": "11.3 Importing Data",
    "text": "11.3 Importing Data\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\nmutate_if will convert columns in chr format as factor.\n\n\ncovid19 <- read_csv('C:/yixin-neo/ISSS608-VAA/Hands-on_Ex/Hands-on_Ex05/data/COVID-19_DKI_Jakarta.csv') %>% \n  mutate_if(is.character, as.factor)\n\n\ncovid19\n\n# A tibble: 267 × 7\n   `Sub-district ID` City       District `Sub-district` Positive Recovered Death\n               <dbl> <fct>      <fct>    <fct>             <dbl>     <dbl> <dbl>\n 1        3172051003 JAKARTA U… PADEMAN… ANCOL              1776      1691    26\n 2        3173041007 JAKARTA B… TAMBORA  ANGKE              1783      1720    29\n 3        3175041005 JAKARTA T… KRAMAT … BALE KAMBANG       2049      1964    31\n 4        3175031003 JAKARTA T… JATINEG… BALI MESTER         827       797    13\n 5        3175101006 JAKARTA T… CIPAYUNG BAMBU APUS         2866      2792    27\n 6        3174031002 JAKARTA S… MAMPANG… BANGKA             1828      1757    26\n 7        3175051002 JAKARTA T… PASAR R… BARU               2541      2433    37\n 8        3175041004 JAKARTA T… KRAMAT … BATU AMPAR         3608      3445    68\n 9        3171071002 JAKARTA P… TANAH A… BENDUNGAN HIL…     2012      1937    38\n10        3175031002 JAKARTA T… JATINEG… BIDARA CINA        2900      2773    52\n# ℹ 257 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#funnelplotr-methods",
    "title": "Hands-on_Ex07",
    "section": "11.4 FunnelPlotR methods",
    "text": "11.4 FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n11.4.1 FunnelPlotR methods: The basic plot\nThe code chunk below plots a funnel plot.\n\n\nCode\nfunnel_plot(\n  numerator = covid19$Positive,\n  denominator = covid19$Death,\n  group = covid19$`Sub-district`\n)\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR” (stands for standardised Ratio)\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n11.4.2 FunnelPlotR methods: Makeover 1\nThe changes made:\n\ndata_type changed to ‘PR’, which stands for proportions of deaths/positive cases. (derieved using numerator and denominator)\nRanges of x and y axes to suit the visualisation\n\n\n\nCode\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",     #<<  proportions\n  xrange = c(0, 6500),  #<<\n  yrange = c(0, 0.05)   #<<\n)\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n11.4.3 FunnelPlotR methods: Makeover 2\nThe changes made:\n\nlabel = NA to remove the default outliers feature\nEdited the x and y axis titles to understand the chart better.\n\n\n\nCode\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative \\nTotal Number of COVID-19 Positive Cases\", #<<           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #<<\n  y_label = \"Cumulative Fatality Rate\"  #<<\n)\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on_Ex07",
    "section": "11.5 Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "11.5 Funnel Plot for Fair Visual Comparison: ggplot2 methods\nIn this section, Iwill gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance my working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n11.5.1 Computing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate (rate) and standard error of cumulative death rate (rate.se). Take note that the formula for SE of Proportions will be used here. (Lecture 4 slide 25)\n\ndf <- covid19 %>%\n  mutate(rate = Death / Positive) %>%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %>%\n  filter(rate > 0)\n\nNext, the fit.mean is computed by using the code chunk below.\nThe function calculates the weighted mean of the rate column in the df data frame, where the weights are the inverse squares of the corresponding standard errors (rate.se).\n\nfit.mean <- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\nfit.mean\n\n[1] 0.01496959\n\n\n\n\n11.5.2 Calculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\nThe number.seq creates a sequence of numbers from 1 to the maximum number of positive cases in the data frame. (max = 6231)\nWe then calculate the lower and upper 95% confidence intervals and the lower and upper 99.9% confidence intervals for the mean rate of death at each number in the sequence.\nFinally, a new data frame dfCI is created that contains the lower and upper confidence intervals and mean rate of death for each number in the sequence.\n\n\nCode\nnumber.seq <- seq(1, max(df$Positive), 1)\nnumber.ll95 <- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 <- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 <- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 <- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \n\n# creates a new dataframe using data.frame()\ndfCI <- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\n11.5.3 Plotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\n\nCode\np <- ggplot(df, aes(x = Positive, y = rate)) +  #<<< death rates vs positive case\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  \n  # 95% line is dashed\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  \n  # 99% line is solid\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\n11.5.4 Interactive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\n\nCode\nfp_ggplotly <- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview",
    "title": "Hands-on_Ex08 (Network graphs)",
    "section": "Overview",
    "text": "Overview\nIn this hands-on exercise, I will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, I will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "title": "Hands-on_Ex08 (Network graphs)",
    "section": "27.2 Getting Started",
    "text": "27.2 Getting Started\n\n27.2.1 Installing and launching R packages\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nThe code chunk:\n\n\nShow the code\npacman::p_load(igraph, tidygraph, ggraph,\n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts,knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-data",
    "title": "Hands-on_Ex08 (Network graphs)",
    "section": "27.3 The Data",
    "text": "27.3 The Data\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n27.3.1 The edges data\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\n\n27.3.2 The nodes data\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\n\n\n27.3.3 Importing network data from files\nIn this step, you will import GAStech_email_node.csv and GAStech_email_edges-v2.csv into RStudio environment by using read_csv() of readr package.\n\n\nShow the code\nGAStech_nodes <- read_csv('data/GAStech_email_node.csv')\nGAStech_edges <- read_csv('data/GAStech_email_edge-v2.csv')\n\n\n\n\n27.3.4 Reviewing the imported data\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\n\nShow the code\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 8\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\nShow the code\n# list()\n# summary()\n# class ()\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. We have to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n27.3.5 Wrangling time\n\n\nShow the code\nGAStech_edges <- GAStech_edges %>% \n  mutate(SentDate = dmy(SentDate)) %>% \n  mutate(Weekday = wday(SentDate,\n                         label = TRUE,  # ordered factor if true\n                         abbr = FALSE))\n\n\nCodes to check the number of unique Weekdays\n\n\nShow the code\nunique(GAStech_edges %>% pull(Weekday))\n\n\n[1] Monday    Tuesday   Wednesday Thursday  Friday   \n7 Levels: Sunday < Monday < Tuesday < Wednesday < Thursday < ... < Saturday\n\n\n\n\n\n\n\n\nLearning from codes above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number (1-7) or an ordered factor (Monday, Tuesday,..) if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n27.3.6 Reviewing the revised date fields\nTable below shows the data structure of the reformatted GAStech_edges with the correct data formats.\n\n\nRows: 9,063\nColumns: 9\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <date> 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ Weekday     <ord> Monday, Monday, Monday, Monday, Monday, Monday, Monday, Mo…\n\n\n\n\n27.3.7 Wrangling attributes\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will\n\nfilter Work related emails\ngroup-by senders, receivers and day of week\naggregate to get the total count of each unique combination of the above to get Weight as a new column\nfilter twice to remove self-loops and edges that occurred only once\nungroup() function is used to remove the grouping created by group_by() so that the resulting dataframe is not grouped by any variable(s) anymore. This is useful when we want to apply further operations or analysis to the individual rows of data rather than grouped results.\n\nThe code chunk:\n\n\nShow the code\nGAStech_edges_aggregated <- GAStech_edges %>%  # after filter 6935 rows remain\n  filter(MainSubject=='Work related') %>% \n  group_by(source, target, Weekday) %>% \n  summarise(Weight = n()) %>%           # 3706 rows remaining and Weight col added\n  filter(source != target) %>%          #3493 rows remaining\n  filter(Weight >1) %>%                # 1456 rows remaining\n  ungroup()                            # 1456 x 4 columns \n\n\n\n\n\n\n\n\nThings to learn from code above\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\nAfter ungroup(), we can analyse row by row instead of by unique combination of source, target and weekday\n\n\n\n\n\n27.3.8 Reviewing the revised edges file\nTable below shows the data structure of the reformatted GAStech_edges_aggregated data frame\n\n\nRows: 1,456\nColumns: 4\n$ source  <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  <dbl> 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7,…\n$ Weekday <ord> Monday, Tuesday, Wednesday, Friday, Monday, Tuesday, Wednesday…\n$ Weight  <int> 4, 3, 5, 8, 4, 3, 5, 8, 4, 3, 5, 8, 4, 3, 5, 8, 4, 3, 5, 8, 4,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on_Ex08 (Network graphs)",
    "section": "27.4 Creating network objects using tidygraph",
    "text": "27.4 Creating network objects using tidygraph\nIn this section, I will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way\n\nto switch between the two tables and provides dplyr verbs for manipulating them.\nto access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\n\nBefore getting started, please read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\n27.4.1 The tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n27.4.2 The dplyr verbs in tidygraph\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n%>% mutate(Species = ifelse(leaf, as.character(iris$Species)[label], NA)) - This line adds a new column called Species to the nodes data frame. The ifelse() function assigns a value to this column based on whether the node is a leaf or not. If it is a leaf, the value is taken from the label column of the iris$Species data frame (which contains the actual species names), and if it is not a leaf, the value is set to NA.\n%>% mutate(to_setose = .N()$Species[to] == 'setosa') - This line adds a new column called to_setose to the edges data frame. The ifelse() function assigns a value to this column based on whether the target node of each edge is a member of the setosa species or not. The to variable refers to the index of the target node in the nodes data frame, and the .N() function allows access to the Species column of the nodes data frame.\n\n\n\n27.4.3 Using tbl_graph() to build tidygraph data model.\nIn this section, I will use tbl_graph() of tidygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, review to reference guide of tbl_graph()\n\n\n\n\n\n\nRequired format of nodes and edges data\n\n\n\nGAStech_nodes has ID of nodes as first column. Label is optional?\nGAStech_edges_aggregated contains source and target as column 1 and 2.\n\n\n\n\nShow the code\nGAStech_graph<- tbl_graph(nodes=GAStech_nodes,\n                          edges = GAStech_edges_aggregated,\n                          directed = TRUE)\n\n\n\n\n27.4.4 Reviewing the output tidygraph’s graph object\n\n\nShow the code\nGAStech_graph\n\n\n# A tbl_graph: 54 nodes and 1456 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 54 × 4\n     id label               Department     Title                                \n  <dbl> <chr>               <chr>          <chr>                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# ℹ 48 more rows\n#\n# A tibble: 1,456 × 4\n   from    to Weekday   Weight\n  <int> <int> <ord>      <int>\n1     1     2 Monday         4\n2     1     2 Tuesday        3\n3     1     2 Wednesday      5\n# ℹ 1,453 more rows\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active (Node data is on top of Edge data). The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n27.4.6 Changing the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\n\nShow the code\nGAStech_graph %>% \n  activate(edges) %>% \n  arrange(desc(Weight))\n\n\n# A tbl_graph: 54 nodes and 1456 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 1,456 × 4\n   from    to Weekday Weight\n  <int> <int> <ord>    <int>\n1    40    41 Tuesday     23\n2    40    43 Tuesday     19\n3    41    43 Tuesday     15\n4    41    40 Tuesday     14\n5    42    41 Tuesday     13\n6    42    40 Tuesday     12\n# ℹ 1,450 more rows\n#\n# A tibble: 54 × 4\n     id label           Department     Title           \n  <dbl> <chr>           <chr>          <chr>           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands-on_Ex08 (Network graphs)",
    "section": "27.5 Plotting Static Network Graphs with ggraph package",
    "text": "27.5 Plotting Static Network Graphs with ggraph package\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n27.5.1 Plotting a basic network graph\nThe code chunk below uses\n\nggraph(),\ngeom-edge_link() and\ngeom_node_point() to plot a network graph by using GAStech_graph.\n\nBefore getting started, it is advisable to read their respective reference guide at least once.\n\n\nShow the code\nggraph(GAStech_graph) +  #<<< GAStech_graph is a tbl_graph object\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from code chunk above\n\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() canaccept either an igraph object or a tbl_graph object.\nigraph uses an adjacency matrix or an edge list and is more focused on traditional graph theory algorithms and operations.\nIn an edge list, each row represents an edge, with the first two columns containing the indices of the nodes that the edge connects.\ntidygraph uses a tbl_graph object, which is a tidy data frame representation of a graph. The nodes and edges data frames contain the metadata about the nodes and edges, respectively, and can be manipulated using the dplyr syntax\n\n\n\n\n\n27.5.2 Changing the default network graph theme\nIn this section, use theme_graph() to remove the x and y axes. Before getting started, it is advisable to read it’s reference guide at least once.\n\n\nShow the code\ng <- ggraph(GAStech_graph) +  #<<< GAStech_graph is a tbl_graph object\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nThings to learn form codes above\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\nShow the code\nclass(g)\n\n\n[1] \"ggraph\" \"gg\"     \"ggplot\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nObject g is a tbl graph object and is a dataframe with nodes, edges, and plot characteristics information. This dataframe changes everytime I overwrite g\n\n\n\n\nShow the code\ng <- ggraph(GAStech_graph) +  #<<< GAStech_graph is a tbl_graph object\n  geom_edge_link(aes(colour ='grey50'),show.legend = FALSE) +  #<< refer to ggraph documentation\n  geom_node_point(aes(colour ='grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'orange')\n\n\n\n\n\n\n\n27.5.4 Working with ggraph’s layouts\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n \n\n\n27.5.5 Fruchterman and Reingold layout\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\nTo change the layout of ggraphs, refer to ggraph_layout\n\n\nShow the code\ng <- ggraph(GAStech_graph, layout='fr') +  #<<< refer to ggraph_layout link above\n  geom_edge_link(aes()) +  #<< refer to ggraph documentation\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the codes above\n\n\n\n\nlayout argument is used to define the layout to be used.\n\n\n\n\n\n27.5.6 Modifying network nodes\nIn this section, I will colour each node by referring to their respective departments.\n\n\nShow the code\ng <- ggraph(GAStech_graph, layout='nicely') +  #<<< refer to ggraph_layout link above\n  geom_edge_link(aes()) +  #<< refer to ggraph documentation\n  geom_node_point(aes(colour=Department, size =3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code\n\n\n\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n\n\n27.5.7 Modifying edges\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable. geom_edge_link search individually\n\n\nShow the code\ng <- ggraph(GAStech_graph, layout='nicely') +  #<<< refer to ggraph_layout link above\n  geom_edge_link(aes(width=Weight, alpha= 0.2)) +  #<< thickness by weight and change alpha\n  scale_edge_width(range = c(0.1, 5)) +  #<< control max size of edge , else my plot is ugly\n  geom_node_point(aes(colour=Department, size =3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from codes above\n\n\n\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line.\n\n\n\nThe code chuck below assign colour to the nodes manually without hard-coding. I have also change the background and text colour.\n\nactivate the nodes df and extract the unique department using the pull() function\nuse length() function to find the nunique departments\nbrewer.pal() function generates a set of colors based on the number of unique departments\nsetNames() function is used to map the colors to the departments\nscale_color_manual() function is used to apply the color mapping to the Department nodes.\n\n\n\nShow the code\nlibrary(RColorBrewer)\n\n# Get unique departments from data\ndepartments <- unique(GAStech_graph %>% activate(nodes) %>% pull(Department))\n\n# Generate color palette based on number of unique departments\nnum_departments <- length(departments)\ncolor_palette <- brewer.pal(num_departments, \"Set3\")\n\n# Create color mapping for Department nodes\ncolor_mapping <- setNames(color_palette, departments)\n\n# Create plot with color mapping\nj <- ggraph(GAStech_graph, layout='fr') + \n     geom_edge_link(aes(alpha=0.1, colour='white'),show.legend = FALSE) +\n     geom_node_point(aes(colour=Department), size = 3) +\n     scale_color_manual(values = color_mapping) +\n     theme_graph(background = 'grey10',text_colour = 'orange')\nj\n\n\n\n\n\nIf choose to hard code, refer to the code chunk below. I have tried ‘star’ layout , wonder if the red adminstrative node in the middle is related to high centrality?\n\n\nShow the code\nggraph(GAStech_graph, layout='star') + \n     geom_edge_link(aes()) +\n     geom_node_point(aes(colour=Department), size =4) +\n     scale_color_manual(values = c(\"Administration\" = \"red\", \n                                   \"Engineering\" = \"blue\", \n                                   \"Executive\" = \"green\", \n                                   \"Facilities\" = \"purple\", \n                                   \"Information Technology\" = \"yellow\", \n                                   \"Security\" = \"pink\")) +\n     theme_graph()\n\n\n\n\n\nI have tried to color code the edges by Weekday. However this graph is hard to interpret due to overplotting. We should try to facet by Weekday instead.\n\n\nShow the code\ng <- ggraph(GAStech_graph) +  #<<< GAStech_graph is a tbl_graph object\n  geom_edge_link(aes(alpha=0.2, colour=Weekday)) +\n  geom_node_point()\n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#creating-facet-graphs",
    "title": "Hands-on_Ex08 (Network graphs)",
    "section": "27.6 Creating facet graphs",
    "text": "27.6 Creating facet graphs\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_edges() whereby nodes are always drawn in a panel even if the node data contains an attribute named the same as the one used for the edge facetting,\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n27.6.1 Working with facet_edges()\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once. Also can refer to ggraph().\n\n\nShow the code\nset_graph_style()   #<< using this command provide plot settings for next few plots\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\n\n\n\nset_graph_style() defaults\n\n\n\nRefer to thomas85github_theme_graph\n\nset_graph_style\n\n(family = ‘Arial Narrow’, face = ‘plain’, size = 11,\ntext_size = 11, text_colour = ‘black’, …)\n\nunset_graph_style() – to reset the graph style to default\n\n\n\n\n\n27.6.2 Working with facet_edges(): change legend position\nThe code chunk below uses theme() to change the position of the legend.\n\n\nShow the code\nset_graph_style()\n\ng<- ggraph(GAStech_graph,\n            layout='nicely') +\n  geom_edge_link(aes(width=Weight),\n                     alpha=0.2) +\n  scale_edge_width(range = c(0.1,5)) +\n  geom_node_point(aes(colour=Department),\n                  size =2) +\n  theme(legend.position = 'bottom')\n                   \n                   \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n27.6.3 A framed facet graph\nThe code chunk below adds frame to each graph.\n\n\nShow the code\nset_graph_style()\n\ng<- ggraph(GAStech_graph,\n           layout='nicely') +\n  geom_edge_link(aes(width=Weight),\n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1,5)) +\n  geom_node_point(aes(colour=Department),\n                  size = 2)\n\ng + facet_edges(~Weekday) +\n  th_foreground(foreground = 'steelblue',\n                fg_text_colour = 'white',\n                border = TRUE) +\n  \n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n27.6.4 Working with facet_nodes()\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\n\nShow the code\nset_graph_style()\n\ng<- ggraph(GAStech_graph,\n           layout='nicely') +\n  geom_edge_link(aes(width=Weight),\n                 alpha = 0.2) +\n  scale_edge_width(range = c(0.1,5)) +\n  geom_node_point(aes(colour=Department),\n                  size = 2)\n\ng + facet_nodes(~Department) +\n  th_foreground(foreground = 'steelblue',\n                fg_text_colour = 'white',\n                border = TRUE) +\n  \n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class_Ex01",
    "section": "",
    "text": "pacman:: p_load(tidyverse)\n\n\nexam_data <- read_csv(\"data1/Exam_data.csv\")\n\n\n\nIn this section, I will explore the theme_minimal() and modify the components of a theme (e.g. plot fill and gridline colours).\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal() +\n  theme(panel.background = element_rect(fill ='lavender', color ='white',linetype ='solid'),\n        panel.grid.major = element_line (color= 'white', linetype = 'solid'),\n        panel.grid.minor = element_line (colour='white', size= 0.2, linetype = 'solid'),\n        plot.title= element_text(size=rel(1.5))) +\n  ggtitle('Number of students by Race') +\n  labs(y='Number of students')\n\nReference website : R bloggers (How to change the background colour of ggplot2?)\nTo modify components of a theme , refer to this ggplot2 webpage\n\n\n\n\n\n\nThere are several flaws in the design below, namely:\n\ny-axis label is not clear (i.e. count)\nTo support effective comparison, the bars should be sorted by their respective frequencies.\nFor static graph, frequency values should be added to provide addition information. (labelled on the graph)\n\n\n\nCode\nggplot(data=exam_data,\n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\nThe designs below are improvised versions with the following features:\n\nBoth axes labelled clearly.\nBars are sorted by - count (descending order).\nCount and percentage are labelled above the bars.\n\n\nMakeover 1 (NYX)Makeover 1 code chunk\n\n\n\n\n\n\n\n\n\n\nexam_data %>%\n  group_by(RACE) %>% \n  summarise(count = n())\n\n# A tibble: 4 × 2\n  RACE    count\n  <chr>   <int>\n1 Chinese   193\n2 Indian     12\n3 Malay     108\n4 Others      9\n\n\nTHe output of the code below is C,M,I O\n\nt <- exam_data %>%\n  group_by(RACE) %>% \n  summarise(count = n())\n\nreorder(t$RACE, (-t$count))\n\n[1] Chinese Indian  Malay   Others \nattr(,\"scores\")\nChinese  Indian   Malay  Others \n   -193     -12    -108      -9 \nLevels: Chinese Malay Indian Others\n\n\n\nexam_data %>%\n  group_by(RACE) %>% \n  summarise(count = n()) %>% \n  ggplot(aes(x = reorder(RACE, (-count)), y = count)) +\n  geom_bar(stat = 'identity', color='black', fill = '#DD8888') +\n  ylim(0,220) +\n  geom_text(aes(label = paste0(count,', ', round(count/sum(count)*100,1), '%')),\n            position = position_dodge(width = 0.8), vjust= -1, size = 3.5) +\n  ggtitle('Distribution of Race') +\n  labs(y='No. \\nof \\nPupils', x = 'Race') +\n  theme(plot.title = element_text(face='bold', hjust = 0.5),   #bold title and center-justify\n        axis.title.y=element_text(angle=0)) \n\nMeaning of the argument ‘identity’ in the ‘stat’ parameter:\nIf we provide the argument stat=“identity” to geom_bar() then we’re telling R to calculate the sum of the y variable, grouped by the x variable and use bars to display the sums\nThere are three arguments in the reorder() function.\n\ncategorical variable to be sorted\nvariable to sort (1) by\na function that returns numerical value on how to sort (1) by\n\nReferences:\nhttps://www.roelpeters.be/reorder-ggplot2-bar-chart-by-count/ http://www.sthda.com/english/wiki/ggplot2-barplots-quick-start-guide-r-software-and-data-visualization#bar-plot-with-labels\n\n\n\n\nMakeover 2 (Prof)Makeover 2 code chunkUnderstanding Reorder()\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=reorder(RACE,RACE,\n                     function(x)-length(x)))) +\n  geom_bar() +\n  ylim(0,220) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(..count.., \", \", \n      round(..count../sum(..count..)*100, 1), \"%\")),\n      vjust=-1) +\n  xlab(\"Race\") +\n  ylab(\"No. of\\nPupils\") +\n  theme(axis.title.y=element_text(angle = 0))\n\n\n\nOutput of the code below is C,M,I,O\n\nreorder(exam_data$RACE,exam_data$RACE,function(x)-length(x))\n\n  [1] Malay   Malay   Chinese Chinese Malay   Malay   Chinese Malay   Malay  \n [10] Indian  Chinese Malay   Chinese Chinese Chinese Chinese Malay   Malay  \n [19] Malay   Malay   Malay   Malay   Chinese Others  Malay   Malay   Malay  \n [28] Malay   Indian  Indian  Malay   Malay   Chinese Malay   Chinese Malay  \n [37] Chinese Chinese Malay   Chinese Malay   Malay   Malay   Malay   Malay  \n [46] Chinese Chinese Chinese Indian  Malay   Chinese Chinese Chinese Malay  \n [55] Chinese Chinese Chinese Malay   Chinese Chinese Malay   Indian  Malay  \n [64] Chinese Malay   Malay   Malay   Malay   Chinese Chinese Malay   Malay  \n [73] Malay   Chinese Malay   Chinese Malay   Malay   Malay   Indian  Malay  \n [82] Malay   Chinese Chinese Malay   Indian  Chinese Chinese Chinese Chinese\n [91] Malay   Malay   Malay   Chinese Chinese Chinese Chinese Malay   Malay  \n[100] Malay   Chinese Chinese Chinese Chinese Malay   Chinese Chinese Others \n[109] Indian  Chinese Malay   Chinese Malay   Malay   Chinese Malay   Chinese\n[118] Chinese Chinese Chinese Malay   Malay   Malay   Chinese Malay   Malay  \n[127] Chinese Chinese Malay   Malay   Chinese Chinese Chinese Malay   Chinese\n[136] Chinese Malay   Others  Malay   Chinese Chinese Malay   Chinese Chinese\n[145] Chinese Malay   Chinese Chinese Malay   Others  Malay   Chinese Malay  \n[154] Malay   Chinese Chinese Malay   Chinese Others  Malay   Malay   Malay  \n[163] Malay   Chinese Malay   Chinese Chinese Others  Malay   Chinese Chinese\n[172] Chinese Chinese Chinese Chinese Chinese Chinese Chinese Chinese Chinese\n[181] Malay   Chinese Chinese Chinese Chinese Chinese Chinese Chinese Malay  \n[190] Chinese Chinese Chinese Chinese Chinese Malay   Chinese Indian  Malay  \n[199] Chinese Chinese Chinese Chinese Chinese Chinese Chinese Chinese Chinese\n[208] Chinese Chinese Chinese Chinese Malay   Chinese Chinese Chinese Chinese\n[217] Chinese Chinese Malay   Chinese Chinese Chinese Chinese Chinese Chinese\n[226] Chinese Chinese Chinese Chinese Chinese Malay   Chinese Chinese Chinese\n[235] Chinese Malay   Chinese Chinese Malay   Chinese Malay   Malay   Malay  \n[244] Chinese Chinese Indian  Malay   Others  Malay   Chinese Chinese Chinese\n[253] Chinese Chinese Malay   Malay   Chinese Chinese Chinese Chinese Chinese\n[262] Chinese Chinese Malay   Chinese Chinese Malay   Chinese Chinese Malay  \n[271] Chinese Malay   Chinese Others  Chinese Chinese Malay   Malay   Malay  \n[280] Chinese Indian  Chinese Chinese Chinese Chinese Chinese Malay   Chinese\n[289] Chinese Chinese Chinese Chinese Malay   Chinese Chinese Chinese Chinese\n[298] Chinese Malay   Malay   Chinese Chinese Chinese Chinese Chinese Chinese\n[307] Chinese Chinese Chinese Indian  Chinese Chinese Malay   Chinese Chinese\n[316] Chinese Chinese Chinese Others  Chinese Chinese Chinese\nattr(,\"scores\")\nChinese  Indian   Malay  Others \n   -193     -12    -108      -9 \nLevels: Chinese Malay Indian Others\n\n\n\n\n\n\nMakeover 3 (Forcats package)Makeover 3 code chunkUnderstanding fct_infreq\n\n\n\n\n\n\n\n\n\n\nexam_data %>%\n  mutate(RACE = fct_infreq(RACE)) %>%\n  ggplot(aes(x = RACE)) + \n  geom_bar()+\n  ylim(0,220) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(..count.., \", \", \n      round(..count../sum(..count..)*100,\n            1), \"%\")),\n      vjust=-1) +\n  xlab(\"Race\") +\n  ylab(\"No. of\\nPupils\") +\n  theme(axis.title.y=element_text(angle = 0))\n\n\n\nOutput of the code below is also C,M,I,O\n\nfct_infreq(exam_data$RACE)\n\n  [1] Malay   Malay   Chinese Chinese Malay   Malay   Chinese Malay   Malay  \n [10] Indian  Chinese Malay   Chinese Chinese Chinese Chinese Malay   Malay  \n [19] Malay   Malay   Malay   Malay   Chinese Others  Malay   Malay   Malay  \n [28] Malay   Indian  Indian  Malay   Malay   Chinese Malay   Chinese Malay  \n [37] Chinese Chinese Malay   Chinese Malay   Malay   Malay   Malay   Malay  \n [46] Chinese Chinese Chinese Indian  Malay   Chinese Chinese Chinese Malay  \n [55] Chinese Chinese Chinese Malay   Chinese Chinese Malay   Indian  Malay  \n [64] Chinese Malay   Malay   Malay   Malay   Chinese Chinese Malay   Malay  \n [73] Malay   Chinese Malay   Chinese Malay   Malay   Malay   Indian  Malay  \n [82] Malay   Chinese Chinese Malay   Indian  Chinese Chinese Chinese Chinese\n [91] Malay   Malay   Malay   Chinese Chinese Chinese Chinese Malay   Malay  \n[100] Malay   Chinese Chinese Chinese Chinese Malay   Chinese Chinese Others \n[109] Indian  Chinese Malay   Chinese Malay   Malay   Chinese Malay   Chinese\n[118] Chinese Chinese Chinese Malay   Malay   Malay   Chinese Malay   Malay  \n[127] Chinese Chinese Malay   Malay   Chinese Chinese Chinese Malay   Chinese\n[136] Chinese Malay   Others  Malay   Chinese Chinese Malay   Chinese Chinese\n[145] Chinese Malay   Chinese Chinese Malay   Others  Malay   Chinese Malay  \n[154] Malay   Chinese Chinese Malay   Chinese Others  Malay   Malay   Malay  \n[163] Malay   Chinese Malay   Chinese Chinese Others  Malay   Chinese Chinese\n[172] Chinese Chinese Chinese Chinese Chinese Chinese Chinese Chinese Chinese\n[181] Malay   Chinese Chinese Chinese Chinese Chinese Chinese Chinese Malay  \n[190] Chinese Chinese Chinese Chinese Chinese Malay   Chinese Indian  Malay  \n[199] Chinese Chinese Chinese Chinese Chinese Chinese Chinese Chinese Chinese\n[208] Chinese Chinese Chinese Chinese Malay   Chinese Chinese Chinese Chinese\n[217] Chinese Chinese Malay   Chinese Chinese Chinese Chinese Chinese Chinese\n[226] Chinese Chinese Chinese Chinese Chinese Malay   Chinese Chinese Chinese\n[235] Chinese Malay   Chinese Chinese Malay   Chinese Malay   Malay   Malay  \n[244] Chinese Chinese Indian  Malay   Others  Malay   Chinese Chinese Chinese\n[253] Chinese Chinese Malay   Malay   Chinese Chinese Chinese Chinese Chinese\n[262] Chinese Chinese Malay   Chinese Chinese Malay   Chinese Chinese Malay  \n[271] Chinese Malay   Chinese Others  Chinese Chinese Malay   Malay   Malay  \n[280] Chinese Indian  Chinese Chinese Chinese Chinese Chinese Malay   Chinese\n[289] Chinese Chinese Chinese Chinese Malay   Chinese Chinese Chinese Chinese\n[298] Chinese Malay   Malay   Chinese Chinese Chinese Chinese Chinese Chinese\n[307] Chinese Chinese Chinese Indian  Chinese Chinese Malay   Chinese Chinese\n[316] Chinese Chinese Chinese Others  Chinese Chinese Chinese\nLevels: Chinese Malay Indian Others\n\n\n\n\n\nSorting a boxplot by median of Math scores using reorder().\nIn the viz below, we are able to achieve several things in one go\n\nsort the boxplot by median of the Math scores in descending order.\nadd mean value by Race\nuse colours to distinguish between outliers and jitters\n\n\nBoxplot designCode ChunkReorder()\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam_data, aes(x = reorder(RACE, -MATHS, median), y = MATHS, fill=RACE)) +\n   geom_boxplot(outlier.colour=\"blue\", outlier.size=1) +\n   geom_point(position = 'jitter',size=0.5) +\n   stat_summary(fun.y=mean, geom=\"point\", shape=20, size=3, color=\"pink\", fill=\"red\") +\n   xlab(\"Race\") +\n   ylab(\"Math Score\") +\n   ggtitle(\"Math Scores by Race\") +\n   scale_fill_brewer(palette='Set2') +\n   theme(plot.title = element_text(hjust = 0.5),\n         legend.position = 'none')\n\nReference: Link\n\n\n\n\nCode\nreorder(exam_data$RACE, -exam_data$MATHS, median)\n\n\n  [1] Malay   Malay   Chinese Chinese Malay   Malay   Chinese Malay   Malay  \n [10] Indian  Chinese Malay   Chinese Chinese Chinese Chinese Malay   Malay  \n [19] Malay   Malay   Malay   Malay   Chinese Others  Malay   Malay   Malay  \n [28] Malay   Indian  Indian  Malay   Malay   Chinese Malay   Chinese Malay  \n [37] Chinese Chinese Malay   Chinese Malay   Malay   Malay   Malay   Malay  \n [46] Chinese Chinese Chinese Indian  Malay   Chinese Chinese Chinese Malay  \n [55] Chinese Chinese Chinese Malay   Chinese Chinese Malay   Indian  Malay  \n [64] Chinese Malay   Malay   Malay   Malay   Chinese Chinese Malay   Malay  \n [73] Malay   Chinese Malay   Chinese Malay   Malay   Malay   Indian  Malay  \n [82] Malay   Chinese Chinese Malay   Indian  Chinese Chinese Chinese Chinese\n [91] Malay   Malay   Malay   Chinese Chinese Chinese Chinese Malay   Malay  \n[100] Malay   Chinese Chinese Chinese Chinese Malay   Chinese Chinese Others \n[109] Indian  Chinese Malay   Chinese Malay   Malay   Chinese Malay   Chinese\n[118] Chinese Chinese Chinese Malay   Malay   Malay   Chinese Malay   Malay  \n[127] Chinese Chinese Malay   Malay   Chinese Chinese Chinese Malay   Chinese\n[136] Chinese Malay   Others  Malay   Chinese Chinese Malay   Chinese Chinese\n[145] Chinese Malay   Chinese Chinese Malay   Others  Malay   Chinese Malay  \n[154] Malay   Chinese Chinese Malay   Chinese Others  Malay   Malay   Malay  \n[163] Malay   Chinese Malay   Chinese Chinese Others  Malay   Chinese Chinese\n[172] Chinese Chinese Chinese Chinese Chinese Chinese Chinese Chinese Chinese\n[181] Malay   Chinese Chinese Chinese Chinese Chinese Chinese Chinese Malay  \n[190] Chinese Chinese Chinese Chinese Chinese Malay   Chinese Indian  Malay  \n[199] Chinese Chinese Chinese Chinese Chinese Chinese Chinese Chinese Chinese\n[208] Chinese Chinese Chinese Chinese Malay   Chinese Chinese Chinese Chinese\n[217] Chinese Chinese Malay   Chinese Chinese Chinese Chinese Chinese Chinese\n[226] Chinese Chinese Chinese Chinese Chinese Malay   Chinese Chinese Chinese\n[235] Chinese Malay   Chinese Chinese Malay   Chinese Malay   Malay   Malay  \n[244] Chinese Chinese Indian  Malay   Others  Malay   Chinese Chinese Chinese\n[253] Chinese Chinese Malay   Malay   Chinese Chinese Chinese Chinese Chinese\n[262] Chinese Chinese Malay   Chinese Chinese Malay   Chinese Chinese Malay  \n[271] Chinese Malay   Chinese Others  Chinese Chinese Malay   Malay   Malay  \n[280] Chinese Indian  Chinese Chinese Chinese Chinese Chinese Malay   Chinese\n[289] Chinese Chinese Chinese Chinese Malay   Chinese Chinese Chinese Chinese\n[298] Chinese Malay   Malay   Chinese Chinese Chinese Chinese Chinese Chinese\n[307] Chinese Chinese Chinese Indian  Chinese Chinese Malay   Chinese Chinese\n[316] Chinese Chinese Chinese Others  Chinese Chinese Chinese\nattr(,\"scores\")\nChinese  Indian   Malay  Others \n  -79.0   -58.5   -61.5   -70.0 \nLevels: Chinese Others Malay Indian\n\n\n\n\n\n\n\n\nThere are several flaws in the design below, namely:\n\nThe outline of the bars is unclear\nUnable to see how the scores are binned\nAddition of reference line (e.g. 75th percentile) will help users get a better understanding of the data.\n\n\n\nCode\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(binwidth=5)\n\n\n\n\n\nThe designs below are improvised version with the following features:\nMakeover 1:\n\nIncludes the 50th and 75th percentile line in the plot.\n\nMakeover 2:\n\nAdding mean and median lines on the histogram plot.\nChange fill color and line color\n\n\nMakeover design 1 (NYX)Makeover 1 code chunk (NYX)\n\n\n\n\n\n\n\n\n\n\nq <- quantile(exam_data$MATHS, probs = c(0.25, 0.5, 0.75))\n\nggplot(data=exam_data,\n  aes(x=MATHS)) +\n  geom_histogram(binwidth = 5, color='black',size= 0.3, fill = '#DD8888') +\n  geom_vline(xintercept = q[2], linetype='dotted', size = 0.8, color='blue') +\n  geom_vline(xintercept = q[3], linetype='dotted', size = 0.8) +\n  annotate('text' , x= 70, y=50, label='50th \\npercentile', size = 3) +\n  annotate('text' , x= 90, y=50, label='75th \\npercentile', size = 3) +\n  labs(y= 'No. of \\nPupils', x='math Score') +\n  theme(axis.title.y=element_text(angle = 0)) +\n  ggtitle('Distribution of Math scores')\n\nReference: link\n\n\n\n\nMakeover Design 2 (Adapted from Prof)Makeover 2 code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  geom_vline(aes(xintercept = mean(MATHS, na.rm=T)),\n             color='red',\n             linetype = 'dashed',\n             size = 1) +\n  annotate(\"text\", x=65, y=50, label=\"mean\", angle=0, size = 4) +\n  geom_vline(aes(xintercept = median(MATHS, na.rm=T)),\n             color='gray30',\n             linetype = 'dashed',\n             size = 1) +\n  annotate(\"text\", x=79, y=50, label=\"median\", angle=0, size = 4)\n\n\n\n\n\n\n\nThe viz below shows the distribution by gender. How can we make it more informative? Could we try to add a background layer of histogram that describe the overall distribution of ENGLISH scores?\n\n\nCode\nggplot(data=exam_data,\n       aes(x=ENGLISH, fill= GENDER)) +\n  geom_histogram(bins=20) +\n  facet_wrap(~GENDER)\n\n\n\n\n\nThe makeover design below now include overall distribution in the backgrounds of the trellis plots by gender.\n\nMakeover design 1Makeover 1 code chunk\n\n\n\n\n\n\n\n\n\n\nd_bg <- exam_data[, -3]  # background data without GENDER column\nggplot(data=exam_data,\n       aes(x=ENGLISH, fill=GENDER)) +\n  geom_histogram(data=d_bg, bins=20, fill='grey',alpha=0.5) +\n  geom_histogram(colour='black') +\n  facet_wrap(~GENDER) +\n  guides(fill=FALSE) + \n  theme_minimal() +\n  labs(y= 'No. of \\nPupils', x='English Score') +\n  theme(axis.title.y=element_text(angle = 0)) +\n  ggtitle('Distribution of English scores by Gender')\n\nThe geom_histogram() function is used twice to create two overlapping histograms.\nThe first histogram is created using the d_bg dataset (no GENDER data, rep all GENDERs) and is filled with grey. This histogram represents the background distribution of ENGLISH marks across ALL GENDERs.\nThe second histogram is created using the entire exam dataset and makes use of the fill = GENDER in ggplot() to color gender differently. This results in a legend and is removed with guides(fill=FALSE). It also has a black border. This histogram represents the distribution of ENGLISH scores for each individual GENDER.\nFinally, facet_wrap(~GENDER) will create panels to represent distribution for each GENDER for easy comparison.\nReference: Plot background histogram data\n\n\n\n\n\n\nThe original design below has several flaws:\n\nThe limits and scale ticks of both axes are inconsistent.\n\n\n\nCode\nggplot(data=exam_data,\n       aes(x=MATHS, y=ENGLISH)) +\n  geom_point()\n\n\n\n\n\nThe improvised design in Makeover 1 now includes:\n\nCommon x and Y axes scale and range.\nReference lines at 50 marks for both subjects.\n\n\nMakeover 1Makeover 1 code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS, y=ENGLISH)) +\n  geom_point() +\n  ylim(0,100) +\n  xlim(0,100) +\n  geom_vline(xintercept=50, linetype='dashed') +\n  geom_hline(yintercept=50, linetype='dashed')\n\n\n\n\nIn makeover 2, I have included a third numerical variable, Science score into the scatterplot.\nThe position of the legend has been shifted to the bottom.\nIn makeover 3, I have used the ggExtra library to add distribution of the English and Math scores in the form of histograms at the margins of the plot.\n\nMakeover 2Makeover 3\n\n\n\n\nCode\nggplot(data=exam_data,\n       aes(x=MATHS, y=ENGLISH)) +\n  geom_point(aes(color=SCIENCE)) +\n  ylim(0,100) +\n  xlim(0,100) +\n  geom_vline(xintercept=50, linetype='dashed') +\n  geom_hline(yintercept=50, linetype='dashed') +\n  ggtitle('Scatterplot of English and Math scores') +\n  theme_minimal() +\n  theme(legend.position='bottom') +\n  scale_color_gradient(low=\"darkgreen\", high=\"green\")\n\n\n\n\n\n\n\n\n\nCode\nlibrary(ggExtra)\n\nggMarginal(ggplot(data=exam_data,\n       aes(x=MATHS, y=ENGLISH)) +\n  geom_point(aes(color=SCIENCE)) +\n  ylim(0,100) +\n  xlim(0,100) +\n  geom_vline(xintercept=50, linetype='dashed') +\n  geom_hline(yintercept=50, linetype='dashed') +\n  ggtitle('Scatterplot of English and Math scores') +\n  theme_minimal() +\n  theme(legend.position='bottom') +\n  scale_color_gradient(low=\"darkgreen\", high=\"green\"), \n  \n  type=\"histogram\", fill =4)\n\n\n\n\n\nReference: ‘How to change ggplot2 colours manually and automatically?’"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class_Ex04",
    "section": "",
    "text": "In today’s in class exercise, Prof shared with us how to combine a qqplot and tabular results of Shapiro test in a single plot."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#import-libraries",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#import-libraries",
    "title": "In-class_Ex04",
    "section": "Import libraries",
    "text": "Import libraries\nThe new libraries used today are :\n\nrstatic: Allows us to perform basic statistical tests, including t-test, Wilcoxon test, ANOVA, Kruskal-Wallis and correlation analyses.\ngt() : starting from a tibble table, customise a table and export in various formats. Most importantly, it works with patch. We will save the tabular results from shapiro test as gt object and export using gtsave() into .png file later.\n\n\n\n\n\n\nOn importing data\n\n\n\n\nImporting tidyverse: will automatically provide read_r() <- for read_csv()\nread.csv() will insert ‘.’ between words. Thus we normally use read_csv()\nTo read excel files, load readxl and use read_xls()\n\n\n\n\n\npacman::p_load(rstatix, gt, patchwork,tidyverse,nortest)\n\n\nexam <- read_csv('C:/yixin-neo/ISSS608-VAA/Hands-on_Ex/Hands-on_Ex05/data/Exam_data.csv')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#background-info",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#background-info",
    "title": "In-class_Ex04",
    "section": "Background info",
    "text": "Background info\n\nThe Anderson_darling test\nUsually, when we check for normality of a distribution, we can use the Anderson-darling test or the Shapiro test. Hitting the three commands below will give us the results, but no visualisation.\n\nad.test(exam$ENGLISH)\n\n\n    Anderson-Darling normality test\n\ndata:  exam$ENGLISH\nA = 4.3661, p-value = 7.341e-11\n\n\n\n\nThe shapiro.test\nUsing shapiro.test will generate result as a HTML object.\n\nshapiro.test(exam$ENGLISH)\n\n\n    Shapiro-Wilk normality test\n\ndata:  exam$ENGLISH\nW = 0.9543, p-value = 1.811e-08\n\n\nUsing shapiro_test will generate result as a tibble object.\n\nexam %>% \n  shapiro_test(ENGLISH)\n\n# A tibble: 1 × 3\n  variable statistic            p\n  <chr>        <dbl>        <dbl>\n1 ENGLISH      0.954 0.0000000181\n\n\n\n\nQQplot\nWe can also generate the qqplot to check for normality. However qqplot does not print any p-values.\n\nggplot(exam,\n       aes(sample=ENGLISH)) +  #<<< use a new argument call sample: el scores\n  stat_qq() +\n  stat_qq_line()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#task-for-today",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#task-for-today",
    "title": "In-class_Ex04",
    "section": "Task for today:",
    "text": "Task for today:\n\nCombine qqplot with results from Shapiro-test.\nRecall that in hands-on 3, we use DT to create an interactive table , however it is not recognized by patchwork.\nWe start by storing the shapiro test in a tibble table as shown above. Then we will use the gt() package and export it as a .png using gtsave().\n\nqq <- ggplot(exam,\n       aes(sample=ENGLISH)) +  #<<< use a new argument call sample: el scores\n  stat_qq() +\n  stat_qq_line()\n\nsw_t <- exam %>% \n  shapiro_test(ENGLISH) %>% gt()   #<<< make into a gt format (will give a nice table)  shapiro.test is not used here as it gives output in another format.\n\ntmp <- tempfile(fileext = '.png') # create  temp table\ngtsave(sw_t, tmp)  # use gtsave() to save sw_t into tmp folder\ntable_png <- png::readPNG(tmp, native = TRUE)\n\nqq+table_png\n\n\n\n\nI tried to customise the gt() table.\n\nqq <- ggplot(exam,\n       aes(sample=ENGLISH)) +  #<<< use a new argument call sample: el scores\n  stat_qq() +\n  stat_qq_line()\n\nsw_t <- exam %>% \n  shapiro_test(ENGLISH) %>% gt()  %>%  \n  tab_header(\n    title = 'Shapiro Test for Normality',\n    subtitle = 'English scores')\n\ntmp <- tempfile(fileext = '.png') # create  temp table\ngtsave(sw_t, tmp)  # use gtsave() to save sw_t into tmp folder\ntable_png <- png::readPNG(tmp, native = TRUE)\n\nqq+table_png  # use patchwork to stitch\n\n\n\n\nThe results of the Shapiro test shows that p-value < 0.05 and we have enough statistical evidence to reject the null hypothesis and conclude that English scores do not follow normal distribution."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class_Ex05 (vast challenge Data)",
    "section": "",
    "text": "Note\n\n\n\nEdge data should be organised as such: (can use dplyr methods)\nFirst column: Source id (FK to Node second column) - compulsory\nSecond column: Target id (FK to Node second column) - compulsory\nNode data\nFirst column: ID - compulsory\nSecond column: Label (contains all the distinct values of source and target in Edge data) (only need if Id are all integers) (what is present in edge data must exists in Labels of node data, must not be missing in node data)\n\n\n\n\n\n\n\n\nWarning\n\n\n\nTry not to use R built-in NA/NULL function. Manually type “unknown’ / ‘missing’ as a value instead.\n\n\nIn today’s in class exercise,\nImport libraries\nThe new libraries used today are :\n\njsonlite to import json file\n\n\n\nShow the code\npacman::p_load(jsonlite, igraph, tidygraph, ggraph,\n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts,knitr)\n\n\n\n\nShow the code\nMC1 <- jsonlite::fromJSON(\"C:/yixin-neo/ISSS608-VAA/Project/data/MC1.json\")\n\n\n\n\n\n\n\n\nNote\n\n\n\nProblem with dataset of links:\nSource and Data columns are at the back instead of the first 2 columns\n\n\nPull out the nodes and edge data and save them as tibble data frames.\n\n\nShow the code\nMC1_nodes <- as_tibble(MC1$nodes) %>% \n  select(id,type,country)\n\n\n\n\nShow the code\nMC1_edges <- as_tibble(MC1$links) %>% \n  select(source,target,type,weight,key)  \n# can exclude dataste column as they all contain the same values.\n\n\nBack to GAStech dataset\n\n\nShow the code\nGAStech_nodes <- read_csv(\"C:/yixin-neo/ISSS608-VAA/Hands-on_Ex/Hands-on_Ex08/data/GAStech_email_node.csv\")\nGAStech_edges <- read_csv('C:/yixin-neo/ISSS608-VAA/Hands-on_Ex/Hands-on_Ex08/data/GAStech_email_edge-v2.csv')"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to my ISSS608 Visual Analytics and Applications HomePage! In this website, you will find my journey in using R for visualisation."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home_Ex01",
    "section": "",
    "text": "This exerise aims to reveal the demographic and financial characteristics of the city of Engagement, using appropriate static and interactive statistical graphics methods. It also requires a user-friendly and interactive solution that helps city managers and planners to explore the complex data in an engaging way and reveal hidden patterns.\nThe dataset consists of a sample survey of 1000 representative residents that collects data related to their household demographic and spending patterns, among other things. There are primarily two datasets used in this exercise\n\n’FinancialJournal.csv”: Contains 1513635 number of daily transaction records (different categories of income and expenses) over a period of twelve months from March 2022 to February 2023.\n’Particpants.csv” : Contains demographics information like household size, age, education level, interest groups, joviality index and whether each household has kids.\n\nIn this exercise, each dataset will be cleansed separately and then joined by ‘participantID’ as primary key to form the final dataset used for further analysis."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#install-and-load-the-required-libraries",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#install-and-load-the-required-libraries",
    "title": "Take-home_Ex01",
    "section": "2.1 Install and load the required libraries",
    "text": "2.1 Install and load the required libraries\nThe code chunk below uses pacman::p_load() to check if packages are installed. If they are, they will be launched into R. The packages installed are\n\nplotly: Used for creating interactive web-based graphs.\nknitr: Used for dynamic report generation\npatchwork: Used to combine plots\ntidyverse: A collection of core packages designed for data science, used extensively for data preparation and wrangling.\nggthemes: Provide additional themes for ggplot2\nggstatsplot: Used for creating graphics with details from statistical tests.\nggdist: Used for visualising distribution and uncertainty\nrstatix: Allows us to perform basic statistical tests, including t-test, Wilcoxon test, ANOVA, Kruskal-Wallis and correlation analyses.\ngt : starting from a tibble table, customise a table and export in various formats. Most importantly, it works with patch. We will save the tabular results from shapiro test as gt object and export using gtsave() into .png file later.\nggridges: a ggplot2 extension specially designed for plotting ridgeline plots.\n\n\npacman::p_load(plotly, knitr, patchwork, tidyverse, ggthemes,hrbrthemes, ggiraph, ggstatsplot, ggdist, ggridges, colorspace, png, gifski, rstatix, gt)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#import-the-dataset",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#import-the-dataset",
    "title": "Take-home_Ex01",
    "section": "2.2 Import the dataset",
    "text": "2.2 Import the dataset\nThe datasets are imported using tidyverse’s readr::read_csv() function.\n’FinancialJournal.csv” is stored as finance variable.\n\nfinance <- read_csv('data/FinancialJournal.csv')\n\n\n\n# A tibble: 6 × 4\n  participantId timestamp           category  amount\n          <dbl> <dttm>              <chr>      <dbl>\n1             0 2022-03-01 00:00:00 Wage      2473. \n2             0 2022-03-01 00:00:00 Shelter   -555. \n3             0 2022-03-01 00:00:00 Education  -38.0\n4             1 2022-03-01 00:00:00 Wage      2047. \n5             1 2022-03-01 00:00:00 Shelter   -555. \n6             1 2022-03-01 00:00:00 Education  -38.0\n\n\nCheck for empty values in the finance table using the is.na() function.\n\nany(is.na(finance))\n\n[1] FALSE\n\n\n’Particpants.csv” is stored as ptcp variable.\n\nptcp <- read_csv('data/Participants.csv')\n\n\n\n# A tibble: 6 × 7\n  participantId householdSize haveKids   age educationLevel      interestGroup\n          <dbl>         <dbl> <lgl>    <dbl> <chr>               <chr>        \n1             0             3 TRUE        36 HighSchoolOrCollege H            \n2             1             3 TRUE        25 HighSchoolOrCollege B            \n3             2             3 TRUE        35 HighSchoolOrCollege A            \n4             3             3 TRUE        21 HighSchoolOrCollege I            \n5             4             3 TRUE        43 Bachelors           H            \n6             5             3 TRUE        32 HighSchoolOrCollege D            \n# ℹ 1 more variable: joviality <dbl>\n\n\nChecking for empty values in ptcp table using the is.na()` function.\n\nany(is.na(ptcp))\n\n[1] FALSE"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-issues-and-wrangling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-issues-and-wrangling",
    "title": "Take-home_Ex01",
    "section": "2.3 Data Issues and wrangling",
    "text": "2.3 Data Issues and wrangling\nI will discuss the issues in the datasets and proposed cleaning methods.\n\n2.3.1 finance dataset issues:\n\nparticipantId should be converted from <dbl> format to <chr> format. It should be a categorical and not numerical data type.\ntimestamp should be converted from <dttm> format to <date> format as I will not be analysing time in this exercise.\nNegative values of amount that belong to the expenses categories should be converted to positive values. The amount will also be rounded to two decimal places.\n\nThe code chunk below does the following:\n\nuse the as.character() function to convert participantId to <chr> format\ncreate a new column month_year by extracting the year and month from the timestamp column using the format() function with the %Y-%m format specifier.\nuse the abs() function to convert negative values amount to positive and round the values to 2 decimal places using the round() function.\n\n\n# Convert participantId to character\nfinance <- finance %>% mutate(participantId = as.character(participantId))\n\n# Extract month and year from timestamp\nfinance <- finance %>% \n  mutate(month_year = format(timestamp, \"%m-%Y\"))\n\n# Transform negative amounts to positive and round to 2 decimal places\nfinance <- finance %>% \n  mutate(amount = abs(amount),\n         amount = round(amount, 2))\n\nA check for duplicates using the duplicated() function reveals that there are 1,113 records of duplicates.\n\nThe duplicated() function to identify the duplicate rows. It returns a logical vector indicating whether each row is a duplicate of a previous row in the data frame. We can then use this logical vector to subset the data frame and show the duplicate rows. The logical vector is stored in a filter duplicated_rows which is used to subset the finance data.\n\n\n# Show duplicate rows\nduplicated_rows <- finance[duplicated(finance),]\nglimpse(duplicated_rows)\n\nRows: 1,113\nColumns: 5\n$ participantId <chr> \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"3\", \"3\", \"4\", \"4\", \"5\", \"…\n$ timestamp     <dttm> 2022-03-01, 2022-03-01, 2022-03-01, 2022-03-01, 2022-03…\n$ category      <chr> \"Shelter\", \"Education\", \"Shelter\", \"Education\", \"Shelter…\n$ amount        <dbl> 554.99, 38.01, 554.99, 38.01, 556.55, 12.81, 554.99, 38.…\n$ month_year    <chr> \"03-2022\", \"03-2022\", \"03-2022\", \"03-2022\", \"03-2022\", \"…\n\n\n\nunique() function is used to remove the duplicate rows form finance data\n\n\n# Remove duplicate rows\nfinance <- unique(finance)\n\n\nPerform a final check to verify that there are no more duplicate using any() function\n\n\nany(duplicated(finance))\n\n[1] FALSE\n\n\nThe last thing to do is to create a new column date that is in <date> format using the as.Date function.\n\nthe paste0() function is used to concatenate “01-” with each value in the month_year column. This is because as.Date() requires a complete date in the format “dd-mm-yyyy”\n\nfinance$date <- as.Date(paste0(\"01-\", finance$month_year), format = \"%d-%m-%Y\")\n\n\nOther issues\nWhen the finance dataset is group-by the date variable , it is noticed that the number of distinct participantID who took part in the survey was 1,011 in March 2022 and suddenly reduced to a constant value of 880 from April 2022 onwards. It seems to suggest that there are 131 residents who moved out of the city at the end of March 2022.\nIn the code chunk below:\n\ndataset is group-by date and the distinct count of participantID is generated using n_distinct function\nthe missing dataframe is displayed below using knitr::kable() function\n\n\nmissing_summary <- finance %>%\n  group_by(date) %>% \n  summarise(n_distinct=n_distinct(participantId)) %>% \n  rename(`Number of unique participantId` = n_distinct)\n\nknitr::kable(missing_summary, \"simple\")\n\n\n\n\ndate\nNumber of unique participantId\n\n\n\n\n2022-03-01\n1011\n\n\n2022-04-01\n880\n\n\n2022-05-01\n880\n\n\n2022-06-01\n880\n\n\n2022-07-01\n880\n\n\n2022-08-01\n880\n\n\n2022-09-01\n880\n\n\n2022-10-01\n880\n\n\n2022-11-01\n880\n\n\n2022-12-01\n880\n\n\n2023-01-01\n880\n\n\n2023-02-01\n880\n\n\n\n\n\nSince 11 out of 12 months of records are missing for these 131 residents, we will delete their records from the finance dataset.\nThe code chunk below does the following:\n\nextract the participantIds of residents whose records exists in March 22 but not in all April 22 using the anti-join function\npass the unique participantId column name as an argument to pull() and use the as.vector() function to convert the resulting tibble column to a vector\nresulting dataframe will only contain participantIds that are in ‘2022-03-01’ but not in ‘2022-04-01’ onwards. There are 131 of them.\n\n\nmissing_id <- finance %>%\n  filter(date == as.Date('2022-03-01')) %>% # filter for '2022-03-01' date\n  anti_join(finance %>%\n             filter(date == as.Date('2022-04-01')), # filter for '2022-04-01' date\n             by = 'participantId') %>% # anti-join by 'participantId'\n  select(participantId) %>% \n  distinct(participantId)\n\n# extract participantId column as convert this column to vector.\nmissing_id_vector <- as.vector(pull(missing_id, participantId))\n\nmissing_id_vector \n\n  [1] \"44\"  \"127\" \"142\" \"154\" \"161\" \"256\" \"262\" \"267\" \"279\" \"285\" \"288\" \"298\"\n [13] \"301\" \"346\" \"352\" \"356\" \"380\" \"382\" \"383\" \"384\" \"392\" \"406\" \"407\" \"509\"\n [25] \"510\" \"512\" \"514\" \"523\" \"526\" \"539\" \"541\" \"553\" \"558\" \"567\" \"568\" \"572\"\n [37] \"574\" \"575\" \"577\" \"580\" \"589\" \"595\" \"599\" \"602\" \"603\" \"604\" \"605\" \"611\"\n [49] \"615\" \"617\" \"621\" \"628\" \"629\" \"634\" \"639\" \"641\" \"643\" \"647\" \"653\" \"655\"\n [61] \"657\" \"658\" \"663\" \"668\" \"670\" \"756\" \"757\" \"760\" \"761\" \"762\" \"768\" \"771\"\n [73] \"773\" \"774\" \"780\" \"785\" \"789\" \"790\" \"791\" \"792\" \"793\" \"794\" \"799\" \"802\"\n [85] \"806\" \"808\" \"816\" \"817\" \"818\" \"824\" \"825\" \"827\" \"828\" \"831\" \"832\" \"834\"\n [97] \"839\" \"842\" \"846\" \"847\" \"853\" \"855\" \"856\" \"858\" \"859\" \"860\" \"862\" \"864\"\n[109] \"867\" \"872\" \"875\" \"876\" \"883\" \"884\" \"885\" \"886\" \"887\" \"892\" \"896\" \"897\"\n[121] \"900\" \"901\" \"902\" \"907\" \"909\" \"911\" \"919\" \"920\" \"923\" \"924\" \"925\"\n\n\nNext, we will remove all records of the 131 potentially non-residents from the finance dataset .\nIn the code chunk below:\n\nthe %in% operator is to check if each id value is contained in the missing_id_vector\nthe negation operator ! ensures the resulting filtered data frame will not contain the rows where the id values are in missing_id_vector\n\n\nfinance1 <- finance[!finance$participantId %in% missing_id_vector, ]\nfinance1\n\n# A tibble: 1,509,897 × 6\n   participantId timestamp           category  amount month_year date      \n   <chr>         <dttm>              <chr>      <dbl> <chr>      <date>    \n 1 0             2022-03-01 00:00:00 Wage      2473.  03-2022    2022-03-01\n 2 0             2022-03-01 00:00:00 Shelter    555.  03-2022    2022-03-01\n 3 0             2022-03-01 00:00:00 Education   38.0 03-2022    2022-03-01\n 4 1             2022-03-01 00:00:00 Wage      2047.  03-2022    2022-03-01\n 5 1             2022-03-01 00:00:00 Shelter    555.  03-2022    2022-03-01\n 6 1             2022-03-01 00:00:00 Education   38.0 03-2022    2022-03-01\n 7 2             2022-03-01 00:00:00 Wage      2437.  03-2022    2022-03-01\n 8 2             2022-03-01 00:00:00 Shelter    557.  03-2022    2022-03-01\n 9 2             2022-03-01 00:00:00 Education   12.8 03-2022    2022-03-01\n10 3             2022-03-01 00:00:00 Wage      2367.  03-2022    2022-03-01\n# ℹ 1,509,887 more rows\n\n\nWe will double check that the records of 131 non-residents have been removed from finance1 dataframe.\nIn the code below\n\ndistinct() function to extract the distinct participantId values from finance1\nthe n_distinct() function will count the number of distinct participantId values in the resulting tibble\n\n\nfinance1 %>% \n  distinct(participantId) %>% \n  n_distinct()\n\n[1] 880\n\n\n\n\n2.3.2 ptcp dataset issues:\n\nparticipantId should be converted from <dbl> format to <chr> format\nhouseholdSize should be converted from <dbl> format to <fct> format. It does not make sense to have 2.5 persons.\nage should be converted from <dbl> format to <int> format.\neducationLevel should be converted from <chr> to <fct> . It should also be ordered according to ‘Low’, ‘HighSchoolOrCollege’, ‘Bachelors’ and ‘Graduate’.\n\nThe code chunk below does the following:\n\nas.character and as.factor functions are used to convert participantId to <chr> , householdSize to <fct> and age to <int>.\nfactor(educationLevel, levels=c(\"Low\", \"HighSchoolOrCollege\", \"Bachelors\", \"Graduate\"))) not only converts educationLevel to factor, but also order the values inside.\n\n\n# convert to factor\nptcp <- ptcp %>% mutate(participantId = as.character(participantId))\nptcp <- ptcp %>% mutate(householdSize = as.factor(householdSize))\n\n# Convert educationLevel to factor and order accordingly\nptcp <- ptcp %>% mutate(educationLevel = factor(educationLevel, levels=c(\"Low\", \"HighSchoolOrCollege\", \"Bachelors\", \"Graduate\")))\n\n# convert age to int\nptcp <- ptcp %>% mutate(age = as.integer(age))\n\nThe columns format are all in order now.\n\nglimpse(ptcp)\n\nRows: 1,011\nColumns: 7\n$ participantId  <chr> \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\",…\n$ householdSize  <fct> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ haveKids       <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T…\n$ age            <int> 36, 25, 35, 21, 43, 32, 26, 27, 20, 35, 48, 27, 34, 18,…\n$ educationLevel <fct> HighSchoolOrCollege, HighSchoolOrCollege, HighSchoolOrC…\n$ interestGroup  <chr> \"H\", \"B\", \"A\", \"I\", \"H\", \"D\", \"I\", \"A\", \"G\", \"D\", \"D\", …\n$ joviality      <dbl> 0.001626703, 0.328086500, 0.393469590, 0.138063446, 0.8…\n\n\nUse distinct() and n_distinct() to check on the number of unique participantIds in ptcp table.\n\nptcp %>% \n  distinct(participantId) %>% \n  n_distinct()\n\n[1] 1011\n\n\nCurrently, the ptcp table still contain the demographic records of the 131 residents who moved out. Let us remove their records by using similar method used in removing the same records in financial table.\n\nptcp1 <- ptcp[!ptcp$participantId %in% missing_id_vector, ]\n\nptcp1 %>% \n  distinct(participantId) %>% \n  n_distinct()\n\n[1] 880\n\n\nBoth finance1 and ptcp1 tables now contains information about the same number of participantIds.\n\n\n2.3.3 Convert finance1 table to wide format and perform left outer join with ptcp1 table.\nWe will now convert the finance1 dataframe from a long to a wide format. The code chunk below does the following:\n\ngroup the data by participantId , date and category using the group_by function\nuse the sum function to calculate the total monthly amount for each category per participantId per month\nthe pivot_wider function will convert the category column to wide format with total monthly values in the amount column.\n\nfinance1_wide<- finance1 %>%\n  group_by(participantId, date, category) %>%\n  summarise(total_amount = sum(amount)) %>%\n  pivot_wider(names_from = category, values_from = total_amount)\n\n\n\n# A tibble: 10,560 × 8\n# Groups:   participantId, date [10,560]\n   participantId date       Education  Food Recreation Shelter   Wage\n   <chr>         <date>         <dbl> <dbl>      <dbl>   <dbl>  <dbl>\n 1 0             2022-03-01      38.0  268.      349.     555. 11932.\n 2 0             2022-04-01      38.0  266.      219.     555.  8637.\n 3 0             2022-05-01      38.0  265.      383.     555.  9048.\n 4 0             2022-06-01      38.0  257.      466.     555.  9048.\n 5 0             2022-07-01      38.0  270.     1069.     555.  8637.\n 6 0             2022-08-01      38.0  262.      314.     555.  9459.\n 7 0             2022-09-01      38.0  256.      295.     555.  9048.\n 8 0             2022-10-01      38.0  267.       25.0    555.  8637.\n 9 0             2022-11-01      38.0  261       377.     555.  9048.\n10 0             2022-12-01      38.0  266.      357.     555.  9048.\n# ℹ 10,550 more rows\n# ℹ 1 more variable: RentAdjustment <dbl>\n\n\n\n\n\n\n\n\nNote\n\n\n\nAbout finance1_wide table\nfinance_wide is a table that has one row for each unique combination of participantId and month and one column for each unique category from the former finance1 table.\n\n\nThe code chunk below performs a left outer join with finance1_wide table (left) and ptcp1 table (right) with join key participantId.\n\n# left outer join\nfinance1_wide_ptcp1 <- left_join(finance1_wide, ptcp1, by = \"participantId\")\n\nThe first 12 rows of the cleansed finance1_wide_ptcp1 is displayed using knitr::kable() function. It contains 10,560 rows and 14 columns.\n\nknitr::kable(head(finance1_wide_ptcp1,12), \"simple\") \n\n\n\n\nparticipantId\ndate\nEducation\nFood\nRecreation\nShelter\nWage\nRentAdjustment\nhouseholdSize\nhaveKids\nage\neducationLevel\ninterestGroup\njoviality\n\n\n\n\n0\n2022-03-01\n38.01\n268.26\n348.68\n554.99\n11931.95\nNA\n3\nTRUE\n36\nHighSchoolOrCollege\nH\n0.0016267\n\n\n0\n2022-04-01\n38.01\n265.79\n219.42\n554.99\n8636.88\nNA\n3\nTRUE\n36\nHighSchoolOrCollege\nH\n0.0016267\n\n\n0\n2022-05-01\n38.01\n264.54\n382.99\n554.99\n9048.16\nNA\n3\nTRUE\n36\nHighSchoolOrCollege\nH\n0.0016267\n\n\n0\n2022-06-01\n38.01\n256.90\n465.67\n554.99\n9048.16\nNA\n3\nTRUE\n36\nHighSchoolOrCollege\nH\n0.0016267\n\n\n0\n2022-07-01\n38.01\n270.13\n1069.48\n554.99\n8636.88\nNA\n3\nTRUE\n36\nHighSchoolOrCollege\nH\n0.0016267\n\n\n0\n2022-08-01\n38.01\n261.76\n314.13\n554.99\n9459.44\nNA\n3\nTRUE\n36\nHighSchoolOrCollege\nH\n0.0016267\n\n\n0\n2022-09-01\n38.01\n256.04\n294.64\n554.99\n9048.16\nNA\n3\nTRUE\n36\nHighSchoolOrCollege\nH\n0.0016267\n\n\n0\n2022-10-01\n38.01\n266.67\n25.01\n554.99\n8636.88\nNA\n3\nTRUE\n36\nHighSchoolOrCollege\nH\n0.0016267\n\n\n0\n2022-11-01\n38.01\n261.00\n377.41\n554.99\n9048.16\nNA\n3\nTRUE\n36\nHighSchoolOrCollege\nH\n0.0016267\n\n\n0\n2022-12-01\n38.01\n265.98\n356.69\n554.99\n9048.16\nNA\n3\nTRUE\n36\nHighSchoolOrCollege\nH\n0.0016267\n\n\n0\n2023-01-01\n38.01\n264.97\n209.77\n554.99\n9048.16\nNA\n3\nTRUE\n36\nHighSchoolOrCollege\nH\n0.0016267\n\n\n0\n2023-02-01\n38.01\n239.05\n319.93\n554.99\n8225.60\nNA\n3\nTRUE\n36\nHighSchoolOrCollege\nH\n0.0016267"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#wage-and-categories-of-expenses",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#wage-and-categories-of-expenses",
    "title": "Take-home_Ex01",
    "section": "3.1 Wage and categories of expenses",
    "text": "3.1 Wage and categories of expenses\nIn this section, I will explore the dataset from high level and then zoom into interesting patterns (if I can find any =))\n\n3.1.1 Normality assumptions of annual wage\nBefore zooming into wages in March, we will first perform a test to confirm whether wages in March follows the normal distribution.\nH0: The wage does not follow a normal distribution.\nH1: The wage follows a normal distribution.\n\n\nCode\nmarch_records <- finance1_wide_ptcp1 %>% \n               filter(date == as.Date(\"2022-03-01\"))\n\nqq <- ggplot(march_records,\n             aes(sample=Wage)) +\n  \n  stat_qq() +\n  stat_qq_line() +\n  ggtitle(\"QQ plot with Shapiro-Wilk test results\")  # add plot title\n\nsw_t <- shapiro_test(march_records$Wage) %>% \n  as_tibble() %>% \n  mutate(variable = \"Wage in March\")%>% gt()  #<<< make into a gt format (will give a nice table)  shapiro.test is not used here as it gives output in another format.\n\ntmp <- tempfile(fileext = '.png') # create  temp table\ngtsave(sw_t, tmp)  # use gtsave() to save sw_t into tmp folder\ntable_png <- png::readPNG(tmp, native = TRUE)\n\nqq+table_png\n\n\n\n\n\nFrom the Shapiro test , p-value < 0.05 and we have enough statistical evidence to reject the null hypothesis and conclude that Wage in March does not follow the normal distribution.\n\n\n3.1.2 Interactive Line charts of wages by month\nPreparing the data, creating a highlevel dataframe containing the rows date (month) and aggregated columns of expenses and wage only.\n\n\nCode\nhighlevel <- finance1_wide_ptcp1 %>%\n  group_by(date) %>%\n  summarize(Education = round(sum(Education, na.rm = TRUE)),\n                Food = round(sum(Food, na.rm = TRUE)),\n                Recreation = round(sum(Recreation, na.rm = TRUE)),\n                Shelter = round(sum(Shelter, na.rm = TRUE)),\n                Wage = round(sum(Wage, na.rm = TRUE)),\n                RentAdjustment = round(sum(RentAdjustment, na.rm = TRUE)),\n                ExpenseP = sum(Education, Food, Recreation, Shelter),  #<<<\n                Income = sum(Wage, RentAdjustment),                    #<<<\n                Saving = Income - ExpenseP,                            #<<<\n                Expense = ExpenseP * -1                                #<<<\n                )\nhead(highlevel,5)\n\n\n# A tibble: 5 × 11\n  date       Education   Food Recreation Shelter    Wage RentAdjustment ExpenseP\n  <date>         <dbl>  <dbl>      <dbl>   <dbl>   <dbl>          <dbl>    <dbl>\n1 2022-03-01     11424 320126     649580  631623 6068610          53504  1612753\n2 2022-04-01     11424 304282     389688  559919 3468757           1429  1265313\n3 2022-05-01     11424 313538     336413  558451 3623068              0  1219826\n4 2022-06-01     11424 302893     314804  558451 3608883              0  1187572\n5 2022-07-01     11424 313803     329608  558451 3485799              0  1213286\n# ℹ 3 more variables: Income <dbl>, Saving <dbl>, Expense <dbl>\n\n\nAn interactive line chart showing us an overview of total income across months.\n\n\nCode\nlibrary(scales)\n\nq1<-highlevel %>%\n  ggplot(aes(x = date)) +\n  geom_line(aes(y = Wage, color = \"Red\", linetype = \"Wage\"), size = 1) +\n\n  \n  # annotating the plot\n  geom_text(aes(x=as.Date(\"2022-04-01\"),\n                y=6000000,\n                label=\"High wages \\nobserved in \\nMarch\"), \n            hjust=1, vjust=1, color='black', size=2.5) +\n  geom_text(aes(x=as.Date(\"2022-12-01\"), y=3800000, label=\"Wage\"),\n            hjust=1, vjust=1,color='red', size=2.5) +\n\n\n  # scale control\n  labs(x = \"Month\", y = \"Amount\") +\n  scale_x_date(date_breaks = '1 month',date_labels = \"%b %Y\") +\n  scale_y_continuous(limits = c(0, 6500000), breaks=seq(0, 6500000, 1000000),\n                     labels= comma) +\n  \n  theme_light(base_size = 12) +\n  theme(axis.title = element_text(size = 10 , face = \"bold\"),\n        axis.text = element_text(size = 10),\n        axis.text.x = element_text(angle = 45, hjust = 1),\n        axis.line = element_line(size = 1),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor = element_line(colour='black'),\n        panel.border = element_blank(),\n        legend.position = \"none\",\n        legend.title = element_blank()) +\n\n\n  labs(title= 'Cumulative Income across Months',\n       x='Month',\n       y='Amount')\n\nggplotly(q1,tooltip = c('labels','x','y'))\n\n\n\n\n\n\n\n\n3.1.3 Boxplot, One-way Anova and Error Plot of wage across months\nNow we willl examine the distribution of wages across the months by education levels using boxplots.\n\nBoxplotsOne way Anova plotError plots\n\n\nThe boxplot shows the distribution of wages of the residents across all the months. The red dot represents the median wage of that month. Wage is much higher in March and possible reasons could be due to Harvest / Bonus month. Are the medians of the month wage significantly different from one another? (See next tab)\n\n\nCode\nlibrary(lubridate)\n\ndf_wage_edu_month <- finance1_wide_ptcp1 %>%\n  mutate(month = month(date))\n\ndf_wage_edu_month$month <- factor(month(finance1_wide_ptcp1$date), \n                                  levels = c(3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2), \n                                  labels = c(\"Mar 22\", \"Apr 22\", \"May 22\", \"Jun 22\", \"Jul 22\", \"Aug 22\", \"Sep 22\", \"Oct 22\", \"Nov 22\", \"Dec 22\", \"Jan 23\", \"Feb 23\"))\n\n\nggplot(df_wage_edu_month,\n       aes(x = month, y = Wage)) +\n  geom_boxplot(aes(fill = educationLevel)) +\n  stat_summary(fun.y = \"median\", geom = \"point\", color = \"red\", size = 2) +\n  labs(x = \"Month\", y = \"Wage\", fill = \"Education Level\", title='Wage Across education level by month') +\n  scale_fill_brewer(palette=\"RdBu\") + \n  theme_minimal() +\n  theme(legend.key.size = unit(0.5,'cm'),\n        legend.position=\"bottom\",\n        plot.title = element_text(size = 12,\n                                  face='bold'),\n        axis.title = element_text(size = 11 , face = \"bold\"),\n        axis.text = element_text(size = 10),\n        axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\nSince the wages in March does not follow a normal distribution, we will use a non parametric test for testing. (As long as one of the wage distribution across the months do not follow normal distribution, choose non-parametric test).\nThe plot below shows us the pairs of months where wage are significantly different. The plot shows that Median Wage of March is significantly different from all the wages of the other months.\nCheck the next tab to see the error plots.\n\n\nCode\nggbetweenstats(data = df_wage_edu_month, x = month, y = Wage,\n               xlab = \"Month\", ylab = \"Wage\",\n               type = \"np\", pairwise.comparisons = TRUE, pairwise.display = \"s\",\n               sort = \"descending\",\n               sort.fun = median,\n               mean.ci = T, p.adjust.method = \"fdr\",  conf.level = 0.95,\n               title = \"Comparison of Median Wage across Months\") +\n # scale_y_continuous(limits = c(0, 300000)) +\n   theme(axis.title.y=element_text(angle = 0,\n                                  vjust=0.9))\n\n\n\n\n\n\n\nAs we are analyzing survey data, each of our sample mean could vary from the actual population mean. Thus we have to visualize the margin of error. The higher the CI, the higher the margin of error.\n95% and 99% confidence intervals are constructed for the median wage for each month.\nNote: A confidence level of 95% means the true result will be within the error bar range 95 times out of 100 sampling tries.\n\n\nCode\ndf_wage_edu_month %>%\n  ggplot(aes(x = month, y = Wage)) +\n  \n  #Using stat_pointinterval to plot the points and intervals\n  stat_pointinterval(.width = c(0.95,0.99),\n  .point = median,\n  .interval = qi,\n  aes(interval_color=stat(level)),\n  show.legend = FALSE) +\n  \n  #Defining the color of the intervals \n  scale_color_manual(\n    values = c(\"blue\", \"darkblue\"),\n    aesthetics = \"interval_color\") +\n  \n  #Title, subtitle, and caption\n  labs(\n    title = \"Visualising confidence intervals of median wage\",\n    subtitle = \"Median Point + Multiple-interval plot, 95% and 99%\",\n    x = \"Months\", y = \"Wage\") +\n  \n  theme_ipsum() +\n  \n  theme(axis.title = element_text(size = 10 , face = \"bold\"),\n        axis.text = element_text(size = 10),\n        axis.title.y=element_text(angle = 0, \n                                  vjust=0.9, \n                                  size = 10, \n                                  face='bold'),\n        axis.title.x=element_text(size = 10,\n                                   face='bold'),\n        axis.text.x = element_text(angle = 45,\n                                   hjust = 1),\n        plot.title = element_text(size = 12,\n                                  face='bold'),\n        panel.border = element_blank(),\n        panel.grid.major = element_blank())\n\n\n\n\n\n\n\n\n\n\n3.1.4 Interactive Line charts of expenditures by month\nDesign considerations:\nInstead of combining Education, Recreation, Food and Shelter expense in one chart, I have plotted them on one chart each with different Y axis range. This will be enable us to visualise variability of amount across categories clearly.\n\n\nCode\ns <- highlevel %>%\n  plot_ly(x = ~date, y = ~Shelter, type = 'scatter', mode = 'lines', name='Shelter') %>%\n  layout(\n         xaxis = list(title = \"Date\"), \n         yaxis = list(title = \"Shelter\"),\n         plot_bgcolor = \"#e5ecf6\")\n\n\ne <- highlevel %>%\n  plot_ly(x = ~date, y = ~Education, type = 'scatter', mode = 'lines', name='Education') %>%\n  layout(xaxis = list(title = \"Date\"), yaxis = list(title = \"Education\"))\n\nf <- highlevel %>%\n  plot_ly(x = ~date, y = ~Food, type = 'scatter', mode = 'lines', name='Food') %>%\n  layout(xaxis = list(title = \"Date\"), yaxis = list(title = \"Food\"))\n\nr <- highlevel %>%\n  plot_ly(x = ~date, y = ~Recreation, type = 'scatter', mode = 'lines', name='Recreation') %>%\n  layout(xaxis = list(title = \"Date\"), yaxis = list(title = \"Recreation\"))\n\n#subplot(s, e, f, r,titleX=TRUE, titleY=TRUE, nrows = 2, margin = 0.1) %>% layout(title = \"Custom Hover Text\")\n\nsubplot(s, e, f, r, shareX=TRUE, titleY=TRUE, nrows = 2, margin = 0.1) %>%\n  layout(title = \"<b>Annual expenses by month<b>\",\n         plot_bgcolor='#e5ecf6', \n         xaxis = list( \n           zerolinecolor = '#ffff', \n           zerolinewidth = 2, \n           gridcolor = 'ffff'), \n         yaxis = list( \n           zerolinecolor = '#ffff', \n           zerolinewidth = 2, \n           gridcolor = 'ffff'))\n\n\n\n\n\n\nFrom all the plots above, March seems to be an exciting month where there is several anomalies observed. There are unusual spikes in wage, recreational and shelter spending.\nNext, we will plot a coordinated dotplot to studying the distribution of expenses. Since we have the daily trasnaction data of participant, which we can aggregate to find the annual spending for each type of expense.\nFirst prepare the annual dataframe that contains participantId, their demographics data (e.g. educationLevel, haveKids etc.. ) and annual expense amount (e.g. Education, Shelter etc..) . The first 5 rows of the annual df is displayed using knitr::kable() function. It contains 880 rows and 12 columns.\n\n\nCode\nannual <- finance1_wide_ptcp1 %>% \n  group_by(participantId, householdSize, haveKids, educationLevel, interestGroup, joviality) %>% \n  summarize(Education = sum(Education, na.rm = TRUE),\n            Food = sum(Food, na.rm = TRUE),\n            Recreation = sum(Recreation, na.rm = TRUE),\n            Shelter = sum(Shelter, na.rm = TRUE),\n            Wage = sum(Wage, na.rm = TRUE),\n            RentAdjustment = sum(RentAdjustment, na.rm = TRUE)) \n\nknitr::kable(head(annual,3), \"simple\")\n\n\n\n\n\nparticipantId\nhouseholdSize\nhaveKids\neducationLevel\ninterestGroup\njoviality\nEducation\nFood\nRecreation\nShelter\nWage\nRentAdjustment\n\n\n\n\n0\n3\nTRUE\nHighSchoolOrCollege\nH\n0.0016267\n456.12\n3141.09\n4383.82\n6659.88\n109816.59\n0\n\n\n1\n3\nTRUE\nHighSchoolOrCollege\nB\n0.3280865\n456.12\n3167.93\n6637.42\n6659.88\n96374.57\n0\n\n\n10\n3\nTRUE\nHighSchoolOrCollege\nD\n0.5571760\n153.72\n4739.39\n3087.83\n6730.80\n79304.72\n0\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the na.rm = TRUE argument is used in the sum function to handle missing values in the columns during aggregation.\n\n\n\n\n3.1.5 Coordinated interactive dotplot of amount spent across categories\nHovering the cursor over the dots will show whether a participant have kids (True) or do not have kids (False). A participant will incur educational expenses when they have kids. Also observed that those with kids are among those who spend slightly more in shelter.\n\n\nCode\nsdot <- ggplot(data=annual,\n            aes(x=Shelter)) +\n  geom_dotplot_interactive(aes(tooltip = haveKids,  #<<<\n                               data_id = haveKids),  #<<<\n                           stackgroups = TRUE,\n                           #binwidth = 2500,\n                           method = \"histodot\",\n                           dotsize= 0.2) +\n  scale_y_continuous(NULL,\n                     breaks= NULL) +  #null to suppress axis labels\n \n  theme_bw()  +\n  labs(title= 'Amount-spent distribution across category') +\n  theme(plot.title = element_text(size = 13,\n                                  face='bold'))\n\nedot <- ggplot(data=annual,\n            aes(x=Education)) +\n  geom_dotplot_interactive(aes(tooltip = haveKids,\n                               data_id = haveKids), \n                           stackgroups = TRUE,\n                           #binwidth = 2500,\n                           method = \"histodot\",\n                           dotsize= 0.2) +\n  scale_y_continuous(NULL,\n                     breaks= NULL) +\n \n  theme_bw()\n\nfdot <- ggplot(data=annual,\n            aes(x=Food)) +\n  geom_dotplot_interactive(aes(tooltip = haveKids,\n                               data_id = haveKids), \n                           stackgroups = TRUE,\n                           #binwidth = 2500,\n                           method = \"histodot\",\n                           dotsize= 0.2) +\n  scale_y_continuous(NULL,\n                     breaks= NULL) +\n \n  theme_bw()\n\nrdot <- ggplot(data=annual,\n            aes(x=Recreation)) +\n  geom_dotplot_interactive(aes(tooltip = haveKids,\n                               data_id = haveKids), \n                           stackgroups = TRUE,\n                           #binwidth = 2500,\n                           method = \"histodot\",\n                           dotsize= 0.2) +\n  scale_y_continuous(NULL,\n                     breaks= NULL) +\n \n  theme_bw()\n\ngirafe(code = print(sdot + edot + fdot + rdot), \n       width_svg = 10,\n       height_svg = 10 *0.618,\n       options = list(                          #<<<\n         opts_hover(css='fill: blue;'),      #<<<\n         opts_hover_inv(css = 'opacity: 0.2;')  #<<<\n         )\n       )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#demographics---finance-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#demographics---finance-analysis",
    "title": "Take-home_Ex01",
    "section": "3.2 Demographics - Finance Analysis",
    "text": "3.2 Demographics - Finance Analysis\n\n3.2.1 Distribution of Annual wage across Education Levels\n\n3.2.1.1 Ridgeline plot\nWe will use the annual dataframe to visualise the distribution of annual wage across education levels.\n\n\nCode\nggplot(annual, \n       aes(x = Wage, \n           y = educationLevel,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Wage\",\n                       option = \"D\") +\n  scale_x_continuous(\n    name = \"Annual Wage\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n3.2.1.4 One- way Anova plot\nFirst, check whether wages across education levels conforms to normality.\n\n\nCode\nlow_records <- annual %>% \n               filter(educationLevel=='Low')\nqq <- ggplot(low_records,\n             aes(sample=Wage)) + \n  \n  stat_qq() +\n  stat_qq_line() +\n  ggtitle(\"QQ plot with Shapiro-Wilk test results\")  \n\nsw_t <- shapiro_test(low_records$Wage) %>% \n  as_tibble() %>% \n  mutate(variable = \"Wage for 'Low' EducationLevel\") %>% gt()  \n\ntmp <- tempfile(fileext = '.png') # create  temp table\ngtsave(sw_t, tmp)  # use gtsave() to save sw_t into tmp folder\ntable_png <- png::readPNG(tmp, native = TRUE)\n\nqq+table_png\n\n\n\n\n\nSince p value is less than 0.05, we have enough statistical evidence to reject the null hypothesis and conclude that wages of the participants belong to ’Low” educationLevel do not follow normal distribution. Hence I will choose a non parametric test to compare whether there is significant difference in the median of wage between education levels.\n\n\nCode\nggbetweenstats(data = annual, x = educationLevel, y = Wage,\n               xlab = \"Education level\", ylab = \"Annual Wage\",\n               type = \"np\", pairwise.comparisons = TRUE, pairwise.display = \"s\",\n               sort = \"descending\",\n               sort.fun = median,\n               mean.ci = T, p.adjust.method = \"fdr\",  conf.level = 0.95,\n               title = \"Comparison of Median Annual Wage across Education Levels\") +\n  scale_y_continuous(limits = c(0, 300000)) +\n   theme(axis.title.y=element_text(angle = 0,\n                                  vjust=0.9))\n\n\n\n\n\nFor 4 categories of education levels, we can have a total of 4C2 = k(k-1)/2 (=6) possible combinations of pairs.\nFrom the results, all six pairwise comparison p-values are less than 0.05 and thus we can reject the null hypothesis and conclude that the median wages across all different educational levels are all different from one another.\n\n\n3.2.1.5 Error plots\nThe error bar for mean Median Wage is the longest for Graduate education level and this could be due to outliers in this category.\n\n\nCode\nannual %>%\n  ggplot(aes(x = educationLevel, y = Wage)) +\n  \n  #Using stat_pointinterval to plot the points and intervals\n  stat_pointinterval(.width = c(0.95,0.99),\n  .point = median,\n  .interval = qi,\n  aes(interval_color=stat(level)),\n  show.legend = FALSE) +\n  \n  #Defining the color of the intervals \n  scale_color_manual(\n    values = c(\"blue\", \"darkblue\"),\n    aesthetics = \"interval_color\") +\n  \n  #Title, subtitle, and caption\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot, 95% and 99%\",\n    x = \"Education  level\", y = \"Wage\") +\n  \n  theme_ipsum() +\n  \n  theme(axis.title.y=element_text(angle = 0, \n                                  vjust=0.9, \n                                  size = 10, \n                                  face='bold'),\n        axis.title.x=element_text(size = 10,\n                                   face='bold'),\n        plot.title = element_text(size = 12,\n                                  face='bold'),\n        panel.border = element_blank(),\n        panel.grid.major = element_blank())\n\n\n\n\n\n\n\n\n3.2.2 Distribution of Joviality Index across Education levels\n\n3.2.2.1 Ridgeline plot\n\n\nCode\nggplot(annual, \n       aes(x = joviality, \n           y = educationLevel,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Joviality\",\n                       option = \"D\") +\n  scale_x_continuous(\n    name = \"Joviality\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n3.2.2.2 Normality check on Joviality Index\nPerform a test to confirm whether joviality index follows the normal distribution.\n\n\nCode\nqq <- ggplot(low_records,\n             aes(sample=joviality)) + \n  \n  stat_qq() +\n  stat_qq_line() +\n  ggtitle(\"QQ plot with Shapiro-Wilk test results\")  \n\nsw_t <- shapiro_test(low_records$joviality) %>% \n  as_tibble() %>% \n  mutate(variable = \"Joviality Index of 'Low' educationlevel\")%>% gt()  \n\ntmp <- tempfile(fileext = '.png') # create  temp table\ngtsave(sw_t, tmp)  # use gtsave() to save sw_t into tmp folder\ntable_png <- png::readPNG(tmp, native = TRUE)\n\nqq+table_png\n\n\n\n\n\nP-value is less than 0.05. We have enough statistical evidence to reject the null hypothesis that joviality index of ‘Low’ Educationlevel follows normal distribution. Use a non parametric test below to test for difference in median of joviality index across education levels.\n\n\n3.2.2.2 One way Anova plot\nFrom the results, only 2 pairwise comparison p-values <0.05 and thus we can reject the null hypothesis for (High School & Graduate) and (High School & Bachelors) and conclude that the median Joviality index for these two pairs of education levels are different.\n\n\nCode\nggbetweenstats(data = annual, x = educationLevel, y = joviality,\n               xlab = \"Education level\", ylab = \"Joviality Index\",\n               type = \"np\", pairwise.comparisons = TRUE, pairwise.display = \"s\",\n               sort = \"descending\",\n               sort.fun = median,\n               mean.ci = T, p.adjust.method = \"fdr\",  conf.level = 0.95,\n               title = \"Comparison of Median Joviality index across Education Levels\") +\n  scale_y_continuous(limits = c(0, 2)) +\n   theme(axis.title.y=element_text(angle = 0,\n                                  vjust=0.9))\n\n\n\n\n\n\n\n3.2.2.3 Error Plot\n\n\nCode\nannual %>%\n  ggplot(aes(x = educationLevel, y = joviality)) +\n  \n  #Using stat_pointinterval to plot the points and intervals\n  stat_pointinterval(.width = c(0.95,0.99),\n  .point = median,\n  .interval = qi,\n  aes(interval_color=stat(level)),\n  show.legend = FALSE) +\n  \n  #Defining the color of the intervals \n  scale_color_manual(\n    values = c(\"blue\", \"darkblue\"),\n    aesthetics = \"interval_color\") +\n  \n  #Title, subtitle, and caption\n  labs(\n    title = \"Visualising confidence intervals of median joviality index\",\n    subtitle = \"Median Point + Multiple-interval plot, 95% and 99%\",\n    x = \"Education  level\", y = \"Joviality Index\") +\n  \n  theme_ipsum() +\n  \n  theme(axis.title.y=element_text(angle = 0, \n                                  vjust=0.9, \n                                  size = 10, \n                                  face='bold'),\n        axis.title.x=element_text(size = 10,\n                                   face='bold'),\n        plot.title = element_text(size = 12,\n                                  face='bold'),\n        panel.border = element_blank(),\n        panel.grid.major = element_blank())"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#correlation-between-annual-shelter-cost-and-annual-wage",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#correlation-between-annual-shelter-cost-and-annual-wage",
    "title": "Take-home_Ex01",
    "section": "3.3 Correlation between Annual Shelter cost and Annual Wage",
    "text": "3.3 Correlation between Annual Shelter cost and Annual Wage\nIn this section, we will investigate if people who earn more will also spend more on shelter. We will also subset the data across education levels.\nWe will use the non-parametric Spearman correlation analysis instead of Pearson correlation since the wage data is not normally distributed.\n\n\nCode\nlow_correl <- ggscatterstats(data = annual |> filter(educationLevel == \"Low\"), \n                           x = Wage, y = Shelter,\n                           type = \"nonparametric\") + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n  scale_x_continuous(limits = c(0, 70000), \n                     breaks=seq(0, 70000, 10000), \n                     labels= comma) + \n  scale_y_continuous(limits = c(0, 20000), \n                     breaks=seq(0, 20000, 5000), \n                     labels= comma) +\n  \n  labs(title = \"Low Education Status\", \n       x = \"Annual Wage\", y = \"Annual Shelter fee\") \n\n\n\nhigh_correl <- ggscatterstats(data = annual |> filter(educationLevel == \"HighSchoolOrCollege\"), \n                           x = Wage, y = Shelter,\n                           type = \"nonparametric\") + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n  scale_x_continuous(limits = c(0, 70000), \n                     breaks=seq(0, 70000, 10000), \n                     labels= comma) + \n  scale_y_continuous(limits = c(0, 20000), \n                     breaks=seq(0, 20000, 5000), \n                     labels= comma) +\n  \n  labs(title = \"High Sch Education Status\", \n       x = \"Annual Wage\", y = \"Annual Shelter fee\") \n\n\n\nbac_correl <- ggscatterstats(data = annual |> filter(educationLevel == \"Bachelors\"), \n                           x = Wage, y = Shelter,\n                           type = \"nonparametric\") + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n  scale_x_continuous(limits = c(0, 70000), \n                     breaks=seq(0, 70000, 10000), \n                     labels= comma) + \n  scale_y_continuous(limits = c(0, 20000), \n                     breaks=seq(0, 20000, 5000), \n                     labels= comma) +\n  \n  labs(title = \"Degree Education Status\", \n       x = \"Annual Wage\", y = \"Annual Shelter fee\") \n\n\ngrad_correl <- ggscatterstats(data = annual |> filter(educationLevel == \"Graduate\"), \n                           x = Wage, y = Shelter,\n                           type = \"nonparametric\") + \n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n  scale_x_continuous(limits = c(0, 70000),\n                     breaks=seq(0, 70000, 10000), \n                     labels= comma) + \n  scale_y_continuous(limits = c(0, 20000),\n                     breaks=seq(0, 20000, 5000), \n                     labels= comma) +\n  \n  labs(title = \"Graduate Education Status\", \n       x = \"Annual Wage\", y = \"Annual Shelter fee\") \n\n\n# combining plots using patchwork\np_correl <- (low_correl + high_correl) / (bac_correl + grad_correl) #+ plot_spacer() + plot_spacer()\np_correl + plot_annotation(title = \"Correlation between Shelter spending and Annual Wage\", \n                           theme = theme(plot.title = element_text(size = 18),\n                                         plot.subtitle = element_text(size = 12))) + plot_layout(heights = c(2,2))\n\n\n\n\n\nH0: There is no [monotonic] association between the annual shelter fees and wage.\nH1: There is association between the annual shelter fees and wage.\nFrom the plots above, there are no strong correlation values above 0.7. only the ‘low’ and ‘degree’ education group showed p-values less than 0.05 which shows that there is a significant association between shelter fee and wage. However, the correlation is weak between shelter spending and wage.\n\n\n\n\n\n\nNote\n\n\n\nSpearman correlation\nThe Spearman correlation is not a linear correlation of the data, but a linear correlation of a transformed version of the data -- specifically, the correlation of the rank-transformed data. Do not be mislead by the slope direction."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home_Ex02",
    "section": "",
    "text": "Note\n\n\n\nEdge data should be organised as such: (can use dplyr methods)\nFirst column: Source id (FK to Node second column) - compulsory\nSecond column: Target id (FK to Node second column) - compulsory\nNode data\nFirst column: ID (contains all the distinct values of source and target in Edge data) - compulsory\n\nNodes present in edge data must exists in ID of node data, must not have missing in node ID.\n\nSecond column: Label (only need if Id are all integers)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#network-metrics-analysis",
    "title": "Hands-on_Ex08 (Network graphs)",
    "section": "27.7 Network Metrics Analysis",
    "text": "27.7 Network Metrics Analysis\n\n27.7.1 Computing centrality indices\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\nTidygraph documentation : so far we used tbl_graph() to create a tbl_graph network object / dataframe called GAStech_graph. Then we practise activate() to swtich between nodes and edges tibbles. This network obj is passed into ggraph() to plot the charts.\nNow we are using tidy graph to perform centrality calculations.\nggraph documentation : node, edge, layouts\n\n\nShow the code\nset.seed (1234)\ng <- GAStech_graph %>% \n  mutate(betweenness_centrality = centrality_betweenness()) %>% #<< tidygraph doc\n  ggraph(layout='fr') +\n  geom_edge_link(aes(width=Weight,\n                     alpha= 0.2)) + \n  scale_edge_width(range = c(0.1, 5)) + \n  geom_node_point(aes(colour=Department, size = betweenness_centrality))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code above\n\n\n\n\nmutate() of dplyr is used to perform the computation and create a new col called betweenness_centrality. Use tidyverse commands on tidygraph object.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\nTo see the centrality values\n\n\nShow the code\nGAStech_graph %>% \n  mutate(betweenness_centrality = centrality_betweenness()) \n\n\n# A tbl_graph: 54 nodes and 1456 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 54 × 5\n     id label               Department     Title          betweenness_centrality\n  <dbl> <chr>               <chr>          <chr>                           <dbl>\n1     1 Mat.Bramar          Administration Assistant to …                  307. \n2     2 Anda.Ribera         Administration Assistant to …                  170. \n3     3 Rachel.Pantanal     Administration Assistant to …                   32.8\n4     4 Linda.Lagos         Administration Assistant to …                    0  \n5     5 Ruscella.Mies.Haber Administration Assistant to …                  501. \n6     6 Carla.Forluniau     Administration Assistant to …                   28.2\n# ℹ 48 more rows\n#\n# A tibble: 1,456 × 4\n   from    to Weekday   Weight\n  <int> <int> <ord>      <int>\n1     1     2 Monday         4\n2     1     2 Tuesday        3\n3     1     2 Wednesday      5\n# ℹ 1,453 more rows\n\n\n\n\n27.7.2 Visualising network metrics (without computing col above)\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\n\nShow the code\nset.seed (1234)\ng <- GAStech_graph %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))   #<<<< access betweenness values directly using `centrality_betweenness()`\ng + theme_graph()\n\n\n\n\n\n\n\n27.7.3 Visualising Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used\nthomas85/tidygraph/group\n\n\nShow the code\nset.seed (1234)\ng <- GAStech_graph %>%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\n\nWhat does the n_groups() argument do? Set the number of communities?\n\n\nShow the code\nset.seed (1234)\ng <- GAStech_graph %>%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, \n                                                      directed = TRUE, \n                                                      n_groups = 20))) %>%  #<< should i try to change the number of groups/community?\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "Project/Project_MC2.html",
    "href": "Project/Project_MC2.html",
    "title": "Project_MC2",
    "section": "",
    "text": "Note\n\n\n\nEdge data should be organised as such: (can use dplyr methods)\nFirst column: Source id (FK to Node second column) - compulsory\nSecond column: Target id (FK to Node second column) - compulsory\nNode data\nFirst column: ID - compulsory\nSecond column: Label (contains all the distinct values of source and target in Edge data) (only need if Id are all integers) (what is present in edge data must exists in Labels of node data, must not be missing in node data)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on_Ex08 (Network graphs)",
    "section": "27.8 Building Interactive Network Graph with visNetwork",
    "text": "27.8 Building Interactive Network Graph with visNetwork\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns. (Instead of ‘source’ and ‘target’?)\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n27.8.1 Data preparation\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below. In this df, there is no weekday column, unlike GAStech_edges_aggregated df.\n\n\nShow the code\nGAStech_edges_aggregated2 <- GAStech_edges %>% \n  left_join(GAStech_nodes, by =c('sourceLabel' = 'label')) %>%  #edges$sourceLabel == nodes.label and the key of right table does not appear\n  rename(from = id) %>%   #rename 'id' column to 'from'\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %>%\n  rename(to = id) %>% \n  filter(MainSubject == 'Work related') %>% \n  group_by(from,to) %>% \n  summarise(weight=n()) %>% \n  filter(from != to) %>% \n  filter(weight >1) %>% \n  ungroup()\n\n\n\n\n27.8.2 Plotting the first interactive network graph\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated2)\n\n\n\n\n27.8.3 Working with layout\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\n\nShow the code\nset.seed(1234)\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated2) %>% \n  visIgraphLayout(layout = 'layout_with_fr')\n\n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n27.8.4 Working with visual attributes - Nodes\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\n\nShow the code\nGAStech_nodes <- GAStech_nodes %>% rename(group= Department)\n\n\nRunning the code chunk above with the rename column will allow visNet to shade the nodes by assigning a unique colour to each category in the group field.\n\n\nShow the code\nset.seed(1234)\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated2) %>% \n  visIgraphLayout(layout = 'layout_with_fr') %>% \n  visLegend() \n\n\n\n\n\n\nShow the code\n# %>% visLayout(randomSeed = 1234)\n\n\n\n\n27.8.5 Working with visual attributes - Edges\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\n\nShow the code\nset.seed(1234)\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated2) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = 'to',\n           smooth = list(enables = TRUE,\n                         type= 'curvedCW'),\n           shadow = FALSE,\n           dash = FALSE) %>% \n  visLegend() \n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nVisit Option to find out more about visEdges’s argument.\narrows : “to”, “from”, “middle”, “middle;to”\ndashes: TRUE , FALSE\ntitle: paste(‘Text’, 1:8) – tooltip\nsmooth: FALSE, TRUE\nshadow: TRUE, FALSE\nvisNetwork(nodes, edges, height = “500px”, width = “100%”)\n\n\n\n\n27.8.6 Interactivity\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n- The argument highlightNearest highlights nearest when clicking a node. (Does it highlight the ego-network?)\n- The argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated2) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reference",
    "title": "Hands-on_Ex08 (Network graphs)",
    "section": "27.9 Reference",
    "text": "27.9 Reference\ntidygraph (tbl obj, centrality calc)\nggraph documentation (Node, edge, layout)\nggraph\ngeom-edge_link()\ngeom_node_point()\ntheme_graph()\nggraph_layout\nFacet\nfacet_edges()\nfacet_nodes()\nfacet_graph()\nset_graph_style() defaults\nthomas85github_theme_graph\ncentrality\nthomas85/tidygraph/group\nvisNetwork()\nIgraph\nvisEdge arguments"
  },
  {
    "objectID": "Project/Project_MC2.html#data-dictionary",
    "href": "Project/Project_MC2.html#data-dictionary",
    "title": "Project_MC2",
    "section": "1.1 Data dictionary",
    "text": "1.1 Data dictionary\nNode Attributes:\nid -- Name of the company that originated (or received) the shipment\nshpcountry -- Country the company most often associated with when shipping\nrcvcountry -- Country the company most often associated with when receiving\ndataset -- Always ‘MC2’\nEdge Attributes:\narrivaldate -- Date the shipment arrived at port in YYYY-MM-DD format.\nhscode -- Harmonized System code for the shipment. Can be joined with the hscodes table to get additional details.\nvalueofgoods_omu -- Customs-declared value of the total shipment, in Oceanus\nMonetary Units (OMU)\nvolumeteu -- The volume of the shipment in ‘Twenty-foot equivalent units’, roughly how many 20-foot standard containers would be required. (Actual number of\ncontainers may have been different as there are 20ft and 40ft standard containers and tankers that do not use containers)\nweightkg -- The weight of the shipment in kilograms (if known)\ndataset -- Always ‘MC2’\ntype -- Always ‘shipment’ for MC2\ngenerated_by -- Name of the program that generated the edge. (Only found on ‘bundle’ records.)"
  },
  {
    "objectID": "Project/Project_MC2.html#importing-the-datasets",
    "href": "Project/Project_MC2.html#importing-the-datasets",
    "title": "Project_MC2",
    "section": "1.2 Importing the datasets",
    "text": "1.2 Importing the datasets\nImport libraries\nThe new libraries used today are :\n\njsonlite to import json file\n\n\n\nShow the code\npacman::p_load(jsonlite, igraph, tidygraph, ggraph,\n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts,knitr)\n\n\n\n\nShow the code\nMC2 <- jsonlite::fromJSON(\"C:/yixin-neo/ISSS608-VAA/Project/data/mc2_challenge_graph.json\")\n\n\n\n\nShow the code\ncarp <- jsonlite::fromJSON(\"C:/yixin-neo/ISSS608-VAA/Project/data/bundles/carp.json\")\n\n\nPull out the nodes and edge data and save them as tibble data frames.\n\n\nShow the code\nMC2_nodes <- as_tibble(MC2$nodes) %>% \n  select(id,shpcountry,rcvcountry)\n\n\nRearranging the columns in edge file as we require source and target columns to be the first two columns.\n\n\nShow the code\nMC2_edges <- as_tibble(MC2$links) %>% \n  select(source,target,arrivaldate,hscode,valueofgoods_omu,volumeteu,weightkg,valueofgoodsusd)  \n# can exclude dataste column as they all contain the same values.\n\n\n\n\nShow the code\nglimpse(MC2_nodes)\n\n\nRows: 34,576\nColumns: 3\n$ id         <chr> \"AquaDelight Inc and Son's\", \"BaringoAmerica Marine Ges.m.b…\n$ shpcountry <chr> \"Polarinda\", NA, \"Oceanus\", NA, \"Oceanus\", \"Kondanovia\", NA…\n$ rcvcountry <chr> \"Oceanus\", NA, \"Oceanus\", NA, \"Oceanus\", \"Utoporiana\", NA, …\n\n\n\n\nShow the code\nglimpse(MC2_edges)\n\n\nRows: 5,464,378\nColumns: 8\n$ source           <chr> \"AquaDelight Inc and Son's\", \"AquaDelight Inc and Son…\n$ target           <chr> \"BaringoAmerica Marine Ges.m.b.H.\", \"BaringoAmerica M…\n$ arrivaldate      <chr> \"2034-02-12\", \"2034-03-13\", \"2028-02-07\", \"2028-02-23…\n$ hscode           <chr> \"630630\", \"630630\", \"470710\", \"470710\", \"470710\", \"47…\n$ valueofgoods_omu <dbl> 141015, 141015, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ volumeteu        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ weightkg         <int> 4780, 6125, 10855, 11250, 11165, 11290, 9000, 19490, …\n$ valueofgoodsusd  <dbl> NA, NA, NA, NA, NA, NA, 87110, 188140, NA, 221110, 58…"
  },
  {
    "objectID": "Project/Project_MC2.html#data-cleaning",
    "href": "Project/Project_MC2.html#data-cleaning",
    "title": "Project_MC2",
    "section": "1.3 Data cleaning",
    "text": "1.3 Data cleaning\n\n1.3.1 Check for null values\nCheck whether each column in MC2_nodes and MC2_edges contains null and prints the percentage of null for each column.\nFor MC2_nodes dataframe:\nThere are no null values in the id column of Nodes file, which is great.\n\n\nShow the code\n# Check for null values in each column\nnull_counts_nodes <- sapply(MC2_nodes, function(x) sum(is.null(x) | is.na(x)))\n\n# Calculate the percentage of null values for each column\nnull_percentages_nodes <- null_counts_nodes / nrow(MC2_nodes) * 100\n\n# Display the results\n#print(null_percentages)\n\nknitr::kable(null_percentages_nodes, \"simple\")\n\n\n\n\n\nx\n\n\n\n\n\nid\n0.00000\n\n\nshpcountry\n64.66624\n\n\nrcvcountry\n8.41335\n\n\n\n\n\nFor MC2_edges dataframe:\nAs there are a lot zeros inside MC2_edges$volumteu col, we will consider 0 as equivalent to null values.\nWe can see that the columns valueofgoods_omu and volumeteu are mainly null. valueofgoodusd column contains more than 50% null values. There are 4 records of source with 0 as value, but 0 is their unique identifier so we do not consider 0 as null in source column. It means to say that only source, target, arrivaldate, hscode and weight columns will be helpful in our analysis.\n\n\nShow the code\n# Check for null values in each column\nnull_counts <- sapply(MC2_edges, function(x) sum(is.null(x) | is.na(x) | x==0))\n\n# Calculate the percentage of null values for each column\nnull_percentages <- null_counts / nrow(MC2_edges) * 100\n\n# Display the results\n#print(null_percentages)\n\nknitr::kable(null_percentages, \"simple\")\n\n\n\n\n\nx\n\n\n\n\n\nsource\n0.0000732\n\n\ntarget\n0.0000000\n\n\narrivaldate\n0.0000000\n\n\nhscode\n0.0000000\n\n\nvalueofgoods_omu\n99.9948576\n\n\nvolumeteu\n85.6684146\n\n\nweightkg\n1.0136561\n\n\nvalueofgoodsusd\n55.3358864\n\n\n\n\n\nWe will be dropping the valueofgoods_omu , valueofgoodusdand volumeteu columns from our dataframe.\n\n\nShow the code\nMC2_edges <- MC2_edges %>% select('source','target', 'arrivaldate', 'hscode','weightkg')\n\n\n\n\n\n\n\n1.3.2 Lets check for duplicates\nFor MC2_nodes dataframe:\nThere are no duplicated nodes, which is great.\n\n\nShow the code\n# check for nay duplicates\nany(duplicated(MC2_nodes))\n\n\nFor MC2_edges dataframe:\nThere are about 0.15 mil records (2 % out of total records) that are duplicated.\n\n\nShow the code\n#duplicated only\nprint(any(duplicated(MC2_edges)))\n\n\n[1] TRUE\n\n\nShow the code\nMC2_edges_dup <- MC2_edges[duplicated(MC2_edges), ]\nprint(nrow(MC2_edges_dup))\n\n\n[1] 273971\n\n\nWe will drop the duplicates.\n\n\nShow the code\n# Drop duplicate rows from the dataframe\nMC2_edges_no_dup <- MC2_edges[!duplicated(MC2_edges), ]\n\n\n\n\n1.3.3 Check on the HScodes.\nCheck the unique number of hscodes in the dataset. There are 4761 unique HScodes.\n\n\nShow the code\n# Find the number of unique values in hscode\nlength(unique(MC2_edges_no_dup$hscode))\n\n\n[1] 4761\n\n\nWith reference to World Custom Organisation Harmonized System codes, Section 1 and 4 are related to seafood. We will filter for records that has HScodes starting with 1604 and 1605 as they refer to seafood commodities, thus removing many other transactions like ‘television’, ‘steel parts’ etc…\n\n\nShow the code\nmc2_seafood_edges<- MC2_edges_no_dup[grepl('^1605|^1604', MC2_edges_no_dup$hscode), ]\n#MC2_edges[startsWith(MC2_edges$hscode, \"1601\"), ]\n\n\n\n\nShow the code\n#unique(mc2_seafood_edges$hscode)\n#unique(mc2_seafood_edges$source)\nmc2_seafood_edges_agg <- mc2_seafood_edges %>%  \n  group_by(source, target,arrivaldate) %>% \n  summarise(Weight=n(),\n            Totalweight = sum(weightkg),\n            hscode=first(hscode)) %>% \n  filter(Weight >=5) %>% \n  ungroup()\n\n\nWhen i tried to plot the graph, i found several disconnected components. Thus I am going to inspect the frequency of source and target actors, and remove those actors below a frequency count of 5. First , we remove low frequency source actors under 5 counts.\n\n\nShow the code\n# Calculate the frequency count of values in 'source'\nfrequency_table <- table(mc2_seafood_edges_agg$source)\n\n# Get the values in 'col1' with a frequency count greater than or equal to 5\nvalid_source <- names(frequency_table[frequency_table >= 5])\n\n# Subset the dataframe to keep only rows with valid values in 'col1'\nmc2_seafood_edges_agg <- mc2_seafood_edges_agg[mc2_seafood_edges_agg$source %in% valid_source, ]\n\n\nNext, remove target actors with frequency count less than 5:\n\n\nShow the code\n# Calculate the frequency count of values in 'source'\nfrequency_table <- table(mc2_seafood_edges_agg$target)\n\n# Get the values in 'col1' with a frequency count greater than or equal to 5\nvalid_target <- names(frequency_table[frequency_table >= 5])\n\n# Subset the dataframe to keep only rows with valid values in 'col1'\nmc2_seafood_edges_agg <- mc2_seafood_edges_agg[mc2_seafood_edges_agg$target %in% valid_target, ]\n\n\n# Print the filtered dataframe\n#print(mc2_seafood_edges_agg)\n\n\n\n\nShow the code\n #sort(table(mc2_seafood_edges_agg$target))\n\n\n\n\n1.3.4 Preparation of Nodes\nWe will include only nodes that are in source and target columns in the mc2_seafood_edges_agg dataframe\n\n\nShow the code\nnodes_seafood <- MC2_nodes %>%\n  filter (id %in% c(mc2_seafood_edges_agg$source, mc2_seafood_edges_agg$target))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-dictionary",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-dictionary",
    "title": "Take-home_Ex02",
    "section": "1.1 Data dictionary",
    "text": "1.1 Data dictionary\nNode Attributes:\nid -- Name of the company that originated (or received) the shipment\nshpcountry -- Country the company most often associated with when shipping\nrcvcountry -- Country the company most often associated with when receiving\ndataset -- Always ‘MC2’\nEdge Attributes:\narrivaldate -- Date the shipment arrived at port in YYYY-MM-DD format.\nhscode -- Harmonized System code for the shipment. Can be joined with the hscodes table to get additional details.\nvalueofgoods_omu -- Customs-declared value of the total shipment, in Oceanus\nMonetary Units (OMU)\nvolumeteu -- The volume of the shipment in ‘Twenty-foot equivalent units’, roughly how many 20-foot standard containers would be required. (Actual number of containers may have been different as there are 20ft and 40ft standard containers and tankers that do not use containers)\nweightkg -- The weight of the shipment in kilograms (if known)\ndataset -- Always ‘MC2’\ntype -- Always ‘shipment’ for MC2\ngenerated_by -- Name of the program that generated the edge. (Only found on ‘bundle’ records.)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-the-datasets",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-the-datasets",
    "title": "Take-home_Ex02",
    "section": "1.2 Importing the datasets",
    "text": "1.2 Importing the datasets\nImport libraries\nThe new libraries used today are :\n\njsonlite to import json file\n\n\n\nShow the code\npacman::p_load(jsonlite, igraph, tidygraph, ggraph,\n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts,knitr)\n\n\n\n\nShow the code\nMC2 <- jsonlite::fromJSON(\"C:/yixin-neo/ISSS608-VAA/Project/data/mc2_challenge_graph.json\")\n\n\n\n\n\nPull out the nodes and edge data and save them as tibble data frames.\n\n\nShow the code\nMC2_nodes <- as_tibble(MC2$nodes) %>% \n  select(id,shpcountry,rcvcountry)\n\n\n\n\nRows: 34,576\nColumns: 3\n$ id         <chr> \"AquaDelight Inc and Son's\", \"BaringoAmerica Marine Ges.m.b…\n$ shpcountry <chr> \"Polarinda\", NA, \"Oceanus\", NA, \"Oceanus\", \"Kondanovia\", NA…\n$ rcvcountry <chr> \"Oceanus\", NA, \"Oceanus\", NA, \"Oceanus\", \"Utoporiana\", NA, …\n\n\nRearranging the columns in edge file as we require source and target columns to be the first two columns.\n\n\nShow the code\nMC2_edges <- as_tibble(MC2$links) %>% \n  select(source,target,arrivaldate,hscode,valueofgoods_omu,volumeteu,weightkg,valueofgoodsusd)  \n# can exclude dataste column as they all contain the same values.\n\n\n\n\nRows: 5,464,378\nColumns: 8\n$ source           <chr> \"AquaDelight Inc and Son's\", \"AquaDelight Inc and Son…\n$ target           <chr> \"BaringoAmerica Marine Ges.m.b.H.\", \"BaringoAmerica M…\n$ arrivaldate      <chr> \"2034-02-12\", \"2034-03-13\", \"2028-02-07\", \"2028-02-23…\n$ hscode           <chr> \"630630\", \"630630\", \"470710\", \"470710\", \"470710\", \"47…\n$ valueofgoods_omu <dbl> 141015, 141015, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ volumeteu        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ weightkg         <int> 4780, 6125, 10855, 11250, 11165, 11290, 9000, 19490, …\n$ valueofgoodsusd  <dbl> NA, NA, NA, NA, NA, NA, 87110, 188140, NA, 221110, 58…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-cleaning",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-cleaning",
    "title": "Take-home_Ex02",
    "section": "1.3 Data cleaning",
    "text": "1.3 Data cleaning\n\n1.3.1 Check for null values\nCheck whether each column in MC2_nodes and MC2_edges contains null and prints the percentage of null for each column.\nFor MC2_nodes dataframe:\nThere are no null values in the id column of Nodes file, which is great.\n\n\nShow the code\n# Check for null values in each column\nnull_counts_nodes <- sapply(MC2_nodes, function(x) sum(is.null(x) | is.na(x)))\n\n# Calculate the percentage of null values for each column\nnull_percentages_nodes <- null_counts_nodes / nrow(MC2_nodes) * 100\n\n# Display the results\n#print(null_percentages)\n\nknitr::kable(null_percentages_nodes, \"simple\", col.names = c(\"Null Percentage\"))\n\n\n\n\n\nNull Percenta\nge\n\n\n\n\nid\n0.00000\n\n\nshpcountry\n64.66624\n\n\nrcvcountry\n8.41335\n\n\n\n\n\nFor MC2_edges dataframe:\nAs there are a lot zeros inside MC2_edges$volumteu col, we will consider 0 as equivalent to null values.\nWe can see that the columns valueofgoods_omu and volumeteu are mainly null. valueofgoodusd column contains more than 50% null values. There are 4 records of source with 0 as value, but 0 is their unique identifier so we do not consider 0 as null in source column. It means to say that only source, target, arrivaldate, hscode and weight columns will be helpful in our analysis.\n\n\nShow the code\n# Check for null values in each column\nnull_counts <- sapply(MC2_edges, function(x) sum(is.null(x) | is.na(x) | x==0))\n\n# Calculate the percentage of null values for each column\nnull_percentages <- null_counts / nrow(MC2_edges) * 100\n\n# Display the results\n#print(null_percentages)\n\nknitr::kable(null_percentages, \"simple\", col.names = c(\"Null Percentage\"))\n\n\n\n\n\nNull Percentage\n\n\n\n\n\nsource\n0.0000732\n\n\ntarget\n0.0000000\n\n\narrivaldate\n0.0000000\n\n\nhscode\n0.0000000\n\n\nvalueofgoods_omu\n99.9948576\n\n\nvolumeteu\n85.6684146\n\n\nweightkg\n1.0136561\n\n\nvalueofgoodsusd\n55.3358864\n\n\n\n\n\nWe will be dropping the valueofgoods_omu , valueofgoodusdand volumeteu columns from our dataframe.\n\n\nShow the code\nMC2_edges <- MC2_edges %>% select('source','target', 'arrivaldate', 'hscode','weightkg')\n\n\n\n\n\n\n\n1.3.2 Lets check for duplicates\nFor MC2_nodes dataframe:\nThere are no duplicated nodes, which is great.\n\n\nShow the code\n# check for nay duplicates\nany(duplicated(MC2_nodes))\n\n\nFor MC2_edges dataframe:\nThere are about 273971 records (4% out of total records) that are duplicated.\n\n\nShow the code\n#duplicated only\n# print(any(duplicated(MC2_edges)))\nMC2_edges_dup <- MC2_edges[duplicated(MC2_edges), ]\nprint(nrow(MC2_edges_dup))\n\n\n[1] 273971\n\n\nWe will drop the duplicates.\n\n\nShow the code\n# Drop duplicate rows from the dataframe\nMC2_edges_no_dup <- MC2_edges[!duplicated(MC2_edges), ]\n\n\n\n\n1.3.3 Check on the HScodes.\nCheck the unique number of hscodes in the dataset. There are 4761 unique HScodes.\n\n\nShow the code\n# Find the number of unique values in hscode\nlength(unique(MC2_edges_no_dup$hscode))\n\n\n[1] 4761\n\n\nWith reference to World Custom Organisation Harmonized System codes, Section 1 and 4 are related to seafood trade. We will filter for records that has HScodes starting with 1604 and 1605 as they refer to seafood commodities, thus removing many other transactions like ‘television’, ‘steel parts’ etc…\n\n\nShow the code\nmc2_seafood_edges<- MC2_edges_no_dup[grepl('^1605|^1604', MC2_edges_no_dup$hscode), ]\n#MC2_edges[startsWith(MC2_edges$hscode, \"1601\"), ]\n\n\n\n\n1.3.4 Preparation of Edges\n\n\nShow the code\n#unique(mc2_seafood_edges$hscode)\n#unique(mc2_seafood_edges$source)\nmc2_seafood_edges_agg <- mc2_seafood_edges %>%  \n  group_by(source, target,arrivaldate) %>% \n  summarise(Weight=n(),\n            Totalweight = sum(weightkg),\n            hscode=first(hscode)) %>% \n  filter(Weight >=5) %>% \n  ungroup()\n\n\nI will now wrangle the date columns to prepare dataframe for temporal analysis later.\n(1) change the arrivaldate column to date data type\n(2) create year, month, weekday, weeknumber columns\n\n\nShow the code\nmc2_seafood_edges_agg$arrivaldate <- as.Date(mc2_seafood_edges_agg$arrivaldate)\n\n\n\n\nShow the code\nmc2_seafood_edges_agg <- mc2_seafood_edges_agg %>% \n  mutate(year = year(arrivaldate)) %>% \n  mutate(month = month(arrivaldate)) %>% \n  mutate(day = day(arrivaldate)) %>% \n  mutate(weekday = wday(arrivaldate,\n                        label= TRUE,\n                        abbr = FALSE)) %>% \n  mutate(weeknumber = isoweek(arrivaldate))\n\n\nTo prevent disconnected graphs, I am going to inspect the frequency of source and target actors, and remove those actors below a frequency count of 5.\nFirst , we remove low frequency source actors under 5 counts.\n\n\nShow the code\n# Calculate the frequency count of values in 'source'\nfrequency_table <- table(mc2_seafood_edges_agg$source)\n\n# Get the values in 'col1' with a frequency count greater than or equal to 5\nvalid_source <- names(frequency_table[frequency_table >= 5])\n\n# Subset the dataframe to keep only rows with valid values in 'col1'\nmc2_seafood_edges_agg <- mc2_seafood_edges_agg[mc2_seafood_edges_agg$source %in% valid_source, ]\n\n\nNext, remove target actors with frequency count less than 5:\n\n\nShow the code\n# Calculate the frequency count of values in 'source'\nfrequency_table <- table(mc2_seafood_edges_agg$target)\n\n# Get the values in 'col1' with a frequency count greater than or equal to 5\nvalid_target <- names(frequency_table[frequency_table >= 5])\n\n# Subset the dataframe to keep only rows with valid values in 'col1'\nmc2_seafood_edges_agg <- mc2_seafood_edges_agg[mc2_seafood_edges_agg$target %in% valid_target, ]\n\n\n# Print the filtered dataframe\n#print(mc2_seafood_edges_agg)\n\n\nBased on some checks on the dataset, there were two pairs of actors that exist as disconnected components. They are ‘Rift Valley fishery OJSC’, ‘Bujagali Falls Pic Family’, ‘Neptune’s Realm NV Navigation’ and ’Rybachit Sagl and Son’s. I will remove the edge records if either source or target columns contains any of these four nodes.\n\n\nShow the code\n# Specify the values to be excluded\nvalues_to_exclude <- c('Rift Valley fishery OJSC', 'Bujagali Falls Pic Family', 'Neptune\\'s Realm NV Navigation', 'Rybachit Sagl and Son\\'s')\n\n# Delete rows with specified values in 'from' or 'to' columns\nmc2_seafood_edges_agg <- mc2_seafood_edges_agg %>%\n  filter(!(source %in% values_to_exclude | target %in% values_to_exclude))\n\n# Display the updated data frame\n#print(mc2_seafood_edges_agg)\n\n\n\n\n\n\n\n1.3.5 Preparation of Nodes\nWe will include only nodes that are in source and target columns in the mc2_seafood_edges_agg dataframe\n\n\nShow the code\nnodes_seafood <- MC2_nodes %>%\n  filter (id %in% c(mc2_seafood_edges_agg$source, mc2_seafood_edges_agg$target))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#creating-the-network-graph-dataframe-using-tbl_graph-of-the-tidygraph-package.",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#creating-the-network-graph-dataframe-using-tbl_graph-of-the-tidygraph-package.",
    "title": "Take-home_Ex02",
    "section": "2.1 Creating the network graph dataframe using tbl_graph() of the tidygraph package.",
    "text": "2.1 Creating the network graph dataframe using tbl_graph() of the tidygraph package.\n\n\n\n\n\n\nNote\n\n\n\nNode file needs to have ID of nodes as first column.\nEdge file need to contain source and target as column 1 and 2.\n\n\nTo create the network graph dataframe\n\n\nShow the code\nseafood_graph<- tbl_graph(nodes=nodes_seafood,\n                          edges = mc2_seafood_edges_agg,\n                          directed = TRUE)\n\n\nTaking a look at the dataframe..\n\n\n# A tbl_graph: 187 nodes and 3311 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 187 × 3\n  id                               shpcountry rcvcountry\n  <chr>                            <chr>      <chr>     \n1 Olas del Mar Worldwide           Oceanus    Oceanus   \n2 Panope Limited Liability Company Vesperanda Oceanus   \n3 hǎi dǎn Corporation Wharf        Marebak    Oceanus   \n4 Sea Breezes GmbH & Co. KG Shark  Oceanus    Oceanus   \n5 Costa de la Felicidad Shipping   Alverossia Oceanus   \n6 Mar del Este CJSC                Merigrad   Oceanus   \n# ℹ 181 more rows\n#\n# A tibble: 3,311 × 11\n   from    to arrivaldate Weight Totalweight hscode  year month   day weekday\n  <int> <int> <date>       <int>       <int> <chr>  <dbl> <dbl> <int> <ord>  \n1    76    13 2029-08-03       5       76235 160521  2029     8     3 Friday \n2    76    29 2028-01-02       6       87635 160521  2028     1     2 Sunday \n3    76    29 2030-02-05       7       98075 160521  2030     2     5 Tuesday\n# ℹ 3,308 more rows\n# ℹ 1 more variable: weeknumber <dbl>\n\n\nWe can run the code below to check that seafood_graph is a connected graph:\n\n\nShow the code\nis.connected(seafood_graph)\n\n\n[1] TRUE\n\n\nNow lets calculate the various centrality measures of seafood_graph. The top 10 inodes with reference to various centrality scores are printed using kable() function from knitr.\nI have taken reference from this link.\nFirst compute ‘in-deg’, ‘out-deg’ and ‘pagerank’ scores.\n\n\nShow the code\nseafood_graph<- seafood_graph %>%\n  activate(\"nodes\") %>% \n  mutate(betweenness_centrality = centrality_betweenness(directed = TRUE)) %>% \n  mutate(in_deg_centrality = centrality_degree(weights = NULL, \n                                               mode = \"in\")) %>% \n  mutate(out_deg_centrality = centrality_degree(weights = NULL, \n                                               mode = \"out\")) %>% \n  mutate(pagerank = centrality_pagerank(weights = Weight,\n                                        directed = TRUE))\n\n\nTo see the top 10 nodes with ‘in-deg’ scores:\n\n\nShow the code\nseafood_graph %>% \n  activate(\"nodes\") %>% \n  as_tibble() %>% \n  arrange(desc(in_deg_centrality), desc(pagerank)) %>% \n  select(id,in_deg_centrality,pagerank) %>% \n  head(n=10) %>% \n  kable()\n\n\n\n\n\n\n\n\n\n\nid\nin_deg_centrality\npagerank\n\n\n\n\nVolga River LLC Enterprises\n363\n0.0120864\n\n\nMar del Este CJSC\n253\n0.0229898\n\n\nhǎi dǎn Corporation Wharf\n245\n0.0488873\n\n\nUttarakhand Market Limited Liability Company Nautical\n176\n0.0111509\n\n\nCosta de la Felicidad Shipping\n155\n0.0195796\n\n\nFresh Wharf SRL Consulting\n151\n0.0066176\n\n\nPanope Limited Liability Company\n148\n0.0132797\n\n\nSea Breezes GmbH & Co. KG Shark\n105\n0.0150483\n\n\nEstrella del Mar Tilapia Oyj Marine\n103\n0.0097471\n\n\nCoral Cove BV Delivery\n84\n0.0078418\n\n\n\n\n\nTo see the top 10 nodes with ‘out-deg’ scores:\n\n\nShow the code\nseafood_graph %>% \n  activate(\"nodes\") %>% \n  as_tibble() %>% \n  arrange(desc(out_deg_centrality)) %>% \n  select(id,out_deg_centrality) %>% \n  head(n=10) %>% \n  kable()\n\n\n\n\n\nid\nout_deg_centrality\n\n\n\n\nEstrella de la Costa SRL\n420\n\n\nOceanicOrigin Foods Co Consulting\n232\n\n\nNáutica del Sol Brothers\n152\n\n\nPlaya del Tesoro OJSC\n152\n\n\nBeachcomber’s Bounty Sea spray\n97\n\n\nShou gan Oyj Overseas\n92\n\n\nMar de la Aventura Limited Liability Company\n81\n\n\nNeptune’s Harvest A/S Hijiki\n77\n\n\nAncla del Mar Marine ecology\n71\n\n\nCosta de Coral SRL United\n66\n\n\n\n\n\nTo extract the seafood nodes data from seafood_graph as a dataframe"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#plot-basic-network-graph-cross-fingers",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#plot-basic-network-graph-cross-fingers",
    "title": "Take-home_Ex02",
    "section": "2.2 Plot basic network graph… cross fingers",
    "text": "2.2 Plot basic network graph… cross fingers\n\n\nShow the code\na <- ggraph(seafood_graph) +  #<<< GAStech_graph is a tbl_graph object\n  geom_edge_link(aes(width=Weight, alpha= 0.2)) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point()\na\n\n\n\n\n\nI have actually already excluded source and target actors with frequency counts of 4 and under. I should not exclude anymore ‘innocent’ actors. Lets use visnetwork to get the id of the two pairs that are still inside there….\nWe first need to rename the edge file first two columns to from and to for visNetwork to be able to regconise them.. .\n\n\nShow the code\nmc2_seafood_edges_agg_vis <- mc2_seafood_edges_agg %>% \n  rename(from = source) %>% \n  rename(to = target)\n\n\nNext, I will rename the shpcountry column to group because i would like visNetwork looks for group column to colour the nodes.\n\n\nShow the code\nnodes_seafood_vis <- nodes_seafood %>% \n  rename(group= shpcountry)\n\n\nThe code chunk below plots in interactive network graph using visNetwork.\n\n\nShow the code\nvisNetwork(nodes_seafood_vis,\n           mc2_seafood_edges_agg_vis) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nThe four isolated actors id are ‘Rift Valley fishery OJSC’, ‘Bujagali Falls Pic Family’, ‘Neptune’s Realm NV Navigation’ and ’Rybachit Sagl and Son’s. Thanks to this interactive graph that I know which nodes to remove from my network graph tmr……"
  },
  {
    "objectID": "Project/Project_MC2.html#creating-the-network-graph-dataframe-using-tbl_graph-of-the-tidygraph-package.",
    "href": "Project/Project_MC2.html#creating-the-network-graph-dataframe-using-tbl_graph-of-the-tidygraph-package.",
    "title": "Project_MC2",
    "section": "2.1 Creating the network graph dataframe using tbl_graph() of the tidygraph package.",
    "text": "2.1 Creating the network graph dataframe using tbl_graph() of the tidygraph package.\n\n\n\n\n\n\nNote\n\n\n\nNode file needs to have ID of nodes as first column.\nEdge file need to contain source and target as column 1 and 2.\n\n\nTo create the dataframe\n\n\nShow the code\nseafood_graph<- tbl_graph(nodes=nodes_seafood,\n                          edges = mc2_seafood_edges_agg,\n                          directed = TRUE)\n\n\n\n\nShow the code\nseafood_graph\n\n\n# A tbl_graph: 191 nodes and 3337 edges\n#\n# A directed multigraph with 3 components\n#\n# A tibble: 191 × 3\n  id                               shpcountry rcvcountry\n  <chr>                            <chr>      <chr>     \n1 Olas del Mar Worldwide           Oceanus    Oceanus   \n2 Panope Limited Liability Company Vesperanda Oceanus   \n3 hǎi dǎn Corporation Wharf        Marebak    Oceanus   \n4 Sea Breezes GmbH & Co. KG Shark  Oceanus    Oceanus   \n5 Costa de la Felicidad Shipping   Alverossia Oceanus   \n6 Mar del Este CJSC                Merigrad   Oceanus   \n# ℹ 185 more rows\n#\n# A tibble: 3,337 × 6\n   from    to arrivaldate Weight Totalweight hscode\n  <int> <int> <chr>        <int>       <int> <chr> \n1    77    13 2029-08-03       5       76235 160521\n2    77    29 2028-01-02       6       87635 160521\n3    77    29 2030-02-05       7       98075 160521\n# ℹ 3,334 more rows"
  },
  {
    "objectID": "Project/Project_MC2.html#plot-basic-network-graph-cross-fingers",
    "href": "Project/Project_MC2.html#plot-basic-network-graph-cross-fingers",
    "title": "Project_MC2",
    "section": "2.2 Plot basic network graph… cross fingers",
    "text": "2.2 Plot basic network graph… cross fingers\n\n\nShow the code\na <- ggraph(seafood_graph) +  #<<< GAStech_graph is a tbl_graph object\n  geom_edge_link(aes(width=Weight, alpha= 0.2)) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point()\na\n\n\n\n\n\nI have actually already excluded source and target actors with frequency counts of 4 and under. I should not exclude anymore ‘innocent’ actors. Lets use visnetwork to get the id of the two pairs that are still inside there….\nWe first need to rename the edge file first two columns to from and to for visNetwork to be able to regconise them.. .\n\n\nShow the code\nmc2_seafood_edges_agg_vis <- mc2_seafood_edges_agg %>% \n  rename(from = source) %>% \n  rename(to = target)\n\n\nNext, I will rename the shpcountry column to group because i would like visNetwork looks for group column to colour the nodes.\n\n\nShow the code\nnodes_seafood_vis <- nodes_seafood %>% \n  rename(group= shpcountry)\n\n\nThe code chunk below plots in interactive network graph using visNetwork.\n\n\nShow the code\nvisNetwork(nodes_seafood_vis,\n           mc2_seafood_edges_agg_vis) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nThe four isolated actors id are ‘Rift Valley fishery OJSC’, ‘Bujagali Falls Pic Family’, ‘Neptune’s Realm NV Navigation’ and ’Rybachit Sagl and Son’s. Thanks to this interactive graph that I know which nodes to remove from my network graph tmr……"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#plot-network-graph-based-on-centrality-scores",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#plot-network-graph-based-on-centrality-scores",
    "title": "Take-home_Ex02",
    "section": "2.2 Plot network graph based on centrality scores",
    "text": "2.2 Plot network graph based on centrality scores\n\n\nShow the code\na <- ggraph(seafood_graph) +  #<<< GAStech_graph is a tbl_graph object\n  geom_edge_link(aes(width=Weight, alpha= 0.2)) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(size = in_deg_centrality, colour=rcvcountry))\na + theme_graph()\n\n\n\n\n\n\n2.2.1 Social Network graph featuring top 10% of ‘in-degree’ centrality scores\nWe will first extract the nodes table into a dataframe\n\n\n\nThe quantile function is used to identify the quantile based on the `in_deg_centrality` of the nodes.\n\n\n\nThen we will filter and keep only the nodes in top 50 percent.\n\n\n\nNext , we will remove source-target links that are not formed by the nodes in top_50_indeg_nodes dataframe"
  }
]