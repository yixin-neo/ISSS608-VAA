---
title: "Hands-on_Ex05"
author: "NeoYX"
editor: visual
execute: 
  freeze: auto
  warning: false
  #echo: false
  #message: false
  html:
    code-fold: True
    code-overflow: scroll
    code-summary: "Show the code"
    code-line-numbers: true
---

# 9Â  Visual Statistical Analysis

## 9.1 Learning Outcome

In this hands-on exercise, you will gain hands-on experience on using:

-   ggstatsplot package to create visual graphics with rich statistical information,

-   performance package to visualise model diagnostics, and

-   parameters package to visualise model parameters

## 9.2 Visual Statistical Analysis with **ggstatsplot**

![](https://r4va.netlify.app/chap09/img/image1.jpg){width="33" height="39"}

-   [**ggstatsplot**](https://indrajeetpatil.github.io/ggstatsplot/) is an extension of [**ggplot2**](https://ggplot2.tidyverse.org/) package for creating graphics with details from statistical tests included in the information-rich plots themselves.

    -   To provide alternative statistical inference methods by default.

    -   To follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the [APA](https://my.ilstu.edu/~jhkahn/apastats.html) gold standard for statistical reporting. For example, here are results from a robust t-test:

![](https://r4va.netlify.app/chap09/img/image2.jpg)

::: callout-note
-   parameter refers to the degree of freedom

-   An effect size of 0.77 is a standardized measure of the magnitude of a treatment or intervention effect, or the strength of an association between two variables. Guideline is that an effect size of 0.2 is considered small, 0.5 is considered moderate, and 0.8 is considered large.

-   CI of 95% means if we replicate our sampling from underlying distribution many times, 95% of our samples will have their means within this interval.
:::

## 9.3 Getting Started

### 9.3.1 Installing and launching R packages

In this exercise, **ggstatsplot** and **tidyverse** will be used.

```{r}
pacman::p_load(ggstatsplot, tidyverse,nortest, ggdist)
```

### 9.3.2 Importing data

Lets import the Exam_data.csv using the read_xls() function.

```{r}
exam <- read_csv('data/Exam_data.csv')
```

Take a glimpse at the data.

```{r}
exam
```

```{r}
glimpse(exam)
```

### 9.3.3 One-sample test: *gghistostats()* method

In the code chunk below, [*gghistostats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/gghistostats.html) is used to to build an visual of one-sample test on English scores.

-   A one-sample test is a statistical hypothesis test used to determine whether the mean of a single sample of data differs significantly from a known or hypothesized value.

-   It is a statistical test that compares the mean of a sample to a specified value, such as a population mean, to see if there is enough evidence to reject the null hypothesis that the sample comes from a population with the specified mean.

```{r}
set.seed(1234)

gghistostats(data=exam,
             x = ENGLISH,
             type='bayes',
             test.value =60,
             xlab = 'English scores')
```

### 9.3.4 Unpacking the Bayes Factor

-   A Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.

-   That's because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.

-   When we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as

![](https://r4va.netlify.app/chap09/img/image5.jpg){width="335"}

-   The [**Schwarz criterion**](https://www.statisticshowto.com/bayesian-information-criterion/) is one of the easiest ways to calculate rough approximation of the Bayes Factor.

### 9.3.5 How to interpret Bayes Factor

A **Bayes Factor** can be any positive number. One of the most common interpretations is this one---first proposed by Harold Jeffereys (1961) and slightly modified by [Lee and Wagenmakers](https://www-tandfonline-com.libproxy.smu.edu.sg/doi/pdf/10.1080/00031305.1999.10474443?needAccess=true) in 2013:

![](https://r4va.netlify.app/chap09/img/image6.jpg){width="342"}

#### 9.3.5.1 How to perform a one-sample wilcoxon test

[Reference website from r-bloggers](https://www.r-bloggers.com/2022/07/one-sample-wilcoxon-test-in-r/)

The one-sample Wilcoxon test (non parametric) will tell us whether the scores are *significantly* different from 60 or not (and thus whether they are different from 60 in the population or not)

H0: EL scores = 60

H1: EL scores != 60

The scores are assumed to be independent (a student's score is not impacted or influenced by the score of another student)

```{r}
wilcox.test(exam$ENGLISH,
            mu = 60)
```

**Interpretation**

P-value\<0.05, we have enough statistical evidence to reject the null hypothesis and conclude that the EL scores are significantly different from 60.

::: callout-note
By default, it is a two-tailed test that is done. As for the t.test() function, we can specify that a one-sided test is required by using either the alternative = "greater" or alternative = "less argument in the wilcox.test() function.
:::

**Combine statistical test and plot**

```{r}
set.seed(1234)

gghistostats(data=exam,
             x = ENGLISH,
             type='nonparametric', #nonparametric = Wilcoxon, parametric = t-test
             test.value =60,
             xlab = 'English scores')
```

Did we forget to check if English scores follow a normal distribution? Use ad.test from nortest library.

H0: EL scores follows normal distribution

H1: EL scores do not follow normal distribution.

```{r}
ad.test(exam$ENGLISH)
```

Results from the Anderson_darling normality test shows enough statistical evidence to reject the null hypothesis and conclude that the EL scores do not follow normal distribution . Thus the use of non parametric test is correct.

### 9.3.6 Two-sample mean test: *ggbetweenstats()*

In the code chunk below, [*ggbetweenstats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/ggbetweenstats.html) is used to build a visual for two-sample mean test of Maths scores by gender (independent).

H0: Mean of F and M Math scores are the same.

H1: Mean of F and M Math scores are not the same.

```{r}
ggbetweenstats(data=exam,
               x=GENDER,
               y=MATHS,
               type='np',
               messages=FALSE)
```

Default information: - statistical details - Bayes Factor - sample sizes - distribution summary

Since p-value \> 0.05, we do not have enough statistical evidence to reject the null hypothesis that mean of Math scores of both gender are the same.

However, if we check for normality of Math scores of each gender.

```{r}
# perform Shapiro-Wilk test on math scores by gender
shapiro_test <- by(exam$MATHS, exam$GENDER, shapiro.test)

# extract p-values
p_values <- sapply(shapiro_test, function(x) x$p.value)
# print results
print(p_values)
```

::: callout-note
The **`by()`** function is used to apply a function to subsets of a data frame or vector split by one or more factors. In the above code, we use **`by()`** to split the **`math_score`** column by **`gender`**, and apply the **`shapiro.test()`** function to each group.
:::

From the Shapiro-Wilk test results, MATHS scores for both gender follows normal distribution. Should we have used parametric test instead?

### 9.3.7 Oneway ANOVA Test: *ggbetweenstats()* method

In the code chunk below, [*ggbetweenstats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/ggbetweenstats.html) is used to build a visual for One-way ANOVA test on English score by race (Independent 4 sample mean).

```{r}
ggbetweenstats(
  data = exam,
  x = RACE, 
  y = ENGLISH,
  type = "p",
  mean.ci=TRUE,
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",  # 'ns': shows only non-sig, 's': shows only sig, 'all': both 
  p.adjust.method = "fdr",
  messages = FALSE
)
## might need to call library(PMCMRplus) and library(rstantools) if this code chunck doesnt work.
```

Since p-value \< 0.05, we have enough statistical evidence to reject the null hypothesis and conclude that NOT ALL means of EL scores by race are the same. The results shows that the means of EL scores of Chinese, Indian and Malay are significantly different.
