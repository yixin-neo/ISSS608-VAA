---
title: "Take-home_Ex02"
author: "NeoYX"
date: '15 May 2023'
date-modified: "`r Sys.Date()`"
editor: visual
execute: 
  freeze: auto
  warning: false
  echo: true
  message: true
format:
  html:
    code-fold: true
    code-overflow: scroll
    code-summary: "Show the code"
    code-line-numbers: true
---

::: callout-note
**Edge data** should be organised as such: (can use dplyr methods)

First column: Source id (FK to Node second column) - compulsory

Second column: Target id (FK to Node second column) - compulsory

**Node data**

First column: ID (contains all the distinct values of source and target in Edge data) - compulsory

-   Nodes present in edge data must exists in ID of node data, must not have missing in node ID.

Second column: Label (only need if Id are all integers)
:::

::: callout-warning
Try not to use R built-in NA/NULL function. Manually type "unknown' / 'missing' as a value instead.
:::

# Vast Challenge 2023 Mini Challenge 2 (Subtask: 1)

# 1 About the dataset

## 1.1 Data dictionary

**Node Attributes:**

id \-- Name of the company that originated (or received) the shipment

shpcountry \-- Country the company most often associated with when shipping

rcvcountry \-- Country the company most often associated with when receiving

dataset \-- Always 'MC2'

**Edge Attributes:**

arrivaldate \-- Date the shipment arrived at port in YYYY-MM-DD format.

hscode \-- Harmonized System code for the shipment. Can be joined with the hscodes table to get additional details.

valueofgoods_omu \-- Customs-declared value of the total shipment, in Oceanus

Monetary Units (OMU)

volumeteu \-- The volume of the shipment in 'Twenty-foot equivalent units', roughly how many 20-foot standard containers would be required. (Actual number of containers may have been different as there are 20ft and 40ft standard containers and tankers that do not use containers)

weightkg \-- The weight of the shipment in kilograms (if known)

dataset \-- Always 'MC2'

type \-- Always 'shipment' for MC2

generated_by \-- Name of the program that generated the edge. (Only found on 'bundle' records.)

## 1.2 Importing the datasets

Import libraries

The new libraries used today are :

-   `jsonlite` to import json file

```{r}
pacman::p_load(jsonlite, igraph, tidygraph, ggraph,
               visNetwork, lubridate, clock,
               tidyverse, graphlayouts,knitr)
```

```{r}
MC2 <- jsonlite::fromJSON("C:/yixin-neo/ISSS608-VAA/Project/data/mc2_challenge_graph.json")
```

```{r}
#| eval: false
#| echo:false
carp <- jsonlite::fromJSON("C:/yixin-neo/ISSS608-VAA/Project/data/bundles/carp.json")
```

Pull out the nodes and edge data and save them as tibble data frames.

```{r}
MC2_nodes <- as_tibble(MC2$nodes) %>% 
  select(id,shpcountry,rcvcountry)
```

```{r}
#| echo:false
glimpse(MC2_nodes)
```

Rearranging the columns in edge file as we require `source` and `target` columns to be the first two columns.

```{r}
MC2_edges <- as_tibble(MC2$links) %>% 
  select(source,target,arrivaldate,hscode,valueofgoods_omu,volumeteu,weightkg,valueofgoodsusd)  
# can exclude dataste column as they all contain the same values.
```

```{r}
#| echo:false
glimpse(MC2_edges)
```

## 1.3 Data cleaning

### 1.3.1 Check for null values

Check whether each column in MC2_nodes and MC2_edges contains null and prints the percentage of null for each column.

**For MC2_nodes dataframe:**

There are no null values in the id column of Nodes file, which is great.

```{r}
# Check for null values in each column
null_counts_nodes <- sapply(MC2_nodes, function(x) sum(is.null(x) | is.na(x)))

# Calculate the percentage of null values for each column
null_percentages_nodes <- null_counts_nodes / nrow(MC2_nodes) * 100

# Display the results
#print(null_percentages)

knitr::kable(null_percentages_nodes, "simple", col.names = c("Null Percentage"))
```

**For MC2_edges dataframe:**

As there are a lot zeros inside MC2_edges\$volumteu col, we will consider 0 as equivalent to null values.

We can see that the columns `valueofgoods_omu` and `volumeteu` are mainly null. `valueofgoodusd` column contains more than 50% null values. There are 4 records of `source` with 0 as value, but 0 is their unique identifier so we do not consider 0 as null in `source` column. It means to say that only `source`, `target`, `arrivaldate`, `hscode` and `weight` columns will be helpful in our analysis.

```{r}
# Check for null values in each column
null_counts <- sapply(MC2_edges, function(x) sum(is.null(x) | is.na(x) | x==0))

# Calculate the percentage of null values for each column
null_percentages <- null_counts / nrow(MC2_edges) * 100

# Display the results
#print(null_percentages)

knitr::kable(null_percentages, "simple", col.names = c("Null Percentage"))

```

We will be dropping the `valueofgoods_omu` , `valueofgoodusd`and `volumeteu` columns from our dataframe.

```{r}
MC2_edges <- MC2_edges %>% select('source','target', 'arrivaldate', 'hscode','weightkg')
```

```{r}
#| eval: false
#| echo: false

# Filter rows where 'source' column contains 0
filtered_df <- MC2_edges %>% filter(source == 0)

# Display the filtered dataframe
print(filtered_df)

```

### 1.3.2 Lets check for duplicates

**For MC2_nodes dataframe:**

There are no duplicated nodes, which is great.

```{r}
#| eval: false
# check for nay duplicates
any(duplicated(MC2_nodes))
```

**For MC2_edges dataframe:**

There are about 273971 records (4% out of total records) that are duplicated.

```{r}
#duplicated only
# print(any(duplicated(MC2_edges)))
MC2_edges_dup <- MC2_edges[duplicated(MC2_edges), ]
print(nrow(MC2_edges_dup))
```

We will drop the duplicates.

```{r}
# Drop duplicate rows from the dataframe
MC2_edges_no_dup <- MC2_edges[!duplicated(MC2_edges), ]
```

### 1.3.3 Check on the HScodes.

Check the unique number of hscodes in the dataset. There are 4761 unique HScodes.

```{r}
# Find the number of unique values in hscode
length(unique(MC2_edges_no_dup$hscode))

```

With reference to [World Custom Organisation Harmonized System codes](https://www.wcoomd.org/en/topics/nomenclature/instrument-and-tools/hs-nomenclature-2022-edition/hs-nomenclature-2022-edition.aspx), Section 1 and 4 are related to seafood trade. We will filter for records that has HScodes starting with `1604` and `1605` as they refer to seafood commodities, thus removing many other transactions like 'television', 'steel parts' etc...

```{r}
mc2_seafood_edges<- MC2_edges_no_dup[grepl('^1605|^1604', MC2_edges_no_dup$hscode), ]
#MC2_edges[startsWith(MC2_edges$hscode, "1601"), ]

```

### 1.3.4 Preparation of Edges

```{r}
#unique(mc2_seafood_edges$hscode)
#unique(mc2_seafood_edges$source)
mc2_seafood_edges_agg <- mc2_seafood_edges %>%  
  group_by(source, target,arrivaldate) %>% 
  summarise(Weight=n(),
            Totalweight = sum(weightkg),
            hscode=first(hscode)) %>% 
  filter(Weight >=5) %>% 
  ungroup()
```

I will now wrangle the date columns to prepare dataframe for temporal analysis later.

\(1\) change the arrivaldate column to date data type

\(2\) create year, month, weekday, weeknumber columns

```{r}
mc2_seafood_edges_agg$arrivaldate <- as.Date(mc2_seafood_edges_agg$arrivaldate)

```

```{r}
mc2_seafood_edges_agg <- mc2_seafood_edges_agg %>% 
  mutate(year = year(arrivaldate)) %>% 
  mutate(month = month(arrivaldate)) %>% 
  mutate(day = day(arrivaldate)) %>% 
  mutate(weekday = wday(arrivaldate,
                        label= TRUE,
                        abbr = FALSE)) %>% 
  mutate(weeknumber = isoweek(arrivaldate))
```

To prevent disconnected graphs, I am going to inspect the frequency of source and target actors, and remove those actors below a frequency count of 5.

First , we remove low frequency source actors under 5 counts.

```{r}
# Calculate the frequency count of values in 'source'
frequency_table <- table(mc2_seafood_edges_agg$source)

# Get the values in 'col1' with a frequency count greater than or equal to 5
valid_source <- names(frequency_table[frequency_table >= 5])

# Subset the dataframe to keep only rows with valid values in 'col1'
mc2_seafood_edges_agg <- mc2_seafood_edges_agg[mc2_seafood_edges_agg$source %in% valid_source, ]


```

Next, remove target actors with frequency count less than 5:

```{r}
# Calculate the frequency count of values in 'source'
frequency_table <- table(mc2_seafood_edges_agg$target)

# Get the values in 'col1' with a frequency count greater than or equal to 5
valid_target <- names(frequency_table[frequency_table >= 5])

# Subset the dataframe to keep only rows with valid values in 'col1'
mc2_seafood_edges_agg <- mc2_seafood_edges_agg[mc2_seafood_edges_agg$target %in% valid_target, ]


# Print the filtered dataframe
#print(mc2_seafood_edges_agg)
```

Based on some checks on the dataset, there were two pairs of actors that exist as disconnected components. They are 'Rift Valley fishery OJSC', 'Bujagali Falls Pic Family', 'Neptune's Realm NV Navigation' and 'Rybachit Sagl and Son's. I will remove the edge records if either `source` or `target` columns contains any of these four nodes.

```{r}
# Specify the values to be excluded
values_to_exclude <- c('Rift Valley fishery OJSC', 'Bujagali Falls Pic Family', 'Neptune\'s Realm NV Navigation', 'Rybachit Sagl and Son\'s')

# Delete rows with specified values in 'from' or 'to' columns
mc2_seafood_edges_agg <- mc2_seafood_edges_agg %>%
  filter(!(source %in% values_to_exclude | target %in% values_to_exclude))

# Display the updated data frame
#print(mc2_seafood_edges_agg)

```

```{r}
#| eval: false
#| echo: false
sort(table(mc2_seafood_edges_agg$target))
```

### 1.3.5 Preparation of Nodes

We will include only nodes that are in source and target columns in the `mc2_seafood_edges_agg` dataframe

```{r}
nodes_seafood <- MC2_nodes %>%
  filter (id %in% c(mc2_seafood_edges_agg$source, mc2_seafood_edges_agg$target))
```

# 2 Visualization

## 2.1 Creating the network graph dataframe using tbl_graph() of the tidygraph package.

::: callout-note
Node file needs to have ID of nodes as first column.

Edge file need to contain source and target as column 1 and 2.
:::

To create the network graph dataframe

```{r}
seafood_graph<- tbl_graph(nodes=nodes_seafood,
                          edges = mc2_seafood_edges_agg,
                          directed = TRUE)
```

Taking a look at the dataframe..

```{r}
#| echo: false
seafood_graph
```

We can run the code below to check that seafood_graph is a connected graph:

```{r}
is.connected(seafood_graph)
```

Now lets calculate the various centrality measures of seafood_graph. The top 10 inodes with reference to various centrality scores are printed using `kable()` function from `knitr`.

I have taken reference from this [link](https://hohenfeld.is/posts/graphs-are-fun-an-introduction-to-graphs-in-r/).

First compute 'in-deg', 'out-deg' and 'pagerank' scores.

```{r}
seafood_graph<- seafood_graph %>%
  activate("nodes") %>% 
  mutate(betweenness_centrality = centrality_betweenness(directed = TRUE)) %>% 
  mutate(in_deg_centrality = centrality_degree(weights = NULL, 
                                               mode = "in")) %>% 
  mutate(out_deg_centrality = centrality_degree(weights = NULL, 
                                               mode = "out")) %>% 
  mutate(pagerank = centrality_pagerank(weights = Weight,
                                        directed = TRUE))
```

To see the top 10 nodes with 'in-deg' scores:

```{r}
seafood_graph %>% 
  activate("nodes") %>% 
  as_tibble() %>% 
  arrange(desc(in_deg_centrality), desc(pagerank)) %>% 
  select(id,in_deg_centrality,pagerank) %>% 
  head(n=10) %>% 
  kable()
```

To see the top 10 nodes with 'out-deg' scores:

```{r}
seafood_graph %>% 
  activate("nodes") %>% 
  as_tibble() %>% 
  arrange(desc(out_deg_centrality)) %>% 
  select(id,out_deg_centrality) %>% 
  head(n=10) %>% 
  kable()
```

To extract the seafood nodes data from seafood_graph as a dataframe

```{r}

```

## 2.2 Plot network graph based on centrality scores

```{r}
#| fig-width: 12
#| fig-asp: 0.618
a <- ggraph(seafood_graph) +  #<<< GAStech_graph is a tbl_graph object
  geom_edge_link(aes(width=Weight, alpha= 0.2)) +
  scale_edge_width(range = c(0.1, 5)) +
  geom_node_point(aes(size = in_deg_centrality, colour=rcvcountry))
a + theme_graph()

```

### 2.2.1 Social Network graph featuring top 10% of  'in-degree' centrality scores

We will first extract the nodes table into a dataframe

```{r}
#| eval: false
#| echo: false
# top_50_indeg_nodes <- as.data.frame(seafood_graph)
```

The `quantile` function is used to identify the quantile based on the `` `in_deg_centrality` `` of the nodes.

```{r}
#| eval: false
#| echo: false
quantile_in_deg <- quantile(top_10_indeg_nodes$in_deg_centrality, probs = seq(0,1,1/10))
quantile_in_deg
```

Then we will filter and keep only the nodes in top 50 percent.

```{r}
#| eval: false
#| echo: false
top_50_indeg_nodes <- top_50_indeg_nodes %>%
  filter(in_deg_centrality >= quantile_in_deg[6])
```

Next , we will remove source-target links that are not formed by the nodes in `top_50_indeg_nodes` dataframe

```{r}
#| eval: false
#| echo: false
seafood_edges_top50 <- mc2_seafood_edges_agg %>%
  filter (source %in% c(top_50_indeg_nodes$id)) %>%
  filter (target %in% c(top_50_indeg_nodes$id))
```

# 3 Interactive network graph

We first need to rename the edge file first two columns to `from` and `to` for visNetwork to be able to regconise them.. .

```{r}
mc2_seafood_edges_agg_vis <- mc2_seafood_edges_agg %>% 
  rename(from = source) %>% 
  rename(to = target)
```

Next, I will rename the `shpcountry` column to `group` because i would like visNetwork looks for `group` column to colour the nodes.

```{r}
nodes_seafood_vis <- nodes_seafood %>% 
  rename(group= shpcountry)
```

The code chunk below plots in interactive network graph using visNetwork.

```{r}
#| fig-width: 12
#| fig-asp: 0.618
visNetwork(nodes_seafood_vis,
           mc2_seafood_edges_agg_vis) %>%
  visIgraphLayout(layout = "layout_with_fr") %>%
  visOptions(highlightNearest = TRUE,
             nodesIdSelection = TRUE) %>%
  visLegend() %>%
  visLayout(randomSeed = 123)
```

References:

https://hohenfeld.is/posts/graphs-are-fun-an-introduction-to-graphs-in-r/
