---
title: "Take-home_Ex01"
author: "NeoYX"
date: '7 May 2023'
#date-modified: "`r Sys.Date()`"
editor: visual
execute: 
  freeze: auto
  warning: false
  #echo: false
  #message: false
  html:
    code-fold: True
    code-overflow: scroll
    code-summary: "Show the code"
    code-line-numbers: true
---

# 1. Task and Dataset

This exerises aims to reveal the demographic and financial characteristics of the city of Engagement, using appropriate **static and interactive statistical graphics** methods. It also requires a user-friendly and interactive solution that helps city managers and planners to explore the complex data in an engaging way and reveal hidden patterns.

The dataset consists of a sample survey of 1000 representative residents that collects data related to their household demographic and spending patterns, among other things. There are primarily two datasets used in this exercise

-   'FinancialJournal.csv": Contains 1513635 number of daily transaction records (different categories of income and expenses) over a period of twelve months from March 2022 to February 2023.

<!-- -->

-   'Particpants.csv" : Contains demographics information like household size, age, education level, interest groups, joviality index and whether each household has kids.

In this exercise, each dataset will be cleansed separately and then joined by 'participantID' as primary key to form the final dataset used for further analysis.

# 

# 2. Data Preparation

## 2.1 Install and load the required libraries

The code chunk below uses `pacman::p_load()` to check if packages are installed. If they are, they will be launched into R. The packages installed are

-   `plotly`: Used for creating interactive web-based graphs.

-   `knitr`: Used for dynamic report generation

-   `patchwork`: Used to combine plots

-   `tidyverse`: A collection of core packages designed for data science, used extensively for data preparation and wrangling.

-   `ggthemes`: Provide additional themes for `ggplot2`

-   `ggstatsplot`: Used for creating graphics with details from statistical tests.

-   `ggdist`: Used for visualising distribution and uncertainty

-   `rstatix`: Allows us to perform basic statistical tests, including t-test, Wilcoxon test, ANOVA, Kruskal-Wallis and correlation analyses.

-   `gt` : starting from a tibble table, customise a table and export in various formats. Most importantly, it works with patch. We will save the tabular results from shapiro test as gt object and export using gtsave() into .png file later.

-   

-   

```{r}
pacman::p_load(plotly, knitr, patchwork, tidyverse, ggthemes,hrbrthemes, ggiraph, ggstatsplot, ggdist, png, gifski, rstatix, gt, nortest)
```

## 2.2 Import the dataset

The datasets are imported using `tidyverse`'s `readr::read_csv()` function.

'FinancialJournal.csv" is stored as `finance` variable.

```{r}
finance <- read_csv('data/FinancialJournal.csv')
```

```{r}
#| echo: false
head(finance)
```

Check for empty values in the `finance` table using the `is.na()` function.

```{r}
any(is.na(finance))
```

'Particpants.csv" is stored as `ptcp` variable.

```{r}
ptcp <- read_csv('data/Participants.csv')
```

```{r}
#| echo: false
head(ptcp)
```

Checking for empty values in `ptcp` table using the `is.na()`\` function.

```{r}
any(is.na(ptcp))
```

## 2.3 Data Issues and wrangling

I will discuss the issues in the datasets and proposed cleaning methods.

### 2.3.1 `finance` dataset issues:

-   **participantId** should be converted from `<dbl>` format to `<chr>` format. It should be a categorical and not numerical data type.

-   **timestamp** should be converted from `<dttm>` format to `<date>` format as I will not be analysing time in this exercise.

-   Negative values of **amount** that belong to the expenses categories should be converted to positive values. The amount will also be rounded to two decimal places.

The code chunk below does the following:

-   use the **`as.character()`** function to convert **participantId** to `<chr>` format

-   create a new column **month_year** by extracting the year and month from the **timestamp** column using the **`format()`** function with the **`%Y-%m`** format specifier.

-   use the **`abs()`** function to convert negative values **amount** to positive and round the values to 2 decimal places using the **`round()`** function.

```{r}

# Convert participantId to character
finance <- finance %>% mutate(participantId = as.character(participantId))

# Extract month and year from timestamp
finance <- finance %>% 
  mutate(month_year = format(timestamp, "%m-%Y"))

# Transform negative amounts to positive and round to 2 decimal places
finance <- finance %>% 
  mutate(amount = abs(amount),
         amount = round(amount, 2))

```

A check for duplicates using the `duplicated()` function reveals that there are 1,113 records of duplicates.

-   The **`duplicated()`** function to identify the duplicate rows. It returns a logical vector indicating whether each row is a duplicate of a previous row in the data frame. We can then use this logical vector to subset the data frame and show the duplicate rows. The logical vector is stored in a filter **duplicated_rows** which is used to subset the `finance` data.

```{r}
# Show duplicate rows
duplicated_rows <- finance[duplicated(finance),]
glimpse(duplicated_rows)
```

-   **`unique()`** function is used to remove the duplicate rows form `finance` data

```{r}
# Remove duplicate rows
finance <- unique(finance)
```

-   Perform a final check to verify that there are no more duplicate using `any()` function

```{r}
any(duplicated(finance))
```

The last thing to do is to create a new colunm **date** that is in \<date\> format using the `as.Date` function.

-   the paste0() function is used to concatenate "01-" with each value in the month_year column. This is because as.Date() requires a complete date in the format "dd-mm-yyyy"

    ```{r}
    finance$date <- as.Date(paste0("01-", finance$month_year), format = "%d-%m-%Y")
    ```

**Other issues**

When the `finance` dataset is groupby the **date** variable , it is noticed that the number of distinct participantID who took part in the survey was 1,011 in March 2022 and suddenly reduced to a constant value of 880 from April 2022 onwards. It seems to suggest that there are 131 residents who moved out of the city at the end of March 2022.

In the code chunk below:

-   dataset is group-by **date** and the distinct count of **participantID** is generated using `n_distinct` function

-   the **missing** dataframe is displayed below using `knitr::kable()` function

```{r}
missing_summary <- finance %>%
  group_by(date) %>% 
  summarise(n_distinct=n_distinct(participantId)) %>% 
  rename(`Number of unique participantId` = n_distinct)

knitr::kable(missing_summary, "simple")
```

Since 11 out of 12 months of records are missing for these 131 residents, we will delete their records from the `finance` dataset.

The code chunk below will extract the **participantIds** of residents whose records exists in March 22 but not in all April 22. The **participantIds** will be stored in a vector called **missing_id_vector.**

This code will filter the **`finance`** dataframe for rows with **`date`** equal to '2022-03-01', and then perform an anti-join with a filtered dataframe containing rows with **`date`** equal to '2022-04-01', based on the common **`participantId`** column. The resulting dataframe will only contain **`participantId`**s that are in '2022-03-01' but not in '2022-04-01'. The **`select`** function is used to extract the **`participantId`** column from the resulting dataframe.

In this code, we assign the result of your code to a variable named **`result`**. Then we use the **`pull()`** function to extract the **`participantId`** column from **`result`**. We pass the **`participantId`** column name as an argument to **`pull()`**. Next, we use the **`as.vector()`** function to convert the resulting tibble column to a vector. Finally, we assign the resulting vector to a variable named **`result_vector`** and print it. The resulting **`result_vector`** should be a numeric vector containing the unique **`participantId`** values from your code.

```{r}

missing_id <- finance %>%
  filter(date == as.Date('2022-03-01')) %>% # filter for '2022-03-01' date
  anti_join(finance %>%
             filter(date == as.Date('2022-04-01')), # filter for '2022-04-01' date
             by = 'participantId') %>% # anti-join by 'participantId'
  select(participantId) %>% 
  distinct(participantId)

# extract participantId column as convert this column to vector.
missing_id_vector <- as.vector(pull(missing_id, participantId))

missing_id_vector 

```

Next, we will remove all records of the 131 potentially non-residents from the `finance` dataset .

In the code chunk below:

we use the **`%in%`** operator to check if each **`id`** value is contained in the missing_id_vector. Then we use the negation operator **`!`** to negate this condition, which gives us a logical vector indicating which rows in **`df1`** should be included in the filtered data frame. Finally, we use this logical vector to index **`df1`** and extract only the rows that satisfy the condition. The resulting filtered data frame will not contain the rows where the **`id`** values are 4 or 5.

```{r}
finance1 <- finance[!finance$participantId %in% missing_id_vector, ]
finance1
```

We will double check that the records of 131 non-residents have been removed from `finance1` dataframe.

in the code below

we use the **`distinct()`** function to extract the distinct **`participantId`** values from **`finance1`**. We pass **`participantId`** as an argument to **`distinct()`** to extract only the unique values of this column. Finally, we use the **`n_distinct()`** function to count the number of distinct **`participantId`** values in the resulting tibble.

The resulting **`distinct_count`** variable should contain the count of distinct **`participantId`** values in **`finance1`**.

```{r}
finance1 %>% 
  distinct(participantId) %>% 
  n_distinct()
```

### 2.3.2 `ptcp` dataset issues:

-   **participantId** should be converted from `<dbl>` format to `<chr>` format

-   **householdSize** should be converted from `<dbl>`{style="caret-color: white;"} format to `<fct>`{style="caret-color: white;"} format. It does not make sense to have 2.5 persons.

-   **age** should be converted from `<dbl>`{style="caret-color: white;"} format to `<int>`{style="caret-color: white;"} format.

-   **educationLevel** should be converted from `<chr>` to `<fct>` . It should also be ordered according to 'Low', 'HighSchoolOrCollege', 'Bachelors' and 'Graduate'.

The code chunk below does the following:

-   `as.character` and `as.factor` functions are used to convert **participantId** to `<chr>` , **householdSize** to `<fct>` and **age** to `<int>`.

-   `factor(educationLevel, levels=c("Low", "HighSchoolOrCollege", "Bachelors", "Graduate")))` not only converts **educationLevel** to factor, but also order the values inside.

```{r}
# convert to factor
ptcp <- ptcp %>% mutate(participantId = as.character(participantId))
ptcp <- ptcp %>% mutate(householdSize = as.factor(householdSize))

# Convert educationLevel to factor and order accordingly
ptcp <- ptcp %>% mutate(educationLevel = factor(educationLevel, levels=c("Low", "HighSchoolOrCollege", "Bachelors", "Graduate")))

# convert age to int
ptcp <- ptcp %>% mutate(age = as.integer(age))
```

The columns format are all in order now.

```{r}
glimpse(ptcp)
```

Use `distinct()` and `n_distinct()` to check on the number of unique participantIds in `ptcp` table.

```{r}
ptcp %>% 
  distinct(participantId) %>% 
  n_distinct()
```

Currently, the `ptcp` table still contain the demographic records of the 131 residents who moved out. Let us remove their records by using similar method used in removing the same records in `financial` table.

```{r}
ptcp1 <- ptcp[!ptcp$participantId %in% missing_id_vector, ]

ptcp1 %>% 
  distinct(participantId) %>% 
  n_distinct()
```

Both `finance1` and `ptcp1` tables now contains information about the same number of participantIds.

### 2.3.3 Convert `finance1` table to wide format and perform left outer join with `ptcp1` table.

We will now convert the `finance1` dataframe from a long to a wide format. The code chunk below does the followingL

-   group the data by **participantId** , **date** and **category** using the **`group_by`** function

-   use the `sum` function to calculate the total monthly amount for each **category** per **participantId** per **month**

-   the `pivot_wider` function will convert the **category** column to wide format with total monthly values in the **amount** column.

    ```{r}
    finance1_wide<- finance1 %>%
      group_by(participantId, date, category) %>%
      summarise(total_amount = sum(amount)) %>%
      pivot_wider(names_from = category, values_from = total_amount)
    ```

    ```{r}
    #| echo: false
    finance1_wide
    ```

    ::: callout-note
    About finance1_wide table

    `finance_wide` is a table that has one row for each unique combination of **participantId** and **month** and one column for each unique category from the former `finance1` table.
    :::

    The code chunk below performs a left outer join with finance1_wide table (left) and ptcp1 table (right) with join key **participantId**.

    ```{r}
    # left outer join
    finance1_wide_ptcp1 <- left_join(finance1_wide, ptcp1, by = "participantId")
    ```

    The first 12 rows of the cleansed finance1_wide_ptcp1 is displayed using `knitr::kable()`{style="caret-color: white;"} function. It contains 10,560 rows and 14 columns.

    ```{r}
    knitr::kable(head(finance1_wide_ptcp1,12), "simple") 
    ```

    # 3. Visualisation

    ## 3.1 EDA

    ### 3.1.1 Lollipop and line plot of city's monthly total income vs total expenses (high-level view)

    In this exercise, I will explore the dataset from high level and then zoom into interesting patterns (if I can find any =))

    We prepare the data require for the plot. Categorise Education, Food, Recreation, Shelter into **Expenses**. Wage belongs to **Income** category**.**

    ```{r}
    #| code-fold: True
    highlevel <- finance1_wide_ptcp1 %>%
      group_by(date) %>%
      summarize(Education = sum(Education, na.rm = TRUE),
                Food = sum(Food, na.rm = TRUE),
                Recreation = sum(Recreation, na.rm = TRUE),
                Shelter = sum(Shelter, na.rm = TRUE),
                Wage = sum(Wage, na.rm = TRUE),
                RentAdjustment = sum(RentAdjustment, na.rm = TRUE),
                ExpenseP = sum(Education, Food, Recreation, Shelter),  #<<<
                Income = sum(Wage, RentAdjustment),                    #<<<
                Saving = Income - ExpenseP,                            #<<<
                Expense = ExpenseP * -1                                #<<<
                )
    head(highlevel,5)
    ```

**Design Considerations:**

I have ensured inking concepts (key words, lines, fill are darker) and gridlines are lighter in shade. In order to see the end of the geom_segments, the opacity of the geom_point objects are reduced via `alpha` argument. The vertical gridlines are disabled to avoid confusion with the vertical geom_segment lines.

::: callout-note
## rgb

The first three arguments are (red, green, and blue) and the last argument (alpha)
:::

```{r}
#| code-fold: True
library(scales)
h<-ggplot(highlevel) +
  geom_segment( aes(x=date, xend=date, y=Income, yend=Expense, color="grey20"), size=0.6, alpha= 0.9) +
  geom_point( aes(x=date, y=Income, color="Income", shape='Income', size = Income))+#, size=2 ) +
  geom_point( aes(x=date, y=Expense, color="Expense", shape='Expense' , size = -Expense))+#, size=2 ) +
  geom_line(aes(x=date, y=Saving), color=rgb(0.2,0.2,0.9,0.9), size=1) +
  geom_text(aes(x=as.Date("2022-04-01"), y=max(Saving), label="Saving"), hjust=1, vjust=1, color=rgb(0.2,0.2,0.9,0.5), size=3.5) +
  
  theme_light() +
  theme(#legend.position = "none",
    
        axis.line.y = element_line(color="black", size=0.2, linetype="solid"),
        panel.grid.major.x = element_blank(),
        panel.border = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.y=element_text(angle = 0,
                                  vjust=0.9),
        axis.text.x = element_text(angle = 45, hjust = 1)) +
  
  scale_x_date(date_breaks = '1 month',date_labels = "%b %Y") +
  scale_y_continuous(limits = c(-2000000, 6500000), breaks=seq(-2000000, 6500000, 1000000), labels= comma) +
  
  scale_color_manual(values = c("Income" = rgb(0.2,0.7,0.1,0.9), "Expense" = rgb(0.7,0.2,0.1,0.9))) +
  scale_shape_manual(values = c("Income" = 16, "Expense" = 16)) +
  labs(color="", shape="") +
  guides(color = guide_legend(override.aes = list(size = 3))) +
  
  geom_hline(yintercept=0, color="black", size=0.2) +
  
  xlab("") +
  ylab("Amount") +
  ggtitle('City monthly total income, total expense and total savings')

ggplotly(h,
         tooltip = c('labels','x','y'))
```

### 3.1.2 Interactive Line charts of income and expenditures by month (Zoom-in)

**Design considerations:**

Due to the large difference in values between wage and other expenses, I have separated income and expense into two graphs. This will enable use to visualise the values of the expense clearly. For the second line plot, the type of expenses are directly labelled beside the lines instead of using a legend as it is more user-friendly this way.

There are several manual adjustments that I made to the graph and the key ones are shown below:

-   the **`color`** aesthetic within each **`geom_line`** maps the name of the variable to a specific color. Then, the **`scale_color_manual`** function is used to assign the desired colors to each variable name.

-   **`scale_x_date()`** is used to display all the values in the x-axis with the date format "%Y-%m".

-   **`scale_y_continuous()`** with **`labels = comma`** is used to format the y-axis labels with commas.

-   **`theme_light()`** is used to set the plot background to white and remove the grid lines.

-   **`element_line()`** is used to increase the axis line width.

-   **`legend.position = "none"`** is used to remove the legend since they are labelled.

-   **`legend.title = element_blank()`** is used to remove the legend title.

```{r}
#| code-fold: True
library(scales)

q1<-highlevel %>%
  ggplot(aes(x = date)) +
  geom_line(aes(y = Wage, color = "Red", linetype = "Wage"), size = 1) +
  #geom_line(aes(y = RentAdjustment, color = "RentAdjustment"), size = 1) +
  
  # annotating the plot
  geom_text(aes(x=as.Date("2022-04-01"), y=6000000, label="High wages \nobserved in \nMarch"), hjust=1, vjust=1, color='black', size=2.5) +
  geom_text(aes(x=as.Date("2022-12-01"), y=3800000, label="Wage"), hjust=1, vjust=1, color='red', size=2.5) +
 # geom_text(aes(x=as.Date("2022-12-01"), y=280000, label="RentalAdjustment"), hjust=1, vjust=1, color='blue', size=2.5) +
 # scale_color_manual(values = c("Wage" = "red", "RentAdjustment" = "blue")) +

  # chart control
  labs(x = "Month", y = "Amount") +
  scale_x_date(date_breaks = '1 month',date_labels = "%b %Y") +
  scale_y_continuous(limits = c(0, 6500000), breaks=seq(0, 6500000, 1000000), labels= comma) +

 

  theme_light(base_size = 12) +
  theme(axis.title = element_text(size = 10 , face = "bold"),
        axis.text = element_text(size = 10),
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.line = element_line(size = 1),
        panel.grid.major.x = element_blank(),
        panel.grid.minor = element_line(colour='black'),
        panel.border = element_blank(),
        legend.position = "none",
        legend.title = element_blank()) +
        #legend.text = element_text(size = 5)) + 

  labs(title= 'Cumulative Income across Months',
       x='Month',
       y='Amount')

ggplotly(q1,tooltip = c('labels','x','y'))
```

```{r}
#| code-fold: True
q2<-highlevel %>%
  ggplot(aes(x = date)) +
  geom_line(aes(y = Education, color = "Education"), size = 1,,alpha=0.8) +
  geom_line(aes(y = Recreation, color = "Recreation"), size = 1,,alpha=0.8) +
  geom_line(aes(y = Food, color = "Food"), size = 1, alpha=0.8) +
  geom_line(aes(y = Shelter, color = "Shelter"), size = 1,alpha=0.8) +
  scale_color_manual(values = c("Education" = "green", "Recreation" = "purple",
                                "Food" = "orange", "Shelter" = "blue")) +
  scale_linetype_manual(values = c("Wage" = "dashed", "RentAdjustment" = "dashed"),
                        guide = guide_legend(override.aes = list(size = 1.2))) +
  
  # annotating the plot
  geom_text(aes(x=as.Date("2022-04-01"), y=640000, label="Higher recreationaland shelter \nspendings observed \nin March"), hjust=1, vjust=1, color='grey10',size=2.5) +
  geom_text(aes(x=as.Date("2022-12-01"), y=600000, label="Shelter"), hjust=1, vjust=1, color='blue', size=2.5) +
  geom_text(aes(x=as.Date("2022-12-01"), y=280000, label="Recreational"), hjust=1, vjust=1, color='purple', size=2.5) +
  geom_text(aes(x=as.Date("2022-12-01"), y=380000, label="Food"), hjust=1, vjust=1, color='orange', size=2.5) +
  geom_text(aes(x=as.Date("2022-12-01"), y=50000, label="Education"), hjust=1, vjust=1, color='green', size=2.5) +
  
  # chart control
  labs(x = "Month", y = "Amount") +
  scale_x_date(date_breaks = '1 month',date_labels = "%b %Y") +
  scale_y_continuous(limits = c(0, 650000), breaks=seq(0, 650000, 100000), labels= comma) +
  
  theme_light(base_size = 12) +
  theme(axis.title = element_text(size = 10 , face = "bold"),
        axis.text = element_text(size = 10),
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.line = element_line(size = 1),
        panel.grid.major.x = element_blank(),
        panel.grid.minor = element_line(colour='black'),
        panel.border = element_blank(),
        legend.position = "none",
        legend.title = element_blank(),
        legend.text = element_text(size = 5)) + 

  labs(title= "Cumulative City Expenses across Months",
       x='Month',
       y='Amount')

ggplotly(q2,tooltip = c('labels','x','y'))
```

From both plots above, March seems to be an exciting month where there is several anomalies observed. There are unsual spikes in wage, recreational and shelter spending.

### 3.1.3 Interactive bubble plots of (Savings, Recreation, Shelter, Food and Jovality) against wage

Pending

```{r}
#| echo: False
#| eval: False
glimpse(finance1_wide_ptcp1)
```

```{r}
#| echo: False
#| eval: False
ggplot(finance1_wide_ptcp1, aes(x = educationLevel, y = Wage)) +
  geom_boxplot() +
  labs(x = "Education Level", y = "Wage")+
facet_wrap(~date)
```

```{r}
#| echo: False
#| eval: False
df_wage_march <- filter(finance1_wide_ptcp1, month(date) == 3) %>%
  select(Wage, educationLevel)
head(df_wage_march)
```

```{r}
#| echo: False
#| eval: False
ggplot(df_wage_march, aes(x = educationLevel, y = Wage)) +

  geom_jitter(width = 0.1, height = 0, alpha = 0.5) +
  geom_boxplot() +
  labs(x = "Education Level", y = "Wage")

```

## 3.2 CDA

## 3.2.1 Normality assumptions of annual wage

Preparing the dataframe needed:

```{r}
#| code-fold: True
annual <- finance1_wide_ptcp1 %>% 
  group_by(participantId, householdSize, haveKids, educationLevel, interestGroup, joviality) %>% 
  summarize(Education = sum(Education, na.rm = TRUE),
            Food = sum(Food, na.rm = TRUE),
            Recreation = sum(Recreation, na.rm = TRUE),
            Shelter = sum(Shelter, na.rm = TRUE),
            Wage = sum(Wage, na.rm = TRUE),
            RentAdjustment = sum(RentAdjustment, na.rm = TRUE)) 
```

::: callout-note
Note that the **`na.rm = TRUE`** argument is used in the **`sum`** function to handle missing values in the columns during aggregation.
:::

We will first perform a test to confirm whether wage follows the normal distribution.

*H0: The wage does not follow a normal distribution.*

*H1: The wage follows a normal distribution.*

```{r}
qq <- ggplot(annual,
       aes(sample=Wage)) +  #<<< use a new argument call sample: el scores
  stat_qq() +
  stat_qq_line() +
  ggtitle("QQ plot with Shapiro-Wilk test results")  # add plot title

sw_t <- shapiro_test(annual$Wage) %>% 
  as_tibble() %>% 
  mutate(variable = "Wage")%>% gt()  #<<< make into a gt format (will give a nice table)  shapiro.test is not used here as it gives output in another format.

tmp <- tempfile(fileext = '.png') # create  temp table
gtsave(sw_t, tmp)  # use gtsave() to save sw_t into tmp folder
table_png <- png::readPNG(tmp, native = TRUE)

qq+table_png
```

From the Shapiro test , p-value \< 0.05 and we have enough statistical evidence to reject the null hypothesis and conclude that **Wage** does not follow the normal distribution. To compare whether there is significant difference in the median of wage between education levels, we must choose a non-parametric test.

### 

3.2.2 Comparison of Annual Wage by Education levels

```{r}
#| code-fold: True
#| fig-width: 8
#| fig-aspect: fig-width*0.618
ggbetweenstats(data = annual, x = educationLevel, y = Wage,
               xlab = "Education level", ylab = "Annual Wage",
               type = "np", pairwise.comparisons = TRUE, pairwise.display = "s", 
               mean.ci = T, p.adjust.method = "fdr",  conf.level = 0.95,
               title = "Comparison of Median Annual Wage across Education Levels") +
  scale_y_continuous(limits = c(0, 300000)) +
   theme(axis.title.y=element_text(angle = 0,
                                  vjust=0.9))
```

From the results, all the pairwise comparison p-values \<0.05 and thus we can reject the null hypothesis and conclude that the median values across different educational levels are not the same.

### 3.2.3 Correlation between Annual Shelter cost and Annual Wage

We will use the non-parametric Spearman correlation analysis instead of Pearson correlation since the wage data is not normally distributed.

```{r}
#| code-fold: True
#| fig-width: 10
#| fig-height: 12
low_correl <- ggscatterstats(data = annual |> filter(educationLevel == "Low"), 
                           x = Wage, y = Shelter,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 70000), breaks=seq(0, 70000, 10000), labels= comma) + 
  scale_y_continuous(limits = c(0, 20000), breaks=seq(0, 20000, 5000), labels= comma) +
  
  labs(title = "Low Education Status", 
       x = "Annual Wage", y = "Annual Shelter fee") 


high_correl <- ggscatterstats(data = annual |> filter(educationLevel == "HighSchoolOrCollege"), 
                           x = Wage, y = Shelter,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 70000), breaks=seq(0, 70000, 10000), labels= comma) + 
  scale_y_continuous(limits = c(0, 20000), breaks=seq(0, 20000, 5000), labels= comma) +
  
  labs(title = "High sch Education Status", 
       x = "Annual Wage", y = "Annual Shelter fee") 


bac_correl <- ggscatterstats(data = annual |> filter(educationLevel == "Bachelors"), 
                           x = Wage, y = Shelter,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 70000), breaks=seq(0, 70000, 10000), labels= comma) + 
  scale_y_continuous(limits = c(0, 20000), breaks=seq(0, 20000, 5000), labels= comma) +
  
  labs(title = "Degree Education Status", 
       x = "Annual Wage", y = "Annual Shelter fee") 


grad_correl <- ggscatterstats(data = annual |> filter(educationLevel == "Graduate"), 
                           x = Wage, y = Shelter,
                           type = "nonparametric") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_continuous(limits = c(0, 70000), breaks=seq(0, 70000, 10000), labels= comma) + 
  scale_y_continuous(limits = c(0, 20000), breaks=seq(0, 20000, 5000), labels= comma) +
  
  labs(title = "Graduate Education Status", 
       x = "Annual Wage", y = "Annual Shelter fee") 


p_correl <- (low_correl + high_correl) / (bac_correl + grad_correl) + plot_spacer()
p_correl
#+
  #scale_x_continuous(limits = c(0, 1500000)) +
  #scale_y_continuous(limits = c(50, 160))
```
